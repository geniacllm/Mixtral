{"cells":[{"cell_type":"markdown","metadata":{"id":"vR3LerzHLX_g"},"source":["# Moe-recipes 事前学習[Colab]"]},{"cell_type":"markdown","metadata":{"id":"FDKHNtG4MKsN"},"source":["## Installing"]},{"cell_type":"code","source":["from IPython.display import Javascript"],"metadata":{"id":"XJeeggue3sDq","executionInfo":{"status":"ok","timestamp":1710823244179,"user_tz":-540,"elapsed":3,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"da8S29Ttv48f"},"source":["Pythonのバージョンが3.10なので、3.11に上げる必要あり。（このあとでやる。）"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1710823249418,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"},"user_tz":-540},"id":"QNE01dnYlo1L","outputId":"9afe1447-42be-44b0-f1a1-be7c0ea47f7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.10.12\n"]}],"source":["!python --version"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3186,"status":"ok","timestamp":1710823253410,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"},"user_tz":-540},"id":"WC5v9lBnm0e3","outputId":"cfed8df8-cebb-4a39-92b0-9e5daa89a6da"},"outputs":[{"output_type":"stream","name":"stdout","text":["/root\n","Cloning into 'moe-recipes'...\n","remote: Enumerating objects: 1310, done.\u001b[K\n","remote: Counting objects: 100% (1310/1310), done.\u001b[K\n","remote: Compressing objects: 100% (511/511), done.\u001b[K\n","remote: Total 1310 (delta 734), reused 1300 (delta 724), pack-reused 0\u001b[K\n","Receiving objects: 100% (1310/1310), 18.48 MiB | 15.22 MiB/s, done.\n","Resolving deltas: 100% (734/734), done.\n"]}],"source":["%cd ~\n","\n","# GitHubのユーザー名を設定\n","user = \"kumagai6\"\n","# GitHubのPersonal Access Token\n","password = \"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\"\n","# リポジトリのURL\n","repo_url = \"https://github.com/kumagai6/moe.git\"\n","\n","# リポジトリURLの'https://'の後にユーザー名とトークンを挿入\n","auth_url = repo_url.replace('https://', f'https://{user}:{password}@')\n","\n","# Gitコマンドを使用してクローンまたは操作\n","!git clone {auth_url} moe-recipes"]},{"cell_type":"markdown","metadata":{"id":"UHYWaTDkFYYX"},"source":["cudaを11.8にダウングレード"]},{"cell_type":"markdown","metadata":{"id":"1EguEIwwHaca"},"source":["現在のCUDAバージョン確認"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1710823253410,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"},"user_tz":-540},"id":"3bRkLjJ1FcZ4","outputId":"09a9cf1a-045e-4bd6-e3fe-4a40e851f25a"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/cuda-12  /usr/local/cuda-12.2\n","nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2023 NVIDIA Corporation\n","Built on Tue_Aug_15_22:02:13_PDT_2023\n","Cuda compilation tools, release 12.2, V12.2.140\n","Build cuda_12.2.r12.2/compiler.33191640_0\n"]}],"source":["!ls -d /usr/local/cuda-*\n","!nvcc --version"]},{"cell_type":"markdown","metadata":{"id":"gHQY_x3KHxWM"},"source":["CUDA11.8のインストール。5分くらいかかる。\n","（途中でkeyboard layoutの選択を求められるところを自動で選択して進むようDEBIAN_FRONTEND環境変数をセットした。)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":100},"id":"l8oJp3zxOJUD","executionInfo":{"status":"ok","timestamp":1710823549648,"user_tz":-540,"elapsed":296243,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}},"outputId":"0fb18203-42e9-48ce-8d45-b2f935958395"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["google.colab.output.setIframeHeight(0, true, {maxHeight: 100})"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  cpp-12 cuda-cccl-11-8 cuda-command-line-tools-11-8 cuda-compiler-11-8\n","  cuda-cudart-11-8 cuda-cudart-dev-11-8 cuda-cuobjdump-11-8 cuda-cupti-11-8\n","  cuda-cupti-dev-11-8 cuda-cuxxfilt-11-8 cuda-demo-suite-11-8\n","  cuda-documentation-11-8 cuda-driver-dev-11-8 cuda-drivers cuda-drivers-550\n","  cuda-gdb-11-8 cuda-libraries-11-8 cuda-libraries-dev-11-8 cuda-memcheck-11-8\n","  cuda-nsight-11-8 cuda-nsight-compute-11-8 cuda-nsight-systems-11-8\n","  cuda-nvcc-11-8 cuda-nvdisasm-11-8 cuda-nvml-dev-11-8 cuda-nvprof-11-8\n","  cuda-nvprune-11-8 cuda-nvrtc-11-8 cuda-nvrtc-dev-11-8 cuda-nvtx-11-8\n","  cuda-nvvp-11-8 cuda-profiler-api-11-8 cuda-runtime-11-8 cuda-sanitizer-11-8\n","  cuda-toolkit-11-8 cuda-toolkit-11-8-config-common\n","  cuda-toolkit-11-config-common cuda-tools-11-8 cuda-visual-tools-11-8\n","  dctrl-tools default-jre default-jre-headless dkms fakeroot fonts-dejavu-core\n","  fonts-dejavu-extra gcc-12 gds-tools-11-8 keyboard-configuration libasan8\n","  libatk-wrapper-java libatk-wrapper-java-jni libcublas-11-8\n","  libcublas-dev-11-8 libcufft-11-8 libcufft-dev-11-8 libcufile-11-8\n","  libcufile-dev-11-8 libcurand-11-8 libcurand-dev-11-8 libcusolver-11-8\n","  libcusolver-dev-11-8 libcusparse-11-8 libcusparse-dev-11-8 libfakeroot\n","  libfontenc1 libgcc-12-dev libjansson4 liblocale-gettext-perl libnpp-11-8\n","  libnpp-dev-11-8 libnvidia-cfg1-550 libnvidia-common-550\n","  libnvidia-compute-550 libnvidia-decode-550 libnvidia-encode-550\n","  libnvidia-extra-550 libnvidia-fbc1-550 libnvidia-gl-550 libnvjpeg-11-8\n","  libnvjpeg-dev-11-8 libtinfo5 libtsan2 libudev1 libxcb-icccm4 libxcb-image0\n","  libxcb-keysyms1 libxcb-render-util0 libxcb-util1 libxcb-xinerama0\n","  libxcb-xinput0 libxcb-xkb1 libxcvt0 libxfont2 libxkbcommon-x11-0 libxkbfile1\n","  libxtst6 libxxf86dga1 nsight-compute-2022.3.0 nsight-systems-2022.4.2\n","  nvidia-compute-utils-550 nvidia-dkms-550 nvidia-driver-550\n","  nvidia-firmware-550-550.54.14 nvidia-kernel-common-550\n","  nvidia-kernel-source-550 nvidia-prime nvidia-settings nvidia-utils-550\n","  openjdk-11-jre python3-xkit screen-resolution-extra systemd-hwe-hwdb udev\n","  x11-utils x11-xkb-utils xcvt xfonts-base xfonts-encodings xfonts-utils\n","  xserver-common xserver-xorg-core xserver-xorg-video-nvidia-550\n","Suggested packages:\n","  gcc-12-locales cpp-12-doc debtags menu gcc-12-multilib gcc-12-doc mesa-utils\n","  xfs | xserver xfonts-100dpi | xfonts-75dpi xfonts-scalable\n","Recommended packages:\n","  libnvidia-compute-550:i386 libnvidia-decode-550:i386\n","  libnvidia-encode-550:i386 libnvidia-fbc1-550:i386 libnvidia-gl-550:i386\n","The following NEW packages will be installed:\n","  cpp-12 cuda-11-8 cuda-cccl-11-8 cuda-command-line-tools-11-8\n","  cuda-compiler-11-8 cuda-cudart-11-8 cuda-cudart-dev-11-8 cuda-cuobjdump-11-8\n","  cuda-cupti-11-8 cuda-cupti-dev-11-8 cuda-cuxxfilt-11-8 cuda-demo-suite-11-8\n","  cuda-documentation-11-8 cuda-driver-dev-11-8 cuda-drivers cuda-drivers-550\n","  cuda-gdb-11-8 cuda-libraries-11-8 cuda-libraries-dev-11-8 cuda-memcheck-11-8\n","  cuda-nsight-11-8 cuda-nsight-compute-11-8 cuda-nsight-systems-11-8\n","  cuda-nvcc-11-8 cuda-nvdisasm-11-8 cuda-nvml-dev-11-8 cuda-nvprof-11-8\n","  cuda-nvprune-11-8 cuda-nvrtc-11-8 cuda-nvrtc-dev-11-8 cuda-nvtx-11-8\n","  cuda-nvvp-11-8 cuda-profiler-api-11-8 cuda-runtime-11-8 cuda-sanitizer-11-8\n","  cuda-toolkit-11-8 cuda-toolkit-11-8-config-common\n","  cuda-toolkit-11-config-common cuda-tools-11-8 cuda-visual-tools-11-8\n","  dctrl-tools default-jre default-jre-headless dkms fakeroot fonts-dejavu-core\n","  fonts-dejavu-extra gcc-12 gds-tools-11-8 keyboard-configuration libasan8\n","  libatk-wrapper-java libatk-wrapper-java-jni libcublas-11-8\n","  libcublas-dev-11-8 libcufft-11-8 libcufft-dev-11-8 libcufile-11-8\n","  libcufile-dev-11-8 libcurand-11-8 libcurand-dev-11-8 libcusolver-11-8\n","  libcusolver-dev-11-8 libcusparse-11-8 libcusparse-dev-11-8 libfakeroot\n","  libfontenc1 libgcc-12-dev libjansson4 liblocale-gettext-perl libnpp-11-8\n","  libnpp-dev-11-8 libnvidia-cfg1-550 libnvidia-common-550\n","  libnvidia-compute-550 libnvidia-decode-550 libnvidia-encode-550\n","  libnvidia-extra-550 libnvidia-fbc1-550 libnvidia-gl-550 libnvjpeg-11-8\n","  libnvjpeg-dev-11-8 libtinfo5 libtsan2 libxcb-icccm4 libxcb-image0\n","  libxcb-keysyms1 libxcb-render-util0 libxcb-util1 libxcb-xinerama0\n","  libxcb-xinput0 libxcb-xkb1 libxcvt0 libxfont2 libxkbcommon-x11-0 libxkbfile1\n","  libxtst6 libxxf86dga1 nsight-compute-2022.3.0 nsight-systems-2022.4.2\n","  nvidia-compute-utils-550 nvidia-dkms-550 nvidia-driver-550\n","  nvidia-firmware-550-550.54.14 nvidia-kernel-common-550\n","  nvidia-kernel-source-550 nvidia-prime nvidia-settings nvidia-utils-550\n","  openjdk-11-jre python3-xkit screen-resolution-extra systemd-hwe-hwdb udev\n","  x11-utils x11-xkb-utils xcvt xfonts-base xfonts-encodings xfonts-utils\n","  xserver-common xserver-xorg-core xserver-xorg-video-nvidia-550\n","The following packages will be upgraded:\n","  libudev1\n","1 upgraded, 123 newly installed, 0 to remove and 37 not upgraded.\n","Need to get 3,039 MB of archives.\n","After this operation, 7,560 MB of additional disk space will be used.\n","Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-toolkit-11-config-common 11.8.89-1 [16.4 kB]\n","Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-toolkit-11-8-config-common 11.8.89-1 [16.3 kB]\n","Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-cudart-11-8 11.8.89-1 [165 kB]\n","Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-nvrtc-11-8 11.8.89-1 [16.4 MB]\n","Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libcublas-11-8 11.11.3.6-1 [248 MB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblocale-gettext-perl amd64 1.07-4build3 [17.1 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 keyboard-configuration all 1.205ubuntu3 [206 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 cpp-12 amd64 12.3.0-1ubuntu1~22.04 [10.8 MB]\n","Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libcufft-11-8 10.9.0.58-1 [94.2 MB]\n","Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libasan8 amd64 12.3.0-1ubuntu1~22.04 [2,442 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtsan2 amd64 12.3.0-1ubuntu1~22.04 [2,477 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgcc-12-dev amd64 12.3.0-1ubuntu1~22.04 [2,618 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gcc-12 amd64 12.3.0-1ubuntu1~22.04 [21.7 MB]\n","Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libcufile-11-8 1.4.0.31-1 [474 kB]\n","Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libcurand-11-8 10.3.0.86-1 [42.2 MB]\n","Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libcusolver-11-8 11.4.1.48-1 [52.3 MB]\n","Get:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libcusparse-11-8 11.7.5.86-1 [116 MB]\n","Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 dctrl-tools amd64 2.24-3build2 [66.9 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dkms all 2.8.7-2ubuntu2.2 [70.1 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.12 [78.2 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.12 [1,557 kB]\n","Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjansson4 amd64 2.13.1-1.1build3 [32.4 kB]\n","Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n","Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n","Get:25 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.8 [28.6 kB]\n","Get:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcvt0 amd64 0.1.1-3 [5,494 B]\n","Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n","Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n","Get:29 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-xorg-core amd64 2:21.1.4-2ubuntu1.7~22.04.8 [1,477 kB]\n","Get:30 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libtinfo5 amd64 6.3-2ubuntu0.1 [100 kB]\n","Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinerama0 amd64 1.14-3ubuntu3 [5,414 B]\n","Get:32 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-icccm4 amd64 0.4.1-1.1build2 [11.5 kB]\n","Get:33 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-util1 amd64 0.4.0-1build2 [11.4 kB]\n","Get:34 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-image0 amd64 0.4.0-2 [11.5 kB]\n","Get:35 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-keysyms1 amd64 0.4.0-1build3 [8,746 B]\n","Get:36 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-render-util0 amd64 0.3.9-1build3 [10.3 kB]\n","Get:37 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xkb1 amd64 1.14-3ubuntu3 [32.8 kB]\n","Get:38 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnpp-11-8 11.8.0.86-1 [102 MB]\n","Get:39 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbcommon-x11-0 amd64 1.4.0-1 [14.4 kB]\n","Get:40 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinput0 amd64 1.14-3ubuntu3 [34.3 kB]\n","Get:41 http://archive.ubuntu.com/ubuntu jammy/main amd64 default-jre-headless amd64 2:1.11-72build2 [3,042 B]\n","Get:42 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n","Get:43 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jre amd64 11.0.22+7-0ubuntu2~22.04.1 [214 kB]\n","Get:44 http://archive.ubuntu.com/ubuntu jammy/main amd64 default-jre amd64 2:1.11-72build2 [896 B]\n","Get:45 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfakeroot amd64 1.28-1ubuntu1 [31.5 kB]\n","Get:46 http://archive.ubuntu.com/ubuntu jammy/main amd64 fakeroot amd64 1.28-1ubuntu1 [60.4 kB]\n","Get:47 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n","Get:48 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n","Get:49 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n","Get:50 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n","Get:51 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n","Get:52 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n","Get:53 http://archive.ubuntu.com/ubuntu jammy/main amd64 nvidia-prime all 0.8.17.1 [9,956 B]\n","Get:54 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-xkit all 0.5.0ubuntu5 [18.5 kB]\n","Get:55 http://archive.ubuntu.com/ubuntu jammy/main amd64 screen-resolution-extra all 0.18.2 [4,396 B]\n","Get:56 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n","Get:57 http://archive.ubuntu.com/ubuntu jammy/main amd64 xcvt amd64 0.1.1-3 [7,140 B]\n","Get:58 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n","Get:59 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n","Get:60 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n","Get:61 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvjpeg-11-8 11.9.0.86-1 [1,865 kB]\n","Get:62 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-libraries-11-8 11.8.0-1 [2,518 B]\n","Get:63 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-common-550 550.54.14-0ubuntu1 [17.1 kB]\n","Get:64 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-compute-550 550.54.14-0ubuntu1 [49.5 MB]\n","Get:65 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-gl-550 550.54.14-0ubuntu1 [136 MB]\n","Get:66 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-kernel-source-550 550.54.14-0ubuntu1 [41.1 MB]\n","Get:67 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-firmware-550-550.54.14 550.54.14-0ubuntu1 [36.8 MB]\n","Get:68 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-kernel-common-550 550.54.14-0ubuntu1 [109 kB]\n","Get:69 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-dkms-550 550.54.14-0ubuntu1 [36.2 kB]\n","Get:70 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-extra-550 550.54.14-0ubuntu1 [71.2 kB]\n","Get:71 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-compute-utils-550 550.54.14-0ubuntu1 [118 kB]\n","Get:72 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-decode-550 550.54.14-0ubuntu1 [1,783 kB]\n","Get:73 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-encode-550 550.54.14-0ubuntu1 [100 kB]\n","Get:74 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-utils-550 550.54.14-0ubuntu1 [493 kB]\n","Get:75 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-cfg1-550 550.54.14-0ubuntu1 [145 kB]\n","Get:76 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  xserver-xorg-video-nvidia-550 550.54.14-0ubuntu1 [1,534 kB]\n","Get:77 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-fbc1-550 550.54.14-0ubuntu1 [55.0 kB]\n","Get:78 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-driver-550 550.54.14-0ubuntu1 [489 kB]\n","Get:79 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-drivers-550 550.54.14-1 [2,546 B]\n","Get:80 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-drivers 550.54.14-1 [2,506 B]\n","Get:81 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-runtime-11-8 11.8.0-1 [2,424 B]\n","Get:82 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-cuobjdump-11-8 11.8.86-1 [165 kB]\n","Get:83 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-cuxxfilt-11-8 11.8.86-1 [189 kB]\n","Get:84 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-cccl-11-8 11.8.89-1 [1,040 kB]\n","Get:85 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-driver-dev-11-8 11.8.89-1 [27.3 kB]\n","Get:86 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-cudart-dev-11-8 11.8.89-1 [820 kB]\n","Get:87 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-nvcc-11-8 11.8.89-1 [43.5 MB]\n","Get:88 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-nvprune-11-8 11.8.86-1 [58.1 kB]\n","Get:89 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-compiler-11-8 11.8.0-1 [2,432 B]\n","Get:90 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-profiler-api-11-8 11.8.86-1 [18.5 kB]\n","Get:91 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-nvrtc-dev-11-8 11.8.89-1 [13.5 MB]\n","Get:92 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libcublas-dev-11-8 11.11.3.6-1 [269 MB]\n","Get:93 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libcufft-dev-11-8 10.9.0.58-1 [189 MB]\n","Get:94 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libcufile-dev-11-8 1.4.0.31-1 [1,062 kB]\n","Get:95 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libcurand-dev-11-8 10.3.0.86-1 [42.9 MB]\n","Get:96 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libcusolver-dev-11-8 11.4.1.48-1 [35.7 MB]\n","Get:97 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libcusparse-dev-11-8 11.7.5.86-1 [116 MB]\n","Get:98 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnpp-dev-11-8 11.8.0.86-1 [100 MB]\n","Get:99 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvjpeg-dev-11-8 11.9.0.86-1 [1,536 kB]\n","Get:100 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-libraries-dev-11-8 11.8.0-1 [2,554 B]\n","Get:101 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-cupti-11-8 11.8.87-1 [15.4 MB]\n","Get:102 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-cupti-dev-11-8 11.8.87-1 [2,552 kB]\n","Get:103 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-nvdisasm-11-8 11.8.86-1 [50.8 MB]\n","Get:104 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-gdb-11-8 11.8.86-1 [4,138 kB]\n","Get:105 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-memcheck-11-8 11.8.86-1 [142 kB]\n","Get:106 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-nvprof-11-8 11.8.87-1 [1,959 kB]\n","Get:107 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-nvtx-11-8 11.8.86-1 [51.3 kB]\n","Get:108 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-sanitizer-11-8 11.8.86-1 [8,784 kB]\n","Get:109 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-command-line-tools-11-8 11.8.0-1 [2,472 B]\n","Get:110 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nsight-compute-2022.3.0 2022.3.0.22-1 [580 MB]\n","Get:111 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-nsight-compute-11-8 11.8.0-1 [3,790 B]\n","Get:112 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nsight-systems-2022.4.2 2022.4.2.50-32196742v0 [286 MB]\n","Get:113 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-nsight-systems-11-8 11.8.0-1 [3,310 B]\n","Get:114 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-nsight-11-8 11.8.86-1 [119 MB]\n","Get:115 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-nvml-dev-11-8 11.8.86-1 [81.4 kB]\n","Get:116 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-nvvp-11-8 11.8.87-1 [114 MB]\n","Get:117 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-visual-tools-11-8 11.8.0-1 [2,870 B]\n","Get:118 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  gds-tools-11-8 1.4.0.31-1 [38.7 MB]\n","Get:119 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-tools-11-8 11.8.0-1 [2,390 B]\n","Get:120 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-documentation-11-8 11.8.86-1 [49.8 kB]\n","Get:121 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-toolkit-11-8 11.8.0-1 [3,374 B]\n","Get:122 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-demo-suite-11-8 11.8.86-1 [3,997 kB]\n","Get:123 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-11-8 11.8.0-1 [2,450 B]\n","Get:124 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-settings 550.54.14-0ubuntu1 [946 kB]\n","Fetched 3,039 MB in 41s (74.7 MB/s)\n","Extracting templates from packages: 100%\n","Preconfiguring packages ...\n","Selecting previously unselected package liblocale-gettext-perl.\n","(Reading database ... 121752 files and directories currently installed.)\n","Preparing to unpack .../0-liblocale-gettext-perl_1.07-4build3_amd64.deb ...\n","Unpacking liblocale-gettext-perl (1.07-4build3) ...\n","Selecting previously unselected package keyboard-configuration.\n","Preparing to unpack .../1-keyboard-configuration_1.205ubuntu3_all.deb ...\n","Unpacking keyboard-configuration (1.205ubuntu3) ...\n","Selecting previously unselected package cpp-12.\n","Preparing to unpack .../2-cpp-12_12.3.0-1ubuntu1~22.04_amd64.deb ...\n","Unpacking cpp-12 (12.3.0-1ubuntu1~22.04) ...\n","Selecting previously unselected package libasan8:amd64.\n","Preparing to unpack .../3-libasan8_12.3.0-1ubuntu1~22.04_amd64.deb ...\n","Unpacking libasan8:amd64 (12.3.0-1ubuntu1~22.04) ...\n","Selecting previously unselected package libtsan2:amd64.\n","Preparing to unpack .../4-libtsan2_12.3.0-1ubuntu1~22.04_amd64.deb ...\n","Unpacking libtsan2:amd64 (12.3.0-1ubuntu1~22.04) ...\n","Selecting previously unselected package libgcc-12-dev:amd64.\n","Preparing to unpack .../5-libgcc-12-dev_12.3.0-1ubuntu1~22.04_amd64.deb ...\n","Unpacking libgcc-12-dev:amd64 (12.3.0-1ubuntu1~22.04) ...\n","Selecting previously unselected package gcc-12.\n","Preparing to unpack .../6-gcc-12_12.3.0-1ubuntu1~22.04_amd64.deb ...\n","Unpacking gcc-12 (12.3.0-1ubuntu1~22.04) ...\n","Selecting previously unselected package dctrl-tools.\n","Preparing to unpack .../7-dctrl-tools_2.24-3build2_amd64.deb ...\n","Unpacking dctrl-tools (2.24-3build2) ...\n","Selecting previously unselected package dkms.\n","Preparing to unpack .../8-dkms_2.8.7-2ubuntu2.2_all.deb ...\n","Unpacking dkms (2.8.7-2ubuntu2.2) ...\n","Preparing to unpack .../9-libudev1_249.11-0ubuntu3.12_amd64.deb ...\n","Unpacking libudev1:amd64 (249.11-0ubuntu3.12) over (249.11-0ubuntu3.10) ...\n","Setting up libudev1:amd64 (249.11-0ubuntu3.12) ...\n","Selecting previously unselected package udev.\n","(Reading database ... 122112 files and directories currently installed.)\n","Preparing to unpack .../000-udev_249.11-0ubuntu3.12_amd64.deb ...\n","Unpacking udev (249.11-0ubuntu3.12) ...\n","Selecting previously unselected package libjansson4:amd64.\n","Preparing to unpack .../001-libjansson4_2.13.1-1.1build3_amd64.deb ...\n","Unpacking libjansson4:amd64 (2.13.1-1.1build3) ...\n","Selecting previously unselected package cuda-toolkit-11-config-common.\n","Preparing to unpack .../002-cuda-toolkit-11-config-common_11.8.89-1_all.deb ...\n","Unpacking cuda-toolkit-11-config-common (11.8.89-1) ...\n","Selecting previously unselected package cuda-toolkit-11-8-config-common.\n","Preparing to unpack .../003-cuda-toolkit-11-8-config-common_11.8.89-1_all.deb ...\n","Unpacking cuda-toolkit-11-8-config-common (11.8.89-1) ...\n","Selecting previously unselected package cuda-cudart-11-8.\n","Preparing to unpack .../004-cuda-cudart-11-8_11.8.89-1_amd64.deb ...\n","Unpacking cuda-cudart-11-8 (11.8.89-1) ...\n","Selecting previously unselected package cuda-nvrtc-11-8.\n","Preparing to unpack .../005-cuda-nvrtc-11-8_11.8.89-1_amd64.deb ...\n","Unpacking cuda-nvrtc-11-8 (11.8.89-1) ...\n","Selecting previously unselected package libcublas-11-8.\n","Preparing to unpack .../006-libcublas-11-8_11.11.3.6-1_amd64.deb ...\n","Unpacking libcublas-11-8 (11.11.3.6-1) ...\n","Selecting previously unselected package libcufft-11-8.\n","Preparing to unpack .../007-libcufft-11-8_10.9.0.58-1_amd64.deb ...\n","Unpacking libcufft-11-8 (10.9.0.58-1) ...\n","Selecting previously unselected package libcufile-11-8.\n","Preparing to unpack .../008-libcufile-11-8_1.4.0.31-1_amd64.deb ...\n","Unpacking libcufile-11-8 (1.4.0.31-1) ...\n","Selecting previously unselected package libcurand-11-8.\n","Preparing to unpack .../009-libcurand-11-8_10.3.0.86-1_amd64.deb ...\n","Unpacking libcurand-11-8 (10.3.0.86-1) ...\n","Selecting previously unselected package libcusolver-11-8.\n","Preparing to unpack .../010-libcusolver-11-8_11.4.1.48-1_amd64.deb ...\n","Unpacking libcusolver-11-8 (11.4.1.48-1) ...\n","Selecting previously unselected package libcusparse-11-8.\n","Preparing to unpack .../011-libcusparse-11-8_11.7.5.86-1_amd64.deb ...\n","Unpacking libcusparse-11-8 (11.7.5.86-1) ...\n","Selecting previously unselected package libnpp-11-8.\n","Preparing to unpack .../012-libnpp-11-8_11.8.0.86-1_amd64.deb ...\n","Unpacking libnpp-11-8 (11.8.0.86-1) ...\n","Selecting previously unselected package libnvjpeg-11-8.\n","Preparing to unpack .../013-libnvjpeg-11-8_11.9.0.86-1_amd64.deb ...\n","Unpacking libnvjpeg-11-8 (11.9.0.86-1) ...\n","Selecting previously unselected package cuda-libraries-11-8.\n","Preparing to unpack .../014-cuda-libraries-11-8_11.8.0-1_amd64.deb ...\n","Unpacking cuda-libraries-11-8 (11.8.0-1) ...\n","Selecting previously unselected package libnvidia-common-550.\n","Preparing to unpack .../015-libnvidia-common-550_550.54.14-0ubuntu1_all.deb ...\n","Unpacking libnvidia-common-550 (550.54.14-0ubuntu1) ...\n","Selecting previously unselected package libnvidia-compute-550:amd64.\n","Preparing to unpack .../016-libnvidia-compute-550_550.54.14-0ubuntu1_amd64.deb ...\n","Unpacking libnvidia-compute-550:amd64 (550.54.14-0ubuntu1) ...\n","Selecting previously unselected package libnvidia-gl-550:amd64.\n","Preparing to unpack .../017-libnvidia-gl-550_550.54.14-0ubuntu1_amd64.deb ...\n","dpkg-query: no packages found matching libnvidia-gl-535\n","Unpacking libnvidia-gl-550:amd64 (550.54.14-0ubuntu1) ...\n","Selecting previously unselected package nvidia-kernel-source-550.\n","Preparing to unpack .../018-nvidia-kernel-source-550_550.54.14-0ubuntu1_amd64.deb ...\n","Unpacking nvidia-kernel-source-550 (550.54.14-0ubuntu1) ...\n","Selecting previously unselected package nvidia-firmware-550-550.54.14.\n","Preparing to unpack .../019-nvidia-firmware-550-550.54.14_550.54.14-0ubuntu1_amd64.deb ...\n","Unpacking nvidia-firmware-550-550.54.14 (550.54.14-0ubuntu1) ...\n","Selecting previously unselected package nvidia-kernel-common-550.\n","Preparing to unpack .../020-nvidia-kernel-common-550_550.54.14-0ubuntu1_amd64.deb ...\n","Unpacking nvidia-kernel-common-550 (550.54.14-0ubuntu1) ...\n","Selecting previously unselected package nvidia-dkms-550.\n","Preparing to unpack .../021-nvidia-dkms-550_550.54.14-0ubuntu1_amd64.deb ...\n","Unpacking nvidia-dkms-550 (550.54.14-0ubuntu1) ...\n","Selecting previously unselected package libnvidia-extra-550:amd64.\n","Preparing to unpack .../022-libnvidia-extra-550_550.54.14-0ubuntu1_amd64.deb ...\n","Unpacking libnvidia-extra-550:amd64 (550.54.14-0ubuntu1) ...\n","Selecting previously unselected package nvidia-compute-utils-550.\n","Preparing to unpack .../023-nvidia-compute-utils-550_550.54.14-0ubuntu1_amd64.deb ...\n","Unpacking nvidia-compute-utils-550 (550.54.14-0ubuntu1) ...\n","Selecting previously unselected package libnvidia-decode-550:amd64.\n","Preparing to unpack .../024-libnvidia-decode-550_550.54.14-0ubuntu1_amd64.deb ...\n","Unpacking libnvidia-decode-550:amd64 (550.54.14-0ubuntu1) ...\n","Selecting previously unselected package libnvidia-encode-550:amd64.\n","Preparing to unpack .../025-libnvidia-encode-550_550.54.14-0ubuntu1_amd64.deb ...\n","Unpacking libnvidia-encode-550:amd64 (550.54.14-0ubuntu1) ...\n","Selecting previously unselected package nvidia-utils-550.\n","Preparing to unpack .../026-nvidia-utils-550_550.54.14-0ubuntu1_amd64.deb ...\n","Unpacking nvidia-utils-550 (550.54.14-0ubuntu1) ...\n","Selecting previously unselected package libnvidia-cfg1-550:amd64.\n","Preparing to unpack .../027-libnvidia-cfg1-550_550.54.14-0ubuntu1_amd64.deb ...\n","Unpacking libnvidia-cfg1-550:amd64 (550.54.14-0ubuntu1) ...\n","Selecting previously unselected package libxkbfile1:amd64.\n","Preparing to unpack .../028-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n","Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n","Selecting previously unselected package x11-xkb-utils.\n","Preparing to unpack .../029-x11-xkb-utils_7.7+5build4_amd64.deb ...\n","Unpacking x11-xkb-utils (7.7+5build4) ...\n","Selecting previously unselected package xserver-common.\n","Preparing to unpack .../030-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.8_all.deb ...\n","Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.8) ...\n","Selecting previously unselected package libxcvt0:amd64.\n","Preparing to unpack .../031-libxcvt0_0.1.1-3_amd64.deb ...\n","Unpacking libxcvt0:amd64 (0.1.1-3) ...\n","Selecting previously unselected package libfontenc1:amd64.\n","Preparing to unpack .../032-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n","Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n","Selecting previously unselected package libxfont2:amd64.\n","Preparing to unpack .../033-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n","Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n","Selecting previously unselected package xserver-xorg-core.\n","Preparing to unpack .../034-xserver-xorg-core_2%3a21.1.4-2ubuntu1.7~22.04.8_amd64.deb ...\n","Unpacking xserver-xorg-core (2:21.1.4-2ubuntu1.7~22.04.8) ...\n","Selecting previously unselected package xserver-xorg-video-nvidia-550.\n","Preparing to unpack .../035-xserver-xorg-video-nvidia-550_550.54.14-0ubuntu1_amd64.deb ...\n","Unpacking xserver-xorg-video-nvidia-550 (550.54.14-0ubuntu1) ...\n","Selecting previously unselected package libnvidia-fbc1-550:amd64.\n","Preparing to unpack .../036-libnvidia-fbc1-550_550.54.14-0ubuntu1_amd64.deb ...\n","Unpacking libnvidia-fbc1-550:amd64 (550.54.14-0ubuntu1) ...\n","Selecting previously unselected package nvidia-driver-550.\n","Preparing to unpack .../037-nvidia-driver-550_550.54.14-0ubuntu1_amd64.deb ...\n","Unpacking nvidia-driver-550 (550.54.14-0ubuntu1) ...\n","Selecting previously unselected package cuda-drivers-550.\n","Preparing to unpack .../038-cuda-drivers-550_550.54.14-1_amd64.deb ...\n","Unpacking cuda-drivers-550 (550.54.14-1) ...\n","Selecting previously unselected package cuda-drivers.\n","Preparing to unpack .../039-cuda-drivers_550.54.14-1_amd64.deb ...\n","Unpacking cuda-drivers (550.54.14-1) ...\n","Selecting previously unselected package cuda-runtime-11-8.\n","Preparing to unpack .../040-cuda-runtime-11-8_11.8.0-1_amd64.deb ...\n","Unpacking cuda-runtime-11-8 (11.8.0-1) ...\n","Selecting previously unselected package cuda-cuobjdump-11-8.\n","Preparing to unpack .../041-cuda-cuobjdump-11-8_11.8.86-1_amd64.deb ...\n","Unpacking cuda-cuobjdump-11-8 (11.8.86-1) ...\n","Selecting previously unselected package cuda-cuxxfilt-11-8.\n","Preparing to unpack .../042-cuda-cuxxfilt-11-8_11.8.86-1_amd64.deb ...\n","Unpacking cuda-cuxxfilt-11-8 (11.8.86-1) ...\n","Selecting previously unselected package cuda-cccl-11-8.\n","Preparing to unpack .../043-cuda-cccl-11-8_11.8.89-1_amd64.deb ...\n","Unpacking cuda-cccl-11-8 (11.8.89-1) ...\n","Selecting previously unselected package cuda-driver-dev-11-8.\n","Preparing to unpack .../044-cuda-driver-dev-11-8_11.8.89-1_amd64.deb ...\n","Unpacking cuda-driver-dev-11-8 (11.8.89-1) ...\n","Selecting previously unselected package cuda-cudart-dev-11-8.\n","Preparing to unpack .../045-cuda-cudart-dev-11-8_11.8.89-1_amd64.deb ...\n","Unpacking cuda-cudart-dev-11-8 (11.8.89-1) ...\n","Selecting previously unselected package cuda-nvcc-11-8.\n","Preparing to unpack .../046-cuda-nvcc-11-8_11.8.89-1_amd64.deb ...\n","Unpacking cuda-nvcc-11-8 (11.8.89-1) ...\n","Selecting previously unselected package cuda-nvprune-11-8.\n","Preparing to unpack .../047-cuda-nvprune-11-8_11.8.86-1_amd64.deb ...\n","Unpacking cuda-nvprune-11-8 (11.8.86-1) ...\n","Selecting previously unselected package cuda-compiler-11-8.\n","Preparing to unpack .../048-cuda-compiler-11-8_11.8.0-1_amd64.deb ...\n","Unpacking cuda-compiler-11-8 (11.8.0-1) ...\n","Selecting previously unselected package cuda-profiler-api-11-8.\n","Preparing to unpack .../049-cuda-profiler-api-11-8_11.8.86-1_amd64.deb ...\n","Unpacking cuda-profiler-api-11-8 (11.8.86-1) ...\n","Selecting previously unselected package cuda-nvrtc-dev-11-8.\n","Preparing to unpack .../050-cuda-nvrtc-dev-11-8_11.8.89-1_amd64.deb ...\n","Unpacking cuda-nvrtc-dev-11-8 (11.8.89-1) ...\n","Selecting previously unselected package libcublas-dev-11-8.\n","Preparing to unpack .../051-libcublas-dev-11-8_11.11.3.6-1_amd64.deb ...\n","Unpacking libcublas-dev-11-8 (11.11.3.6-1) ...\n","Selecting previously unselected package libcufft-dev-11-8.\n","Preparing to unpack .../052-libcufft-dev-11-8_10.9.0.58-1_amd64.deb ...\n","Unpacking libcufft-dev-11-8 (10.9.0.58-1) ...\n","Selecting previously unselected package libcufile-dev-11-8.\n","Preparing to unpack .../053-libcufile-dev-11-8_1.4.0.31-1_amd64.deb ...\n","Unpacking libcufile-dev-11-8 (1.4.0.31-1) ...\n","Selecting previously unselected package libcurand-dev-11-8.\n","Preparing to unpack .../054-libcurand-dev-11-8_10.3.0.86-1_amd64.deb ...\n","Unpacking libcurand-dev-11-8 (10.3.0.86-1) ...\n","Selecting previously unselected package libcusolver-dev-11-8.\n","Preparing to unpack .../055-libcusolver-dev-11-8_11.4.1.48-1_amd64.deb ...\n","Unpacking libcusolver-dev-11-8 (11.4.1.48-1) ...\n","Selecting previously unselected package libcusparse-dev-11-8.\n","Preparing to unpack .../056-libcusparse-dev-11-8_11.7.5.86-1_amd64.deb ...\n","Unpacking libcusparse-dev-11-8 (11.7.5.86-1) ...\n","Selecting previously unselected package libnpp-dev-11-8.\n","Preparing to unpack .../057-libnpp-dev-11-8_11.8.0.86-1_amd64.deb ...\n","Unpacking libnpp-dev-11-8 (11.8.0.86-1) ...\n","Selecting previously unselected package libnvjpeg-dev-11-8.\n","Preparing to unpack .../058-libnvjpeg-dev-11-8_11.9.0.86-1_amd64.deb ...\n","Unpacking libnvjpeg-dev-11-8 (11.9.0.86-1) ...\n","Selecting previously unselected package cuda-libraries-dev-11-8.\n","Preparing to unpack .../059-cuda-libraries-dev-11-8_11.8.0-1_amd64.deb ...\n","Unpacking cuda-libraries-dev-11-8 (11.8.0-1) ...\n","Selecting previously unselected package cuda-cupti-11-8.\n","Preparing to unpack .../060-cuda-cupti-11-8_11.8.87-1_amd64.deb ...\n","Unpacking cuda-cupti-11-8 (11.8.87-1) ...\n","Selecting previously unselected package cuda-cupti-dev-11-8.\n","Preparing to unpack .../061-cuda-cupti-dev-11-8_11.8.87-1_amd64.deb ...\n","Unpacking cuda-cupti-dev-11-8 (11.8.87-1) ...\n","Selecting previously unselected package cuda-nvdisasm-11-8.\n","Preparing to unpack .../062-cuda-nvdisasm-11-8_11.8.86-1_amd64.deb ...\n","Unpacking cuda-nvdisasm-11-8 (11.8.86-1) ...\n","Selecting previously unselected package cuda-gdb-11-8.\n","Preparing to unpack .../063-cuda-gdb-11-8_11.8.86-1_amd64.deb ...\n","Unpacking cuda-gdb-11-8 (11.8.86-1) ...\n","Selecting previously unselected package cuda-memcheck-11-8.\n","Preparing to unpack .../064-cuda-memcheck-11-8_11.8.86-1_amd64.deb ...\n","Unpacking cuda-memcheck-11-8 (11.8.86-1) ...\n","Selecting previously unselected package cuda-nvprof-11-8.\n","Preparing to unpack .../065-cuda-nvprof-11-8_11.8.87-1_amd64.deb ...\n","Unpacking cuda-nvprof-11-8 (11.8.87-1) ...\n","Selecting previously unselected package cuda-nvtx-11-8.\n","Preparing to unpack .../066-cuda-nvtx-11-8_11.8.86-1_amd64.deb ...\n","Unpacking cuda-nvtx-11-8 (11.8.86-1) ...\n","Selecting previously unselected package cuda-sanitizer-11-8.\n","Preparing to unpack .../067-cuda-sanitizer-11-8_11.8.86-1_amd64.deb ...\n","Unpacking cuda-sanitizer-11-8 (11.8.86-1) ...\n","Selecting previously unselected package cuda-command-line-tools-11-8.\n","Preparing to unpack .../068-cuda-command-line-tools-11-8_11.8.0-1_amd64.deb ...\n","Unpacking cuda-command-line-tools-11-8 (11.8.0-1) ...\n","Selecting previously unselected package nsight-compute-2022.3.0.\n","Preparing to unpack .../069-nsight-compute-2022.3.0_2022.3.0.22-1_amd64.deb ...\n","Unpacking nsight-compute-2022.3.0 (2022.3.0.22-1) ...\n","Selecting previously unselected package cuda-nsight-compute-11-8.\n","Preparing to unpack .../070-cuda-nsight-compute-11-8_11.8.0-1_amd64.deb ...\n","Unpacking cuda-nsight-compute-11-8 (11.8.0-1) ...\n","Selecting previously unselected package libtinfo5:amd64.\n","Preparing to unpack .../071-libtinfo5_6.3-2ubuntu0.1_amd64.deb ...\n","Unpacking libtinfo5:amd64 (6.3-2ubuntu0.1) ...\n","Selecting previously unselected package libxcb-xinerama0:amd64.\n","Preparing to unpack .../072-libxcb-xinerama0_1.14-3ubuntu3_amd64.deb ...\n","Unpacking libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n","Selecting previously unselected package libxcb-icccm4:amd64.\n","Preparing to unpack .../073-libxcb-icccm4_0.4.1-1.1build2_amd64.deb ...\n","Unpacking libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n","Selecting previously unselected package libxcb-util1:amd64.\n","Preparing to unpack .../074-libxcb-util1_0.4.0-1build2_amd64.deb ...\n","Unpacking libxcb-util1:amd64 (0.4.0-1build2) ...\n","Selecting previously unselected package libxcb-image0:amd64.\n","Preparing to unpack .../075-libxcb-image0_0.4.0-2_amd64.deb ...\n","Unpacking libxcb-image0:amd64 (0.4.0-2) ...\n","Selecting previously unselected package libxcb-keysyms1:amd64.\n","Preparing to unpack .../076-libxcb-keysyms1_0.4.0-1build3_amd64.deb ...\n","Unpacking libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n","Selecting previously unselected package libxcb-render-util0:amd64.\n","Preparing to unpack .../077-libxcb-render-util0_0.3.9-1build3_amd64.deb ...\n","Unpacking libxcb-render-util0:amd64 (0.3.9-1build3) ...\n","Selecting previously unselected package libxcb-xkb1:amd64.\n","Preparing to unpack .../078-libxcb-xkb1_1.14-3ubuntu3_amd64.deb ...\n","Unpacking libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n","Selecting previously unselected package libxkbcommon-x11-0:amd64.\n","Preparing to unpack .../079-libxkbcommon-x11-0_1.4.0-1_amd64.deb ...\n","Unpacking libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libxcb-xinput0:amd64.\n","Preparing to unpack .../080-libxcb-xinput0_1.14-3ubuntu3_amd64.deb ...\n","Unpacking libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n","Selecting previously unselected package nsight-systems-2022.4.2.\n","Preparing to unpack .../081-nsight-systems-2022.4.2_2022.4.2.50-32196742v0_amd64.deb ...\n","Unpacking nsight-systems-2022.4.2 (2022.4.2.50-32196742v0) ...\n","Selecting previously unselected package cuda-nsight-systems-11-8.\n","Preparing to unpack .../082-cuda-nsight-systems-11-8_11.8.0-1_amd64.deb ...\n","Unpacking cuda-nsight-systems-11-8 (11.8.0-1) ...\n","Selecting previously unselected package default-jre-headless.\n","Preparing to unpack .../083-default-jre-headless_2%3a1.11-72build2_amd64.deb ...\n","Unpacking default-jre-headless (2:1.11-72build2) ...\n","Selecting previously unselected package libxtst6:amd64.\n","Preparing to unpack .../084-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n","Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n","Selecting previously unselected package openjdk-11-jre:amd64.\n","Preparing to unpack .../085-openjdk-11-jre_11.0.22+7-0ubuntu2~22.04.1_amd64.deb ...\n","Unpacking openjdk-11-jre:amd64 (11.0.22+7-0ubuntu2~22.04.1) ...\n","Selecting previously unselected package default-jre.\n","Preparing to unpack .../086-default-jre_2%3a1.11-72build2_amd64.deb ...\n","Unpacking default-jre (2:1.11-72build2) ...\n","Selecting previously unselected package cuda-nsight-11-8.\n","Preparing to unpack .../087-cuda-nsight-11-8_11.8.86-1_amd64.deb ...\n","Unpacking cuda-nsight-11-8 (11.8.86-1) ...\n","Selecting previously unselected package cuda-nvml-dev-11-8.\n","Preparing to unpack .../088-cuda-nvml-dev-11-8_11.8.86-1_amd64.deb ...\n","Unpacking cuda-nvml-dev-11-8 (11.8.86-1) ...\n","Selecting previously unselected package cuda-nvvp-11-8.\n","Preparing to unpack .../089-cuda-nvvp-11-8_11.8.87-1_amd64.deb ...\n","Unpacking cuda-nvvp-11-8 (11.8.87-1) ...\n","Selecting previously unselected package cuda-visual-tools-11-8.\n","Preparing to unpack .../090-cuda-visual-tools-11-8_11.8.0-1_amd64.deb ...\n","Unpacking cuda-visual-tools-11-8 (11.8.0-1) ...\n","Selecting previously unselected package gds-tools-11-8.\n","Preparing to unpack .../091-gds-tools-11-8_1.4.0.31-1_amd64.deb ...\n","Unpacking gds-tools-11-8 (1.4.0.31-1) ...\n","Selecting previously unselected package cuda-tools-11-8.\n","Preparing to unpack .../092-cuda-tools-11-8_11.8.0-1_amd64.deb ...\n","Unpacking cuda-tools-11-8 (11.8.0-1) ...\n","Selecting previously unselected package cuda-documentation-11-8.\n","Preparing to unpack .../093-cuda-documentation-11-8_11.8.86-1_amd64.deb ...\n","Unpacking cuda-documentation-11-8 (11.8.86-1) ...\n","Selecting previously unselected package cuda-toolkit-11-8.\n","Preparing to unpack .../094-cuda-toolkit-11-8_11.8.0-1_amd64.deb ...\n","Unpacking cuda-toolkit-11-8 (11.8.0-1) ...\n","Selecting previously unselected package cuda-demo-suite-11-8.\n","Preparing to unpack .../095-cuda-demo-suite-11-8_11.8.86-1_amd64.deb ...\n","Unpacking cuda-demo-suite-11-8 (11.8.86-1) ...\n","Selecting previously unselected package cuda-11-8.\n","Preparing to unpack .../096-cuda-11-8_11.8.0-1_amd64.deb ...\n","Unpacking cuda-11-8 (11.8.0-1) ...\n","Selecting previously unselected package libfakeroot:amd64.\n","Preparing to unpack .../097-libfakeroot_1.28-1ubuntu1_amd64.deb ...\n","Unpacking libfakeroot:amd64 (1.28-1ubuntu1) ...\n","Selecting previously unselected package fakeroot.\n","Preparing to unpack .../098-fakeroot_1.28-1ubuntu1_amd64.deb ...\n","Unpacking fakeroot (1.28-1ubuntu1) ...\n","Selecting previously unselected package fonts-dejavu-core.\n","Preparing to unpack .../099-fonts-dejavu-core_2.37-2build1_all.deb ...\n","Unpacking fonts-dejavu-core (2.37-2build1) ...\n","Selecting previously unselected package fonts-dejavu-extra.\n","Preparing to unpack .../100-fonts-dejavu-extra_2.37-2build1_all.deb ...\n","Unpacking fonts-dejavu-extra (2.37-2build1) ...\n","Selecting previously unselected package libxxf86dga1:amd64.\n","Preparing to unpack .../101-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n","Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n","Selecting previously unselected package x11-utils.\n","Preparing to unpack .../102-x11-utils_7.7+5build2_amd64.deb ...\n","Unpacking x11-utils (7.7+5build2) ...\n","Selecting previously unselected package libatk-wrapper-java.\n","Preparing to unpack .../103-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n","Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n","Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n","Preparing to unpack .../104-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n","Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n","Selecting previously unselected package nvidia-prime.\n","Preparing to unpack .../105-nvidia-prime_0.8.17.1_all.deb ...\n","Unpacking nvidia-prime (0.8.17.1) ...\n","Selecting previously unselected package python3-xkit.\n","Preparing to unpack .../106-python3-xkit_0.5.0ubuntu5_all.deb ...\n","Unpacking python3-xkit (0.5.0ubuntu5) ...\n","Selecting previously unselected package screen-resolution-extra.\n","Preparing to unpack .../107-screen-resolution-extra_0.18.2_all.deb ...\n","Unpacking screen-resolution-extra (0.18.2) ...\n","Selecting previously unselected package nvidia-settings.\n","Preparing to unpack .../108-nvidia-settings_550.54.14-0ubuntu1_amd64.deb ...\n","Unpacking nvidia-settings (550.54.14-0ubuntu1) ...\n","Selecting previously unselected package systemd-hwe-hwdb.\n","Preparing to unpack .../109-systemd-hwe-hwdb_249.11.5_all.deb ...\n","Unpacking systemd-hwe-hwdb (249.11.5) ...\n","Selecting previously unselected package xcvt.\n","Preparing to unpack .../110-xcvt_0.1.1-3_amd64.deb ...\n","Unpacking xcvt (0.1.1-3) ...\n","Selecting previously unselected package xfonts-encodings.\n","Preparing to unpack .../111-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n","Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n","Selecting previously unselected package xfonts-utils.\n","Preparing to unpack .../112-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n","Unpacking xfonts-utils (1:7.7+6build2) ...\n","Selecting previously unselected package xfonts-base.\n","Preparing to unpack .../113-xfonts-base_1%3a1.0.5_all.deb ...\n","Unpacking xfonts-base (1:1.0.5) ...\n","Setting up cpp-12 (12.3.0-1ubuntu1~22.04) ...\n","Setting up cuda-nvml-dev-11-8 (11.8.86-1) ...\n","Setting up default-jre-headless (2:1.11-72build2) ...\n","Setting up cuda-toolkit-11-config-common (11.8.89-1) ...\n","Setting up libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n","Setting up cuda-cccl-11-8 (11.8.89-1) ...\n","Setting up cuda-cuobjdump-11-8 (11.8.86-1) ...\n","Setting up cuda-nvrtc-11-8 (11.8.89-1) ...\n","Setting up cuda-sanitizer-11-8 (11.8.86-1) ...\n","Setting up libnvidia-compute-550:amd64 (550.54.14-0ubuntu1) ...\n","Setting up nvidia-prime (0.8.17.1) ...\n","Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n","Setting up nvidia-firmware-550-550.54.14 (550.54.14-0ubuntu1) ...\n","Setting up libnvidia-common-550 (550.54.14-0ubuntu1) ...\n","Setting up cuda-cupti-11-8 (11.8.87-1) ...\n","Setting up libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n","Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n","Setting up libxcb-render-util0:amd64 (0.3.9-1build3) ...\n","Setting up nvidia-utils-550 (550.54.14-0ubuntu1) ...\n","Setting up openjdk-11-jre:amd64 (11.0.22+7-0ubuntu2~22.04.1) ...\n","Setting up cuda-nvdisasm-11-8 (11.8.86-1) ...\n","Setting up libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n","Setting up default-jre (2:1.11-72build2) ...\n","Setting up cuda-cuxxfilt-11-8 (11.8.86-1) ...\n","Setting up libnvidia-fbc1-550:amd64 (550.54.14-0ubuntu1) ...\n","Setting up libnvidia-cfg1-550:amd64 (550.54.14-0ubuntu1) ...\n","Setting up nvidia-compute-utils-550 (550.54.14-0ubuntu1) ...\n","Warning: The home dir /nonexistent you specified can't be accessed: No such file or directory\n","Adding system user `nvidia-persistenced' (UID 104) ...\n","Adding new group `nvidia-persistenced' (GID 107) ...\n","Adding new user `nvidia-persistenced' (UID 104) with group `nvidia-persistenced' ...\n","Not creating home directory `/nonexistent'.\n","Setting up libfakeroot:amd64 (1.28-1ubuntu1) ...\n","Setting up libxcb-util1:amd64 (0.4.0-1build2) ...\n","Setting up libjansson4:amd64 (2.13.1-1.1build3) ...\n","Setting up libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n","Setting up libxcb-image0:amd64 (0.4.0-2) ...\n","Setting up fakeroot (1.28-1ubuntu1) ...\n","update-alternatives: using /usr/bin/fakeroot-sysv to provide /usr/bin/fakeroot (fakeroot) in auto mode\n","Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n","Setting up libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n","Setting up cuda-nvvp-11-8 (11.8.87-1) ...\n","Setting up cuda-nvtx-11-8 (11.8.86-1) ...\n","Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n","Setting up cuda-gdb-11-8 (11.8.86-1) ...\n","Setting up cuda-toolkit-11-8-config-common (11.8.89-1) ...\n","Setting alternatives\n","update-alternatives: using /usr/local/cuda-11.8 to provide /usr/local/cuda-11 (cuda-11) in auto mode\n","Setting up libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n","Setting up udev (249.11-0ubuntu3.12) ...\n","invoke-rc.d: could not determine current runlevel\n","invoke-rc.d: policy-rc.d denied execution of start.\n","Setting up libcusolver-11-8 (11.4.1.48-1) ...\n","Setting up cuda-nvrtc-dev-11-8 (11.8.89-1) ...\n","Setting up fonts-dejavu-core (2.37-2build1) ...\n","Setting up cuda-driver-dev-11-8 (11.8.89-1) ...\n","Setting up systemd-hwe-hwdb (249.11.5) ...\n","Setting up cuda-memcheck-11-8 (11.8.86-1) ...\n","Setting up libnvidia-gl-550:amd64 (550.54.14-0ubuntu1) ...\n","Setting up nvidia-kernel-common-550 (550.54.14-0ubuntu1) ...\n","Created symlink /etc/systemd/system/systemd-hibernate.service.wants/nvidia-hibernate.service → /lib/systemd/system/nvidia-hibernate.service.\n","Created symlink /etc/systemd/system/systemd-suspend.service.wants/nvidia-resume.service → /lib/systemd/system/nvidia-resume.service.\n","Created symlink /etc/systemd/system/systemd-hibernate.service.wants/nvidia-resume.service → /lib/systemd/system/nvidia-resume.service.\n","Created symlink /etc/systemd/system/systemd-suspend.service.wants/nvidia-suspend.service → /lib/systemd/system/nvidia-suspend.service.\n","Setting up fonts-dejavu-extra (2.37-2build1) ...\n","Setting up gds-tools-11-8 (1.4.0.31-1) ...\n","Setting up libnvidia-extra-550:amd64 (550.54.14-0ubuntu1) ...\n","Setting up cuda-nsight-11-8 (11.8.86-1) ...\n","Setting up cuda-profiler-api-11-8 (11.8.86-1) ...\n","Setting up libasan8:amd64 (12.3.0-1ubuntu1~22.04) ...\n","Setting up libxcvt0:amd64 (0.1.1-3) ...\n","Setting up nvidia-kernel-source-550 (550.54.14-0ubuntu1) ...\n","Setting up cuda-documentation-11-8 (11.8.86-1) ...\n","Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n","Setting up libtsan2:amd64 (12.3.0-1ubuntu1~22.04) ...\n","Setting up python3-xkit (0.5.0ubuntu5) ...\n","Setting up libtinfo5:amd64 (6.3-2ubuntu0.1) ...\n","Setting up cuda-nvprune-11-8 (11.8.86-1) ...\n","Setting up cuda-cudart-11-8 (11.8.89-1) ...\n","Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n","Setting up libnvjpeg-11-8 (11.9.0.86-1) ...\n","Setting up liblocale-gettext-perl (1.07-4build3) ...\n","Setting up dctrl-tools (2.24-3build2) ...\n","Setting up cuda-nvprof-11-8 (11.8.87-1) ...\n","Setting up nsight-compute-2022.3.0 (2022.3.0.22-1) ...\n","Setting up nsight-systems-2022.4.2 (2022.4.2.50-32196742v0) ...\n","update-alternatives: using /opt/nvidia/nsight-systems/2022.4.2/target-linux-x64/nsys to provide /usr/local/bin/nsys (nsys) in auto mode\n","update-alternatives: using /opt/nvidia/nsight-systems/2022.4.2/host-linux-x64/nsys-ui to provide /usr/local/bin/nsys-ui (nsys-ui) in auto mode\n","Setting up libcusparse-11-8 (11.7.5.86-1) ...\n","Setting up libnvidia-decode-550:amd64 (550.54.14-0ubuntu1) ...\n","Setting up libcufft-11-8 (10.9.0.58-1) ...\n","Setting up cuda-cupti-dev-11-8 (11.8.87-1) ...\n","Setting up libcufft-dev-11-8 (10.9.0.58-1) ...\n","Setting up cuda-cudart-dev-11-8 (11.8.89-1) ...\n","Setting up x11-xkb-utils (7.7+5build4) ...\n","Setting up libnpp-11-8 (11.8.0.86-1) ...\n","Setting up libcusolver-dev-11-8 (11.4.1.48-1) ...\n","Setting up xfonts-utils (1:7.7+6build2) ...\n","Setting up libnvidia-encode-550:amd64 (550.54.14-0ubuntu1) ...\n","Setting up xcvt (0.1.1-3) ...\n","Setting up cuda-nsight-systems-11-8 (11.8.0-1) ...\n","Setting up cuda-command-line-tools-11-8 (11.8.0-1) ...\n","Setting up libcusparse-dev-11-8 (11.7.5.86-1) ...\n","Setting up xfonts-base (1:1.0.5) ...\n","Setting up libcurand-11-8 (10.3.0.86-1) ...\n","Setting up libcufile-11-8 (1.4.0.31-1) ...\n","Setting alternatives\n","Setting up libcublas-11-8 (11.11.3.6-1) ...\n","Setting up libnpp-dev-11-8 (11.8.0.86-1) ...\n","Setting up libgcc-12-dev:amd64 (12.3.0-1ubuntu1~22.04) ...\n","Setting up cuda-libraries-11-8 (11.8.0-1) ...\n","Setting up cuda-nsight-compute-11-8 (11.8.0-1) ...\n","Setting up screen-resolution-extra (0.18.2) ...\n","Setting up x11-utils (7.7+5build2) ...\n","Setting up nvidia-settings (550.54.14-0ubuntu1) ...\n","Setting up libnvjpeg-dev-11-8 (11.9.0.86-1) ...\n","Setting up libatk-wrapper-java (0.38.0-5build1) ...\n","Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.8) ...\n","Setting up keyboard-configuration (1.205ubuntu3) ...\n","Your console font configuration will be updated the next time your system\n","boots. If you want to update it now, run 'setupcon' from a virtual console.\n","Setting up cuda-nvcc-11-8 (11.8.89-1) ...\n","Setting up xserver-xorg-core (2:21.1.4-2ubuntu1.7~22.04.8) ...\n","Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n","Setting up libcublas-dev-11-8 (11.11.3.6-1) ...\n","Setting up libcurand-dev-11-8 (10.3.0.86-1) ...\n","Setting up libcufile-dev-11-8 (1.4.0.31-1) ...\n","Setting up gcc-12 (12.3.0-1ubuntu1~22.04) ...\n","Setting up cuda-compiler-11-8 (11.8.0-1) ...\n","Setting up xserver-xorg-video-nvidia-550 (550.54.14-0ubuntu1) ...\n","Setting up cuda-libraries-dev-11-8 (11.8.0-1) ...\n","Setting up dkms (2.8.7-2ubuntu2.2) ...\n","Setting up cuda-visual-tools-11-8 (11.8.0-1) ...\n","Setting up cuda-tools-11-8 (11.8.0-1) ...\n","Setting up nvidia-dkms-550 (550.54.14-0ubuntu1) ...\n","Loading new nvidia-550.54.14 DKMS files...\n","It is likely that 6.1.58+ belongs to a chroot's host\n","Building for 5.15.0-100-generic\n","Building for architecture x86_64\n","Building initial module for 5.15.0-100-generic\n","Done.\n","\n","nvidia.ko:\n","Running module version sanity check.\n"," - Original module\n","   - No original module exists within this kernel\n"," - Installation\n","   - Installing to /lib/modules/5.15.0-100-generic/updates/dkms/\n","\n","nvidia-modeset.ko:\n","Running module version sanity check.\n"," - Original module\n","   - No original module exists within this kernel\n"," - Installation\n","   - Installing to /lib/modules/5.15.0-100-generic/updates/dkms/\n","\n","nvidia-drm.ko:\n","Running module version sanity check.\n"," - Original module\n","   - No original module exists within this kernel\n"," - Installation\n","   - Installing to /lib/modules/5.15.0-100-generic/updates/dkms/\n","\n","nvidia-uvm.ko:\n","Running module version sanity check.\n"," - Original module\n","   - No original module exists within this kernel\n"," - Installation\n","   - Installing to /lib/modules/5.15.0-100-generic/updates/dkms/\n","\n","nvidia-peermem.ko:\n","Running module version sanity check.\n"," - Original module\n","   - No original module exists within this kernel\n"," - Installation\n","   - Installing to /lib/modules/5.15.0-100-generic/updates/dkms/\n","\n","depmod...\n","Setting up nvidia-driver-550 (550.54.14-0ubuntu1) ...\n","Setting up cuda-toolkit-11-8 (11.8.0-1) ...\n","Setting alternatives\n","Setting up cuda-drivers-550 (550.54.14-1) ...\n","Setting up cuda-drivers (550.54.14-1) ...\n","Setting up cuda-runtime-11-8 (11.8.0-1) ...\n","Setting up cuda-demo-suite-11-8 (11.8.86-1) ...\n","Setting up cuda-11-8 (11.8.0-1) ...\n","Processing triggers for hicolor-icon-theme (0.17-2) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n"]}],"source":["display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 100})'''))\n","!sudo DEBIAN_FRONTEND=noninteractive apt-get install cuda-11-8\n"]},{"cell_type":"markdown","metadata":{"id":"cdLMR00gYX2N"},"source":["バージョン変更"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"yy7be3hLFcdW","executionInfo":{"status":"ok","timestamp":1710823549649,"user_tz":-540,"elapsed":6,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}}},"outputs":[],"source":["import os\n","p = os.getenv('PATH')\n","ld = os.getenv('LD_LIBRARY_PATH')\n","os.environ['PATH'] = f\"/usr/local/cuda-11.8/bin:{p}\"\n","os.environ['LD_LIBRARY_PATH'] = f\"/usr/local/cuda-11.8/lib64:{ld}\""]},{"cell_type":"markdown","metadata":{"id":"T051w8D5HiNE"},"source":["変更後のCUDAバージョン確認。11.8になっていればOK"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"067ytXl4FyWL","executionInfo":{"status":"ok","timestamp":1710823550231,"user_tz":-540,"elapsed":587,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}},"outputId":"1c64d9f8-91e3-462d-ad37-fb2b2e9658ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/cuda-11  /usr/local/cuda-11.8  /usr/local/cuda-12  /usr/local/cuda-12.2\n","nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2022 NVIDIA Corporation\n","Built on Wed_Sep_21_10:33:58_PDT_2022\n","Cuda compilation tools, release 11.8, V11.8.89\n","Build cuda_11.8.r11.8/compiler.31833905_0\n"]}],"source":["!ls -d /usr/local/cuda-*\n","!nvcc --version"]},{"cell_type":"markdown","metadata":{"id":"QXwr0Yt_wLYd"},"source":["### Python 3.11をインストール。"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":100},"id":"Ln6cN1rRpKdX","executionInfo":{"status":"ok","timestamp":1710823584057,"user_tz":-540,"elapsed":33830,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}},"outputId":"285d20e9-ba36-46a8-8e88-cbf8384dad3a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["google.colab.output.setIframeHeight(0, true, {maxHeight: 100})"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n","Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [770 kB]\n","Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n","Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n","Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n","Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Get:9 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,080 kB]\n","Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n","Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,570 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,883 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,056 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,354 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.3 kB]\n","Fetched 9,090 kB in 4s (2,096 kB/s)\n","Reading package lists... Done\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","Note, selecting 'python3-distutils' instead of 'python3.11-distutils'\n","python3-distutils is already the newest version (3.10.8-1~22.04).\n","The following additional packages will be installed:\n","  libpython3.11 libpython3.11-minimal libpython3.11-stdlib mailcap\n","  mime-support python3.11-minimal\n","Suggested packages:\n","  python3.11-venv binfmt-support\n","The following NEW packages will be installed:\n","  libpython3.11 libpython3.11-dev libpython3.11-minimal libpython3.11-stdlib\n","  mailcap mime-support python3.11 python3.11-dev python3.11-minimal\n","0 upgraded, 9 newly installed, 0 to remove and 62 not upgraded.\n","Need to get 13.8 MB of archives.\n","After this operation, 55.5 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 mailcap all 3.70+nmu1ubuntu1 [23.8 kB]\n","Get:2 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.11-minimal amd64 3.11.8-1+jammy2 [883 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 mime-support all 3.66 [3,696 B]\n","Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.11-minimal amd64 3.11.8-1+jammy2 [2,346 kB]\n","Get:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.11-stdlib amd64 3.11.8-1+jammy2 [1,923 kB]\n","Get:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.11 amd64 3.11.8-1+jammy2 [2,215 kB]\n","Get:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.11-dev amd64 3.11.8-1+jammy2 [5,308 kB]\n","Get:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.11 amd64 3.11.8-1+jammy2 [636 kB]\n","Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.11-dev amd64 3.11.8-1+jammy2 [500 kB]\n","Fetched 13.8 MB in 23s (599 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 9.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package libpython3.11-minimal:amd64.\n","(Reading database ... 129058 files and directories currently installed.)\n","Preparing to unpack .../0-libpython3.11-minimal_3.11.8-1+jammy2_amd64.deb ...\n","Unpacking libpython3.11-minimal:amd64 (3.11.8-1+jammy2) ...\n","Selecting previously unselected package python3.11-minimal.\n","Preparing to unpack .../1-python3.11-minimal_3.11.8-1+jammy2_amd64.deb ...\n","Unpacking python3.11-minimal (3.11.8-1+jammy2) ...\n","Selecting previously unselected package mailcap.\n","Preparing to unpack .../2-mailcap_3.70+nmu1ubuntu1_all.deb ...\n","Unpacking mailcap (3.70+nmu1ubuntu1) ...\n","Selecting previously unselected package mime-support.\n","Preparing to unpack .../3-mime-support_3.66_all.deb ...\n","Unpacking mime-support (3.66) ...\n","Selecting previously unselected package libpython3.11-stdlib:amd64.\n","Preparing to unpack .../4-libpython3.11-stdlib_3.11.8-1+jammy2_amd64.deb ...\n","Unpacking libpython3.11-stdlib:amd64 (3.11.8-1+jammy2) ...\n","Selecting previously unselected package libpython3.11:amd64.\n","Preparing to unpack .../5-libpython3.11_3.11.8-1+jammy2_amd64.deb ...\n","Unpacking libpython3.11:amd64 (3.11.8-1+jammy2) ...\n","Selecting previously unselected package libpython3.11-dev:amd64.\n","Preparing to unpack .../6-libpython3.11-dev_3.11.8-1+jammy2_amd64.deb ...\n","Unpacking libpython3.11-dev:amd64 (3.11.8-1+jammy2) ...\n","Selecting previously unselected package python3.11.\n","Preparing to unpack .../7-python3.11_3.11.8-1+jammy2_amd64.deb ...\n","Unpacking python3.11 (3.11.8-1+jammy2) ...\n","Selecting previously unselected package python3.11-dev.\n","Preparing to unpack .../8-python3.11-dev_3.11.8-1+jammy2_amd64.deb ...\n","Unpacking python3.11-dev (3.11.8-1+jammy2) ...\n","Setting up libpython3.11-minimal:amd64 (3.11.8-1+jammy2) ...\n","Setting up mailcap (3.70+nmu1ubuntu1) ...\n","Setting up python3.11-minimal (3.11.8-1+jammy2) ...\n","Setting up mime-support (3.66) ...\n","Setting up libpython3.11-stdlib:amd64 (3.11.8-1+jammy2) ...\n","Setting up python3.11 (3.11.8-1+jammy2) ...\n","Setting up libpython3.11:amd64 (3.11.8-1+jammy2) ...\n","Setting up libpython3.11-dev:amd64 (3.11.8-1+jammy2) ...\n","Setting up python3.11-dev (3.11.8-1+jammy2) ...\n","Processing triggers for man-db (2.10.2-1) ...\n"]}],"source":["display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 100})'''))\n","!sudo apt-get update -y\n","!sudo apt-get install python3.11 python3.11-dev python3.11-distutils libpython3.11-dev"]},{"cell_type":"markdown","metadata":{"id":"FEvIRCGUwRZ1"},"source":["Python 3.11の優先度(2)を3.10の優先度(1)より高く設定。"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12FmEK2hpaxz","executionInfo":{"status":"ok","timestamp":1710823584057,"user_tz":-540,"elapsed":8,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}},"outputId":"fdc64b6c-9ab4-4085-eb7d-5a2f2871745c"},"outputs":[{"output_type":"stream","name":"stdout","text":["update-alternatives: using /usr/bin/python3.10 to provide /usr/bin/python3 (python3) in auto mode\n","update-alternatives: using /usr/bin/python3.11 to provide /usr/bin/python3 (python3) in auto mode\n"]}],"source":["!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1\n","!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 2"]},{"cell_type":"markdown","source":["### Python"],"metadata":{"id":"mzNdYd0ClXhY"}},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1710823584057,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"},"user_tz":-540},"id":"z7-tEaGtqPSd","outputId":"4b148e06-eccb-476f-d68d-a0c38772ceff"},"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.11.8\n"]}],"source":["!python --version"]},{"cell_type":"code","source":["display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 100})'''))\n","!sudo apt install python3-pip\n","!pip install --upgrade pip setuptools wheel"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":100},"id":"liWs8_EAUvRe","executionInfo":{"status":"ok","timestamp":1710823595122,"user_tz":-540,"elapsed":11067,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}},"outputId":"c0e26ad4-f326-4c17-dbd1-9c2044479c64"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["google.colab.output.setIframeHeight(0, true, {maxHeight: 100})"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  python3-setuptools python3-wheel\n","Suggested packages:\n","  python-setuptools-doc\n","The following NEW packages will be installed:\n","  python3-pip python3-setuptools python3-wheel\n","0 upgraded, 3 newly installed, 0 to remove and 62 not upgraded.\n","Need to get 1,677 kB of archives.\n","After this operation, 8,967 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-setuptools all 59.6.0-1.2ubuntu0.22.04.1 [339 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-wheel all 0.37.1-2ubuntu0.22.04.1 [32.0 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip all 22.0.2+dfsg-1ubuntu0.4 [1,305 kB]\n","Fetched 1,677 kB in 2s (858 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package python3-setuptools.\n","(Reading database ... 129992 files and directories currently installed.)\n","Preparing to unpack .../python3-setuptools_59.6.0-1.2ubuntu0.22.04.1_all.deb ...\n","Unpacking python3-setuptools (59.6.0-1.2ubuntu0.22.04.1) ...\n","Selecting previously unselected package python3-wheel.\n","Preparing to unpack .../python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\n","Unpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n","Selecting previously unselected package python3-pip.\n","Preparing to unpack .../python3-pip_22.0.2+dfsg-1ubuntu0.4_all.deb ...\n","Unpacking python3-pip (22.0.2+dfsg-1ubuntu0.4) ...\n","Setting up python3-setuptools (59.6.0-1.2ubuntu0.22.04.1) ...\n","Setting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n","Setting up python3-pip (22.0.2+dfsg-1ubuntu0.4) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Requirement already satisfied: pip in /usr/lib/python3/dist-packages (22.0.2)\n","Collecting pip\n","  Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (59.6.0)\n","Collecting setuptools\n","  Downloading setuptools-69.2.0-py3-none-any.whl (821 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.5/821.5 KB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wheel in /usr/lib/python3/dist-packages (0.37.1)\n","Collecting wheel\n","  Downloading wheel-0.43.0-py3-none-any.whl (65 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: wheel, setuptools, pip\n","  Attempting uninstall: wheel\n","    Found existing installation: wheel 0.37.1\n","    Not uninstalling wheel at /usr/lib/python3/dist-packages, outside environment /usr\n","    Can't uninstall 'wheel'. No files were found to uninstall.\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 59.6.0\n","    Not uninstalling setuptools at /usr/lib/python3/dist-packages, outside environment /usr\n","    Can't uninstall 'setuptools'. No files were found to uninstall.\n","  Attempting uninstall: pip\n","    Found existing installation: pip 22.0.2\n","    Not uninstalling pip at /usr/lib/python3/dist-packages, outside environment /usr\n","    Can't uninstall 'pip'. No files were found to uninstall.\n","Successfully installed pip-24.0 setuptools-69.2.0 wheel-0.43.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"markdown","metadata":{"id":"a-eDjIJ59yfy"},"source":["## Preprocessingは省略（Trainingではデフォルトのarxivデータを使う。）"]},{"cell_type":"markdown","metadata":{"id":"7jX4sMma93w0"},"source":["## Training"]},{"cell_type":"markdown","source":["### 準備"],"metadata":{"id":"owsDiSCj2_yK"}},{"cell_type":"markdown","metadata":{"id":"JBGiWj5lO25L"},"source":["venv部分は省略"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1710823595123,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"},"user_tz":-540},"id":"I8FinlXd9Vtt","outputId":"7fbf585a-e77e-4e99-f8d7-1d19c141fdf2"},"outputs":[{"output_type":"stream","name":"stdout","text":["/root/moe-recipes\n"]}],"source":["%cd ~/moe-recipes"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1710823595123,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"},"user_tz":-540},"id":"BoqXPX2L-f2H","outputId":"7b4834ae-727d-4866-a840-8b1bb45a88bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/bin/python\n","====\n","Python 3.11.8\n"]}],"source":["!which python && echo \"====\" && python --version"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1710823595123,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"},"user_tz":-540},"id":"9r4kMH3m-f4x","outputId":"4ff5802b-e80e-4260-fde2-f067738a7866"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/cuda-11.8/bin/nvcc\n","====\n","nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2022 NVIDIA Corporation\n","Built on Wed_Sep_21_10:33:58_PDT_2022\n","Cuda compilation tools, release 11.8, V11.8.89\n","Build cuda_11.8.r11.8/compiler.31833905_0\n"]}],"source":["!which nvcc && echo \"====\" && nvcc --version #11.8であることを確認"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":100},"id":"3OK54wFSATYU","executionInfo":{"status":"ok","timestamp":1710824055659,"user_tz":-540,"elapsed":460543,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}},"outputId":"1e24e7f2-fd85-48b6-cdea-aff6f0dd64e7"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["google.colab.output.setIframeHeight(0, true, {maxHeight: 100})"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mLooking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==2.1.2+cu118 (from -r requirements.txt (line 2))\n","  Downloading https://download.pytorch.org/whl/cu118/torch-2.1.2%2Bcu118-cp311-cp311-linux_x86_64.whl (2325.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting transformers>=4.35.0 (from -r requirements.txt (line 5))\n","  Downloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.7/130.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets (from -r requirements.txt (line 6))\n","  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n","Collecting accelerate (from -r requirements.txt (line 7))\n","  Downloading accelerate-0.28.0-py3-none-any.whl.metadata (18 kB)\n","Collecting optimum (from -r requirements.txt (line 8))\n","  Downloading optimum-1.17.1-py3-none-any.whl.metadata (18 kB)\n","Collecting peft (from -r requirements.txt (line 9))\n","  Downloading peft-0.9.0-py3-none-any.whl.metadata (13 kB)\n","Collecting appdirs (from -r requirements.txt (line 11))\n","  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n","Collecting loralib (from -r requirements.txt (line 12))\n","  Downloading loralib-0.1.2-py3-none-any.whl.metadata (15 kB)\n","Collecting scipy (from -r requirements.txt (line 13))\n","  Downloading scipy-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting py7zr (from -r requirements.txt (line 14))\n","  Downloading py7zr-0.21.0-py3-none-any.whl.metadata (17 kB)\n","Collecting bitsandbytes (from -r requirements.txt (line 15))\n","  Downloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl.metadata (1.8 kB)\n","Collecting fire (from -r requirements.txt (line 16))\n","  Downloading fire-0.6.0.tar.gz (88 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting black (from -r requirements.txt (line 19))\n","  Downloading black-24.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting flake8 (from -r requirements.txt (line 20))\n","  Downloading flake8-7.0.0-py2.py3-none-any.whl.metadata (3.8 kB)\n","Collecting sentencepiece (from -r requirements.txt (line 23))\n","  Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n","Collecting wandb (from -r requirements.txt (line 26))\n","  Downloading wandb-0.16.4-py3-none-any.whl.metadata (10 kB)\n","Collecting deepspeed (from -r requirements.txt (line 29))\n","  Downloading deepspeed-0.14.0.tar.gz (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting mpi4py (from -r requirements.txt (line 30))\n","  Downloading mpi4py-3.1.5.tar.gz (2.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting nltk (from -r requirements.txt (line 33))\n","  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n","Collecting pybind11 (from -r requirements.txt (line 34))\n","  Downloading pybind11-2.11.1-py3-none-any.whl.metadata (9.5 kB)\n","Collecting filelock (from torch==2.1.2+cu118->-r requirements.txt (line 2))\n","  Downloading filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n","Collecting typing-extensions (from torch==2.1.2+cu118->-r requirements.txt (line 2))\n","  Downloading typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n","Collecting sympy (from torch==2.1.2+cu118->-r requirements.txt (line 2))\n","  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n","Collecting networkx (from torch==2.1.2+cu118->-r requirements.txt (line 2))\n","  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n","Collecting jinja2 (from torch==2.1.2+cu118->-r requirements.txt (line 2))\n","  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n","Collecting fsspec (from torch==2.1.2+cu118->-r requirements.txt (line 2))\n","  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n","Collecting triton==2.1.0 (from torch==2.1.2+cu118->-r requirements.txt (line 2))\n","  Downloading triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n","Collecting huggingface-hub<1.0,>=0.19.3 (from transformers>=4.35.0->-r requirements.txt (line 5))\n","  Downloading huggingface_hub-0.21.4-py3-none-any.whl.metadata (13 kB)\n","Collecting numpy>=1.17 (from transformers>=4.35.0->-r requirements.txt (line 5))\n","  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting packaging>=20.0 (from transformers>=4.35.0->-r requirements.txt (line 5))\n","  Downloading packaging-24.0-py3-none-any.whl.metadata (3.2 kB)\n","Collecting pyyaml>=5.1 (from transformers>=4.35.0->-r requirements.txt (line 5))\n","  Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n","Collecting regex!=2019.12.17 (from transformers>=4.35.0->-r requirements.txt (line 5))\n","  Downloading regex-2023.12.25-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting requests (from transformers>=4.35.0->-r requirements.txt (line 5))\n","  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n","Collecting tokenizers<0.19,>=0.14 (from transformers>=4.35.0->-r requirements.txt (line 5))\n","  Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Collecting safetensors>=0.4.1 (from transformers>=4.35.0->-r requirements.txt (line 5))\n","  Downloading safetensors-0.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n","Collecting tqdm>=4.27 (from transformers>=4.35.0->-r requirements.txt (line 5))\n","  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyarrow>=12.0.0 (from datasets->-r requirements.txt (line 6))\n","  Downloading pyarrow-15.0.2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n","Collecting pyarrow-hotfix (from datasets->-r requirements.txt (line 6))\n","  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets->-r requirements.txt (line 6))\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Collecting pandas (from datasets->-r requirements.txt (line 6))\n","  Downloading pandas-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n","Collecting xxhash (from datasets->-r requirements.txt (line 6))\n","  Downloading xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess (from datasets->-r requirements.txt (line 6))\n","  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec (from torch==2.1.2+cu118->-r requirements.txt (line 2))\n","  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n","Collecting aiohttp (from datasets->-r requirements.txt (line 6))\n","  Downloading aiohttp-3.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n","Collecting psutil (from accelerate->-r requirements.txt (line 7))\n","  Downloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n","Collecting coloredlogs (from optimum->-r requirements.txt (line 8))\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Collecting texttable (from py7zr->-r requirements.txt (line 14))\n","  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n","Collecting pycryptodomex>=3.16.0 (from py7zr->-r requirements.txt (line 14))\n","  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n","Collecting pyzstd>=0.15.9 (from py7zr->-r requirements.txt (line 14))\n","  Downloading pyzstd-0.15.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n","Collecting pyppmd<1.2.0,>=1.1.0 (from py7zr->-r requirements.txt (line 14))\n","  Downloading pyppmd-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n","Collecting pybcj<1.1.0,>=1.0.0 (from py7zr->-r requirements.txt (line 14))\n","  Downloading pybcj-1.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n","Collecting multivolumefile>=0.2.3 (from py7zr->-r requirements.txt (line 14))\n","  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n","Collecting inflate64<1.1.0,>=1.0.0 (from py7zr->-r requirements.txt (line 14))\n","  Downloading inflate64-1.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n","Collecting brotli>=1.1.0 (from py7zr->-r requirements.txt (line 14))\n","  Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n","Requirement already satisfied: six in /usr/lib/python3/dist-packages (from fire->-r requirements.txt (line 16)) (1.16.0)\n","Collecting termcolor (from fire->-r requirements.txt (line 16))\n","  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n","Collecting click>=8.0.0 (from black->-r requirements.txt (line 19))\n","  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n","Collecting mypy-extensions>=0.4.3 (from black->-r requirements.txt (line 19))\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n","Collecting pathspec>=0.9.0 (from black->-r requirements.txt (line 19))\n","  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n","Collecting platformdirs>=2 (from black->-r requirements.txt (line 19))\n","  Downloading platformdirs-4.2.0-py3-none-any.whl.metadata (11 kB)\n","Collecting mccabe<0.8.0,>=0.7.0 (from flake8->-r requirements.txt (line 20))\n","  Downloading mccabe-0.7.0-py2.py3-none-any.whl.metadata (5.0 kB)\n","Collecting pycodestyle<2.12.0,>=2.11.0 (from flake8->-r requirements.txt (line 20))\n","  Downloading pycodestyle-2.11.1-py2.py3-none-any.whl.metadata (4.5 kB)\n","Collecting pyflakes<3.3.0,>=3.2.0 (from flake8->-r requirements.txt (line 20))\n","  Downloading pyflakes-3.2.0-py2.py3-none-any.whl.metadata (3.5 kB)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 26))\n","  Downloading GitPython-3.1.42-py3-none-any.whl.metadata (12 kB)\n","Collecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 26))\n","  Downloading sentry_sdk-1.42.0-py2.py3-none-any.whl.metadata (9.8 kB)\n","Collecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 26))\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n","Collecting setproctitle (from wandb->-r requirements.txt (line 26))\n","  Downloading setproctitle-1.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 26)) (69.2.0)\n","Collecting protobuf!=4.21.0,<5,>=3.19.0 (from wandb->-r requirements.txt (line 26))\n","  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n","Collecting hjson (from deepspeed->-r requirements.txt (line 29))\n","  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n","Collecting ninja (from deepspeed->-r requirements.txt (line 29))\n","  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n","Collecting py-cpuinfo (from deepspeed->-r requirements.txt (line 29))\n","  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n","Collecting pydantic (from deepspeed->-r requirements.txt (line 29))\n","  Downloading pydantic-2.6.4-py3-none-any.whl.metadata (85 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.1/85.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pynvml (from deepspeed->-r requirements.txt (line 29))\n","  Downloading pynvml-11.5.0-py3-none-any.whl.metadata (7.8 kB)\n","Collecting joblib (from nltk->-r requirements.txt (line 33))\n","  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n","Collecting aiosignal>=1.1.2 (from aiohttp->datasets->-r requirements.txt (line 6))\n","  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n","Collecting attrs>=17.3.0 (from aiohttp->datasets->-r requirements.txt (line 6))\n","  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n","Collecting frozenlist>=1.1.1 (from aiohttp->datasets->-r requirements.txt (line 6))\n","  Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multidict<7.0,>=4.5 (from aiohttp->datasets->-r requirements.txt (line 6))\n","  Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n","Collecting yarl<2.0,>=1.0 (from aiohttp->datasets->-r requirements.txt (line 6))\n","  Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 26))\n","  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n","Collecting charset-normalizer<4,>=2 (from requests->transformers>=4.35.0->-r requirements.txt (line 5))\n","  Downloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n","Collecting idna<4,>=2.5 (from requests->transformers>=4.35.0->-r requirements.txt (line 5))\n","  Downloading idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n","Collecting urllib3<3,>=1.21.1 (from requests->transformers>=4.35.0->-r requirements.txt (line 5))\n","  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n","Collecting certifi>=2017.4.17 (from requests->transformers>=4.35.0->-r requirements.txt (line 5))\n","  Downloading certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n","Collecting humanfriendly>=9.1 (from coloredlogs->optimum->-r requirements.txt (line 8))\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Collecting MarkupSafe>=2.0 (from jinja2->torch==2.1.2+cu118->-r requirements.txt (line 2))\n","  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n","Collecting python-dateutil>=2.8.2 (from pandas->datasets->-r requirements.txt (line 6))\n","  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n","Collecting pytz>=2020.1 (from pandas->datasets->-r requirements.txt (line 6))\n","  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n","Collecting tzdata>=2022.7 (from pandas->datasets->-r requirements.txt (line 6))\n","  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting annotated-types>=0.4.0 (from pydantic->deepspeed->-r requirements.txt (line 29))\n","  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n","Collecting pydantic-core==2.16.3 (from pydantic->deepspeed->-r requirements.txt (line 29))\n","  Downloading pydantic_core-2.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n","Collecting mpmath>=0.19 (from sympy->torch==2.1.2+cu118->-r requirements.txt (line 2))\n","  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 26))\n","  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n","Downloading triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m118.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-2.18.0-py3-none-any.whl (510 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading optimum-1.17.1-py3-none-any.whl (407 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.1/407.1 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading peft-0.9.0-py3-none-any.whl (190 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n","Downloading loralib-0.1.2-py3-none-any.whl (10 kB)\n","Downloading scipy-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading py7zr-0.21.0-py3-none-any.whl (67 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl (102.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading black-24.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading flake8-7.0.0-py2.py3-none-any.whl (57 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading wandb-0.16.4-py3-none-any.whl (2.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pybind11-2.11.1-py3-none-any.whl (227 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.7/227.7 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiohttp-3.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.4/346.4 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading inflate64-1.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n","Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n","Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading packaging-24.0-py3-none-any.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n","Downloading platformdirs-4.2.0-py3-none-any.whl (17 kB)\n","Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyarrow-15.0.2-cp311-cp311-manylinux_2_28_x86_64.whl (38.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pybcj-1.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pycodestyle-2.11.1-py2.py3-none-any.whl (31 kB)\n","Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyflakes-3.2.0-py2.py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyppmd-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.2/141.2 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.7/757.7 kB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyzstd-0.15.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.3/412.3 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading regex-2023.12.25-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.1/785.1 kB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading safetensors-0.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sentry_sdk-1.42.0-py2.py3-none-any.whl (263 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.5/263.5 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n","Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading filelock-3.13.1-py3-none-any.whl (11 kB)\n","Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pandas-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m117.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n","Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n","Downloading pydantic-2.6.4-py3-none-any.whl (394 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.9/394.9 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydantic_core-2.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading setproctitle-1.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n","Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n","Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n","Downloading xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n","Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (140 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.3/140.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.3/272.3 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading idna-3.6-py3-none-any.whl (61 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n","Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (328 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.1/328.1 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: fire, deepspeed, mpi4py\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117029 sha256=a3f01a5b5d4e616bf797fd82b99670da65cc9b8ae09aeffc73fe987922904a00\n","  Stored in directory: /root/.cache/pip/wheels/6a/f3/0c/fa347dfa663f573462c6533d259c2c859e97e103d1ce21538f\n","  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for deepspeed: filename=deepspeed-0.14.0-py3-none-any.whl size=1400346 sha256=6fa66d131a961c886972ba6101e135f35eb49dfde3292d07966961840e4942bf\n","  Stored in directory: /root/.cache/pip/wheels/21/93/10/aca4f9f9390297a80a58fb8db0fcdcf1f41499d1afe922a513\n","  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mpi4py: filename=mpi4py-3.1.5-cp311-cp311-linux_x86_64.whl size=2878987 sha256=b50fb6eb431965a5e276e3339e5e1063cdfae5039cacf6e53fbaddd74b32df2a\n","  Stored in directory: /root/.cache/pip/wheels/b4/36/dc/392c299a27e4f93c9fe3f215cfe71245415c278bebfefc5414\n","Successfully built fire deepspeed mpi4py\n","Installing collected packages: texttable, sentencepiece, pytz, py-cpuinfo, ninja, mpmath, hjson, brotli, appdirs, xxhash, urllib3, tzdata, typing-extensions, tqdm, termcolor, sympy, smmap, setproctitle, safetensors, regex, pyzstd, pyyaml, python-dateutil, pyppmd, pynvml, pyflakes, pycryptodomex, pycodestyle, pybind11, pybcj, pyarrow-hotfix, psutil, protobuf, platformdirs, pathspec, packaging, numpy, networkx, mypy-extensions, multivolumefile, multidict, mpi4py, mccabe, MarkupSafe, loralib, joblib, inflate64, idna, humanfriendly, fsspec, frozenlist, filelock, docker-pycreds, dill, click, charset-normalizer, certifi, attrs, annotated-types, yarl, triton, sentry-sdk, scipy, requests, pydantic-core, pyarrow, py7zr, pandas, nltk, multiprocess, jinja2, gitdb, flake8, fire, coloredlogs, black, aiosignal, torch, pydantic, huggingface-hub, GitPython, aiohttp, wandb, tokenizers, deepspeed, bitsandbytes, accelerate, transformers, datasets, peft, optimum\n","Successfully installed GitPython-3.1.42 MarkupSafe-2.1.5 accelerate-0.28.0 aiohttp-3.9.3 aiosignal-1.3.1 annotated-types-0.6.0 appdirs-1.4.4 attrs-23.2.0 bitsandbytes-0.43.0 black-24.3.0 brotli-1.1.0 certifi-2024.2.2 charset-normalizer-3.3.2 click-8.1.7 coloredlogs-15.0.1 datasets-2.18.0 deepspeed-0.14.0 dill-0.3.8 docker-pycreds-0.4.0 filelock-3.13.1 fire-0.6.0 flake8-7.0.0 frozenlist-1.4.1 fsspec-2024.2.0 gitdb-4.0.11 hjson-3.1.0 huggingface-hub-0.21.4 humanfriendly-10.0 idna-3.6 inflate64-1.0.0 jinja2-3.1.3 joblib-1.3.2 loralib-0.1.2 mccabe-0.7.0 mpi4py-3.1.5 mpmath-1.3.0 multidict-6.0.5 multiprocess-0.70.16 multivolumefile-0.2.3 mypy-extensions-1.0.0 networkx-3.2.1 ninja-1.11.1.1 nltk-3.8.1 numpy-1.26.4 optimum-1.17.1 packaging-24.0 pandas-2.2.1 pathspec-0.12.1 peft-0.9.0 platformdirs-4.2.0 protobuf-4.25.3 psutil-5.9.8 py-cpuinfo-9.0.0 py7zr-0.21.0 pyarrow-15.0.2 pyarrow-hotfix-0.6 pybcj-1.0.2 pybind11-2.11.1 pycodestyle-2.11.1 pycryptodomex-3.20.0 pydantic-2.6.4 pydantic-core-2.16.3 pyflakes-3.2.0 pynvml-11.5.0 pyppmd-1.1.0 python-dateutil-2.9.0.post0 pytz-2024.1 pyyaml-6.0.1 pyzstd-0.15.9 regex-2023.12.25 requests-2.31.0 safetensors-0.4.2 scipy-1.12.0 sentencepiece-0.2.0 sentry-sdk-1.42.0 setproctitle-1.3.3 smmap-5.0.1 sympy-1.12 termcolor-2.4.0 texttable-1.7.0 tokenizers-0.15.2 torch-2.1.2+cu118 tqdm-4.66.2 transformers-4.38.2 triton-2.1.0 typing-extensions-4.10.0 tzdata-2024.1 urllib3-2.2.1 wandb-0.16.4 xxhash-3.4.1 yarl-1.9.4\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: mpi4py in /usr/local/lib/python3.11/dist-packages (3.1.5)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.21.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2024.2.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.66.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.10.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2024.2.2)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (1.11.1.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (24.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (0.43.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting flash-attn==2.3.6\n","  Downloading flash_attn-2.3.6.tar.gz (2.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn==2.3.6) (2.1.2+cu118)\n","Collecting einops (from flash-attn==2.3.6)\n","  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from flash-attn==2.3.6) (24.0)\n","Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from flash-attn==2.3.6) (1.11.1.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.3.6) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.3.6) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.3.6) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.3.6) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.3.6) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.3.6) (2024.2.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.3.6) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn==2.3.6) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->flash-attn==2.3.6) (1.3.0)\n","Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: flash-attn\n","  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for flash-attn: filename=flash_attn-2.3.6-cp311-cp311-linux_x86_64.whl size=56617236 sha256=cab4d92225ef0a4a9b4a1dbc5f69a0c2cb80ebada906365612b310de94672464\n","  Stored in directory: /root/.cache/pip/wheels/76/d7/8d/6cc2b6bbfda831a177abf1015646ac434b8e3323784bab480a\n","Successfully built flash-attn\n","Installing collected packages: einops, flash-attn\n","Successfully installed einops-0.7.0 flash-attn-2.3.6\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 100})'''))\n","!bash install_colab.sh"]},{"cell_type":"markdown","source":["### Megatron-DeepSpeedのインストール"],"metadata":{"id":"QPPSyC31zK74"}},{"cell_type":"code","source":["display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 100})'''))\n","%cd ~/moe-recipes\n","!git clone https://github.com/hotsuyuki/Megatron-DeepSpeed\n","\n","# Makefileのpython3-configをフルパスで指定\n","# （参考）https://zenn.dev/turing_motors/articles/04c1328bf6095a#pyenv-virtualenv-%E3%82%92%E4%BD%BF%E3%81%86%E3%81%A8%E5%BF%85%E8%A6%81%E3%81%AB%E3%81%AA%E3%82%8B%E5%87%A6%E7%90%86\n","!sed -i 's|python3-config |/usr/bin/python3.11-config |g' megatron/data/Makefile\n","\n","!git fetch origin && git checkout refs/tags/ucllm_nedo_dev_v20240205.1.0\n","!python setup.py install"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":100},"id":"KSteX62XT0pL","executionInfo":{"status":"ok","timestamp":1710824058618,"user_tz":-540,"elapsed":2966,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}},"outputId":"edad71c8-94fa-47aa-a922-655164121502"},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["google.colab.output.setIframeHeight(0, true, {maxHeight: 100})"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["/root/moe-recipes\n","Cloning into 'Megatron-DeepSpeed'...\n","remote: Enumerating objects: 13401, done.\u001b[K\n","remote: Counting objects: 100% (2910/2910), done.\u001b[K\n","remote: Compressing objects: 100% (172/172), done.\u001b[K\n","remote: Total 13401 (delta 2807), reused 2743 (delta 2738), pack-reused 10491\u001b[K\n","Receiving objects: 100% (13401/13401), 4.84 MiB | 6.46 MiB/s, done.\n","Resolving deltas: 100% (10050/10050), done.\n","sed: can't read megatron/data/Makefile: No such file or directory\n","error: pathspec 'refs/tags/ucllm_nedo_dev_v20240205.1.0' did not match any file(s) known to git\n","python3: can't open file '/root/moe-recipes/setup.py': [Errno 2] No such file or directory\n"]}]},{"cell_type":"markdown","source":["### Tokenizer"],"metadata":{"id":"kgvGD-Tblsd6"}},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mixtral-8x7B-v0.1\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269,"referenced_widgets":["c6fe94b70c50470495befb609de8d2e8","6199cc7dd9624dc8b18d11096ac67a13","df48b892eb674ec881867664c73bde78","f346caf6dfd345e88d9fae0e30dd3ccd","57d08b7e9b1a4a1999f6c7c1b9220814","f67e1d4ebf4448bca2b34d74c3f80249","517127fce3ec442f9c42a17752aeed0f","d0e1dde5d3034a67b1a03ca10c0d34b9","4ce24eca8dbb480799bd5cb162bffe97","e3d704b60bd34593adf44d28981c3902","7dcbeabcd20541a483b000af3a701feb","c7310901b30c414fa7e29bb084986e1a","3719d76264814566804dac0094c3d105","58ab0807c52740de936d79f6a0e7f13d","5a9e40ca33ba4b70abfc5075b11ef320","cc484497cbe84ea1a9c5d7127521bbb5","1af221c394c541a298118903e567fec2","2d20507f7926459caaf46bb776aeca8b","0cee4ee704a046b1a3669476ecdc27c7","9d70008067b941e78db3a011b0f705f2","8d6e34b71f5f413eaf3011e0b286615a","0d7c1f47efe44eb1a3250ae866540dd9","354880a1d1d0419ab74668a13a2b1627","9d99df716c2443f690fade01e204ad8a","629ccc3f025049b39a3134cfdbac3f14","ad7035ac8de942f196749394ed48a714","d2bbb85605cb46688ba77854200265c7","8824d2d9d9cf427e9b5c3d4bb863b1cf","5f3d2dcfe7c247f7ba8e4a301f6e1d2b","1ca79947b0664e759f0a6d9df3f9cc7e","d9b73342b27343308a8c54c2eaa24cc3","1bd52af930f64ccc8d91450e1cb4663e","30d7729408b14e6db45179d81fa043b9","fca413e0d8e643758caf7d0d131fecfa","04f1a5cd3ebc408cae13a4ac3a53d465","6a964d68ee794218b18bcf602a4124ed","fd7da8d0d37c406883e1e3081a6daf52","d3db72b97e8948c899cc303ff9b16694","4c175173be8a4b14914125b48ee766b7","e6cff957b7b04580845cc969c71c28e9","b38fb27ff76e4c7680a8c3e7f5c63250","2abbd77b65434840af9a9078f8188cc9","ad59fbb0749e4c4ea2a3b6b6d6dddf7c","d5f7cbdb20b34ecd96ba965ec3a1de67"]},"id":"ISAS5zATo4AW","executionInfo":{"status":"ok","timestamp":1710824068869,"user_tz":-540,"elapsed":10253,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}},"outputId":"d559f347-96ae-4032-bd5d-c307c1236769"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6fe94b70c50470495befb609de8d2e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7310901b30c414fa7e29bb084986e1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"354880a1d1d0419ab74668a13a2b1627"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fca413e0d8e643758caf7d0d131fecfa"}},"metadata":{}}]},{"cell_type":"code","source":["%cd ~/moe-recipes\n","tokenizer.save_pretrained(\"./tokenizer_model_directory\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MGSJiPbjqyge","executionInfo":{"status":"ok","timestamp":1710824068870,"user_tz":-540,"elapsed":8,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}},"outputId":"0e4f4828-bd3d-4975-a4a0-3500ba02c21a"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["/root/moe-recipes\n"]},{"output_type":"execute_result","data":{"text/plain":["('./tokenizer_model_directory/tokenizer_config.json',\n"," './tokenizer_model_directory/special_tokens_map.json',\n"," './tokenizer_model_directory/tokenizer.model',\n"," './tokenizer_model_directory/added_tokens.json',\n"," './tokenizer_model_directory/tokenizer.json')"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["tokenizer.vocab_size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HoNzM_p2b7Jv","executionInfo":{"status":"ok","timestamp":1710824068870,"user_tz":-540,"elapsed":6,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}},"outputId":"01dcc7b2-66fb-4cb4-f3fe-bdabae41b13e"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["32000"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["### モデルの事前学習"],"metadata":{"id":"5vgurFdX3DpZ"}},{"cell_type":"code","source":["%cd ~/moe-recipes\n","!git clone https://github.com/NVIDIA/apex\n","%cd apex"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IR704h5vDnw8","executionInfo":{"status":"ok","timestamp":1710824071140,"user_tz":-540,"elapsed":2274,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}},"outputId":"0a096986-5619-4621-fc0f-ba9ff63aaca5"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["/root/moe-recipes\n","Cloning into 'apex'...\n","remote: Enumerating objects: 11638, done.\u001b[K\n","remote: Counting objects: 100% (3706/3706), done.\u001b[K\n","remote: Compressing objects: 100% (569/569), done.\u001b[K\n","remote: Total 11638 (delta 3342), reused 3264 (delta 3134), pack-reused 7932\u001b[K\n","Receiving objects: 100% (11638/11638), 15.47 MiB | 17.66 MiB/s, done.\n","Resolving deltas: 100% (8171/8171), done.\n","/root/moe-recipes/apex\n"]}]},{"cell_type":"code","source":["!pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation --config-settings \"--build-option=--cpp_ext\" --config-settings \"--build-option=--cuda_ext\" ./"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gzGdPxVLDyOK","executionInfo":{"status":"ok","timestamp":1710825006199,"user_tz":-540,"elapsed":935060,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}},"outputId":"2a6eb416-4a88-4df2-98f1-033b286e3242"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Using pip 24.0 from /usr/local/lib/python3.11/dist-packages/pip (python 3.11)\n","Processing /root/moe-recipes/apex\n","  Running command Preparing metadata (pyproject.toml)\n","\n","\n","  torch.__version__  = 2.1.2+cu118\n","\n","\n","  running dist_info\n","  creating /tmp/pip-modern-metadata-twhp3m2k/apex.egg-info\n","  writing /tmp/pip-modern-metadata-twhp3m2k/apex.egg-info/PKG-INFO\n","  writing dependency_links to /tmp/pip-modern-metadata-twhp3m2k/apex.egg-info/dependency_links.txt\n","  writing requirements to /tmp/pip-modern-metadata-twhp3m2k/apex.egg-info/requires.txt\n","  writing top-level names to /tmp/pip-modern-metadata-twhp3m2k/apex.egg-info/top_level.txt\n","  writing manifest file '/tmp/pip-modern-metadata-twhp3m2k/apex.egg-info/SOURCES.txt'\n","  reading manifest file '/tmp/pip-modern-metadata-twhp3m2k/apex.egg-info/SOURCES.txt'\n","  adding license file 'LICENSE'\n","  writing manifest file '/tmp/pip-modern-metadata-twhp3m2k/apex.egg-info/SOURCES.txt'\n","  creating '/tmp/pip-modern-metadata-twhp3m2k/apex-0.1.dist-info'\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: packaging>20.6 in /usr/local/lib/python3.11/dist-packages (from apex==0.1) (24.0)\n","Building wheels for collected packages: apex\n","  Running command Building wheel for apex (pyproject.toml)\n","\n","\n","  torch.__version__  = 2.1.2+cu118\n","\n","\n","\n","  Compiling cuda extensions with\n","  nvcc: NVIDIA (R) Cuda compiler driver\n","  Copyright (c) 2005-2022 NVIDIA Corporation\n","  Built on Wed_Sep_21_10:33:58_PDT_2022\n","  Cuda compilation tools, release 11.8, V11.8.89\n","  Build cuda_11.8.r11.8/compiler.31833905_0\n","  from /usr/local/cuda-11.8/bin\n","\n","  running bdist_wheel\n","  running build\n","  running build_py\n","  creating build\n","  creating build/lib.linux-x86_64-cpython-311\n","  creating build/lib.linux-x86_64-cpython-311/apex\n","  copying apex/_autocast_utils.py -> build/lib.linux-x86_64-cpython-311/apex\n","  copying apex/__init__.py -> build/lib.linux-x86_64-cpython-311/apex\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib\n","  copying apex/contrib/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib\n","  creating build/lib.linux-x86_64-cpython-311/apex/amp\n","  copying apex/amp/scaler.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n","  copying apex/amp/handle.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n","  copying apex/amp/_initialize.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n","  copying apex/amp/compat.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n","  copying apex/amp/__version__.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n","  copying apex/amp/opt.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n","  copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n","  copying apex/amp/amp.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n","  copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n","  copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n","  copying apex/amp/wrap.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n","  copying apex/amp/frontend.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n","  copying apex/amp/utils.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n","  copying apex/amp/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n","  creating build/lib.linux-x86_64-cpython-311/apex/fp16_utils\n","  copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-cpython-311/apex/fp16_utils\n","  copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-cpython-311/apex/fp16_utils\n","  copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-cpython-311/apex/fp16_utils\n","  copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/fp16_utils\n","  creating build/lib.linux-x86_64-cpython-311/apex/mlp\n","  copying apex/mlp/mlp.py -> build/lib.linux-x86_64-cpython-311/apex/mlp\n","  copying apex/mlp/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/mlp\n","  creating build/lib.linux-x86_64-cpython-311/apex/transformer\n","  copying apex/transformer/microbatches.py -> build/lib.linux-x86_64-cpython-311/apex/transformer\n","  copying apex/transformer/log_util.py -> build/lib.linux-x86_64-cpython-311/apex/transformer\n","  copying apex/transformer/parallel_state.py -> build/lib.linux-x86_64-cpython-311/apex/transformer\n","  copying apex/transformer/enums.py -> build/lib.linux-x86_64-cpython-311/apex/transformer\n","  copying apex/transformer/_ucc_util.py -> build/lib.linux-x86_64-cpython-311/apex/transformer\n","  copying apex/transformer/utils.py -> build/lib.linux-x86_64-cpython-311/apex/transformer\n","  copying apex/transformer/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/transformer\n","  creating build/lib.linux-x86_64-cpython-311/apex/multi_tensor_apply\n","  copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-cpython-311/apex/multi_tensor_apply\n","  copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/multi_tensor_apply\n","  creating build/lib.linux-x86_64-cpython-311/apex/fused_dense\n","  copying apex/fused_dense/fused_dense.py -> build/lib.linux-x86_64-cpython-311/apex/fused_dense\n","  copying apex/fused_dense/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/fused_dense\n","  creating build/lib.linux-x86_64-cpython-311/apex/optimizers\n","  copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-cpython-311/apex/optimizers\n","  copying apex/optimizers/fused_mixed_precision_lamb.py -> build/lib.linux-x86_64-cpython-311/apex/optimizers\n","  copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-cpython-311/apex/optimizers\n","  copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-cpython-311/apex/optimizers\n","  copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-cpython-311/apex/optimizers\n","  copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-cpython-311/apex/optimizers\n","  copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/optimizers\n","  creating build/lib.linux-x86_64-cpython-311/apex/normalization\n","  copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-cpython-311/apex/normalization\n","  copying apex/normalization/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/normalization\n","  creating build/lib.linux-x86_64-cpython-311/apex/RNN\n","  copying apex/RNN/models.py -> build/lib.linux-x86_64-cpython-311/apex/RNN\n","  copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-cpython-311/apex/RNN\n","  copying apex/RNN/cells.py -> build/lib.linux-x86_64-cpython-311/apex/RNN\n","  copying apex/RNN/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/RNN\n","  creating build/lib.linux-x86_64-cpython-311/apex/parallel\n","  copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-cpython-311/apex/parallel\n","  copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-cpython-311/apex/parallel\n","  copying apex/parallel/distributed.py -> build/lib.linux-x86_64-cpython-311/apex/parallel\n","  copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-cpython-311/apex/parallel\n","  copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-cpython-311/apex/parallel\n","  copying apex/parallel/LARC.py -> build/lib.linux-x86_64-cpython-311/apex/parallel\n","  copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-cpython-311/apex/parallel\n","  copying apex/parallel/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/parallel\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/bottleneck\n","  copying apex/contrib/bottleneck/bottleneck.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/bottleneck\n","  copying apex/contrib/bottleneck/halo_exchangers.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/bottleneck\n","  copying apex/contrib/bottleneck/test.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/bottleneck\n","  copying apex/contrib/bottleneck/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/bottleneck\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/fmha\n","  copying apex/contrib/fmha/fmha.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/fmha\n","  copying apex/contrib/fmha/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/fmha\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/conv_bias_relu\n","  copying apex/contrib/conv_bias_relu/conv_bias_relu.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/conv_bias_relu\n","  copying apex/contrib/conv_bias_relu/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/conv_bias_relu\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n","  copying apex/contrib/openfold_triton/_layer_norm_config_ampere.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n","  copying apex/contrib/openfold_triton/_mha_kernel.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n","  copying apex/contrib/openfold_triton/fused_adam_swa.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n","  copying apex/contrib/openfold_triton/_layer_norm_config_hopper.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n","  copying apex/contrib/openfold_triton/_layer_norm_backward_kernels.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n","  copying apex/contrib/openfold_triton/mha.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n","  copying apex/contrib/openfold_triton/layer_norm.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n","  copying apex/contrib/openfold_triton/_layer_norm_forward_kernels.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n","  copying apex/contrib/openfold_triton/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/cudnn_gbn\n","  copying apex/contrib/cudnn_gbn/batch_norm.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/cudnn_gbn\n","  copying apex/contrib/cudnn_gbn/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/cudnn_gbn\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/groupbn\n","  copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/groupbn\n","  copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/groupbn\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/gpu_direct_storage\n","  copying apex/contrib/gpu_direct_storage/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/gpu_direct_storage\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/layer_norm\n","  copying apex/contrib/layer_norm/layer_norm.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/layer_norm\n","  copying apex/contrib/layer_norm/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/layer_norm\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity\n","  copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity\n","  copying apex/contrib/sparsity/permutation_lib.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity\n","  copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity\n","  copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/index_mul_2d\n","  copying apex/contrib/index_mul_2d/index_mul_2d.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/index_mul_2d\n","  copying apex/contrib/index_mul_2d/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/index_mul_2d\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/test\n","  copying apex/contrib/test/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/transducer\n","  copying apex/contrib/transducer/transducer.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/transducer\n","  copying apex/contrib/transducer/_transducer_ref.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/transducer\n","  copying apex/contrib/transducer/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/transducer\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/xentropy\n","  copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/xentropy\n","  copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/xentropy\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/clip_grad\n","  copying apex/contrib/clip_grad/clip_grad.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/clip_grad\n","  copying apex/contrib/clip_grad/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/clip_grad\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/peer_memory\n","  copying apex/contrib/peer_memory/peer_halo_exchanger_1d.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/peer_memory\n","  copying apex/contrib/peer_memory/peer_memory.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/peer_memory\n","  copying apex/contrib/peer_memory/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/peer_memory\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/group_norm\n","  copying apex/contrib/group_norm/group_norm.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/group_norm\n","  copying apex/contrib/group_norm/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/group_norm\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/focal_loss\n","  copying apex/contrib/focal_loss/focal_loss.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/focal_loss\n","  copying apex/contrib/focal_loss/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/focal_loss\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels\n","  copying apex/contrib/sparsity/permutation_search_kernels/channel_swap.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels\n","  copying apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels\n","  copying apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels\n","  copying apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels\n","  copying apex/contrib/sparsity/permutation_search_kernels/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/bottleneck\n","  copying apex/contrib/test/bottleneck/test_bottleneck_module.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/bottleneck\n","  copying apex/contrib/test/bottleneck/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/bottleneck\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/fmha\n","  copying apex/contrib/test/fmha/test_fmha.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/fmha\n","  copying apex/contrib/test/fmha/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/fmha\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/conv_bias_relu\n","  copying apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/conv_bias_relu\n","  copying apex/contrib/test/conv_bias_relu/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/conv_bias_relu\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/cudnn_gbn\n","  copying apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/cudnn_gbn\n","  copying apex/contrib/test/cudnn_gbn/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/cudnn_gbn\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/optimizers\n","  copying apex/contrib/test/optimizers/test_distributed_fused_lamb.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/optimizers\n","  copying apex/contrib/test/optimizers/test_dist_adam.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/optimizers\n","  copying apex/contrib/test/optimizers/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/optimizers\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/layer_norm\n","  copying apex/contrib/test/layer_norm/test_fast_layer_norm.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/layer_norm\n","  copying apex/contrib/test/layer_norm/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/layer_norm\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/index_mul_2d\n","  copying apex/contrib/test/index_mul_2d/test_index_mul_2d.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/index_mul_2d\n","  copying apex/contrib/test/index_mul_2d/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/index_mul_2d\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/transducer\n","  copying apex/contrib/test/transducer/test_transducer_joint.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/transducer\n","  copying apex/contrib/test/transducer/test_transducer_loss.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/transducer\n","  copying apex/contrib/test/transducer/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/transducer\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/xentropy\n","  copying apex/contrib/test/xentropy/test_label_smoothing.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/xentropy\n","  copying apex/contrib/test/xentropy/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/xentropy\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/clip_grad\n","  copying apex/contrib/test/clip_grad/test_clip_grad.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/clip_grad\n","  copying apex/contrib/test/clip_grad/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/clip_grad\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/peer_memory\n","  copying apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/peer_memory\n","  copying apex/contrib/test/peer_memory/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/peer_memory\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/group_norm\n","  copying apex/contrib/test/group_norm/test_group_norm.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/group_norm\n","  copying apex/contrib/test/group_norm/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/group_norm\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/focal_loss\n","  copying apex/contrib/test/focal_loss/test_focal_loss.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/focal_loss\n","  copying apex/contrib/test/focal_loss/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/focal_loss\n","  creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn\n","  copying apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn\n","  copying apex/contrib/test/multihead_attn/test_self_multihead_attn.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn\n","  copying apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn\n","  copying apex/contrib/test/multihead_attn/test_mha_fused_softmax.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn\n","  copying apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn\n","  copying apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn\n","  copying apex/contrib/test/multihead_attn/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn\n","  creating build/lib.linux-x86_64-cpython-311/apex/amp/lists\n","  copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-cpython-311/apex/amp/lists\n","  copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-cpython-311/apex/amp/lists\n","  copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-cpython-311/apex/amp/lists\n","  copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/amp/lists\n","  creating build/lib.linux-x86_64-cpython-311/apex/transformer/amp\n","  copying apex/transformer/amp/grad_scaler.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/amp\n","  copying apex/transformer/amp/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/amp\n","  creating build/lib.linux-x86_64-cpython-311/apex/transformer/layers\n","  copying apex/transformer/layers/layer_norm.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/layers\n","  copying apex/transformer/layers/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/layers\n","  creating build/lib.linux-x86_64-cpython-311/apex/transformer/_data\n","  copying apex/transformer/_data/_batchsampler.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/_data\n","  copying apex/transformer/_data/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/_data\n","  creating build/lib.linux-x86_64-cpython-311/apex/transformer/testing\n","  copying apex/transformer/testing/commons.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/testing\n","  copying apex/transformer/testing/distributed_test_base.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/testing\n","  copying apex/transformer/testing/standalone_transformer_lm.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/testing\n","  copying apex/transformer/testing/global_vars.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/testing\n","  copying apex/transformer/testing/standalone_gpt.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/testing\n","  copying apex/transformer/testing/standalone_bert.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/testing\n","  copying apex/transformer/testing/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/testing\n","  copying apex/transformer/testing/arguments.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/testing\n","  creating build/lib.linux-x86_64-cpython-311/apex/transformer/functional\n","  copying apex/transformer/functional/fused_softmax.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/functional\n","  copying apex/transformer/functional/fused_rope.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/functional\n","  copying apex/transformer/functional/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/functional\n","  creating build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel\n","  copying apex/transformer/tensor_parallel/layers.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel\n","  copying apex/transformer/tensor_parallel/random.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel\n","  copying apex/transformer/tensor_parallel/data.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel\n","  copying apex/transformer/tensor_parallel/mappings.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel\n","  copying apex/transformer/tensor_parallel/cross_entropy.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel\n","  copying apex/transformer/tensor_parallel/memory.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel\n","  copying apex/transformer/tensor_parallel/utils.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel\n","  copying apex/transformer/tensor_parallel/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel\n","  creating build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel\n","  copying apex/transformer/pipeline_parallel/_timers.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel\n","  copying apex/transformer/pipeline_parallel/utils.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel\n","  copying apex/transformer/pipeline_parallel/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel\n","  copying apex/transformer/pipeline_parallel/p2p_communication.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel\n","  creating build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules\n","  copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules\n","  copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules\n","  copying apex/transformer/pipeline_parallel/schedules/common.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules\n","  copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules\n","  copying apex/transformer/pipeline_parallel/schedules/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules\n","  running build_ext\n","  /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:424: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 11.8\n","    warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n","  building 'apex_C' extension\n","  creating /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311\n","  creating /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc\n","  Emitting ninja build file /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/build.ninja...\n","  Compiling objects...\n","  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n","  [1/1] c++ -MMD -MF /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/flatten_unflatten.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/flatten_unflatten.cpp -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","  x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/flatten_unflatten.o -L/usr/local/lib/python3.11/dist-packages/torch/lib -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-311/apex_C.cpython-311-x86_64-linux-gnu.so\n","  building 'amp_C' extension\n","  Emitting ninja build file /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/build.ninja...\n","  Compiling objects...\n","  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n","  [1/15] /usr/local/cuda-11.8/bin/nvcc  -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/multi_tensor_novograd.cu -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17\n","  [2/15] /usr/local/cuda-11.8/bin/nvcc  -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/multi_tensor_adagrad.cu -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/multi_tensor_adagrad.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17\n","  [3/15] /usr/local/cuda-11.8/bin/nvcc  -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/multi_tensor_l2norm_scale_kernel.cu -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/multi_tensor_l2norm_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17\n","  [4/15] /usr/local/cuda-11.8/bin/nvcc  -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/multi_tensor_scale_kernel.cu -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17\n","  [5/15] /usr/local/cuda-11.8/bin/nvcc  -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/multi_tensor_lamb_stage_1.cu -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17\n","  [6/15] /usr/local/cuda-11.8/bin/nvcc  -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/multi_tensor_lamb_stage_2.cu -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17\n","  [7/15] /usr/local/cuda-11.8/bin/nvcc  -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/multi_tensor_l2norm_kernel_mp.cu -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/multi_tensor_l2norm_kernel_mp.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17\n","  [8/15] /usr/local/cuda-11.8/bin/nvcc  -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/multi_tensor_sgd_kernel.cu -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17\n","  [9/15] /usr/local/cuda-11.8/bin/nvcc  -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/multi_tensor_l2norm_kernel.cu -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17\n","  [10/15] /usr/local/cuda-11.8/bin/nvcc  -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/multi_tensor_lamb_mp.cu -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/multi_tensor_lamb_mp.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17\n","  [11/15] /usr/local/cuda-11.8/bin/nvcc  -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/multi_tensor_axpby_kernel.cu -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17\n","  [12/15] /usr/local/cuda-11.8/bin/nvcc  -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/multi_tensor_lamb.cu -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17\n","  [13/15] /usr/local/cuda-11.8/bin/nvcc  -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/multi_tensor_adam.cu -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17\n","  [14/15] c++ -MMD -MF /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/amp_C_frontend.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/amp_C_frontend.cpp -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","  [15/15] /usr/local/cuda-11.8/bin/nvcc  -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/update_scale_hysteresis.cu -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/update_scale_hysteresis.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17\n","  x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/amp_C_frontend.o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/multi_tensor_adagrad.o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/multi_tensor_adam.o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/multi_tensor_axpby_kernel.o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/multi_tensor_l2norm_kernel.o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/multi_tensor_l2norm_kernel_mp.o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/multi_tensor_l2norm_scale_kernel.o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/multi_tensor_lamb.o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/multi_tensor_lamb_mp.o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/multi_tensor_lamb_stage_1.o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/multi_tensor_lamb_stage_2.o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/multi_tensor_novograd.o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/multi_tensor_scale_kernel.o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/multi_tensor_sgd_kernel.o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/update_scale_hysteresis.o -L/usr/local/lib/python3.11/dist-packages/torch/lib -L/usr/local/cuda-11.8/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/amp_C.cpython-311-x86_64-linux-gnu.so\n","  building 'syncbn' extension\n","  Emitting ninja build file /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/build.ninja...\n","  Compiling objects...\n","  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n","  [1/2] /usr/local/cuda-11.8/bin/nvcc  -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/welford.cu -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17\n","  [2/2] c++ -MMD -MF /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/syncbn.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/syncbn.cpp -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","  x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/syncbn.o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/welford.o -L/usr/local/lib/python3.11/dist-packages/torch/lib -L/usr/local/cuda-11.8/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/syncbn.cpython-311-x86_64-linux-gnu.so\n","  building 'fused_layer_norm_cuda' extension\n","  Emitting ninja build file /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/build.ninja...\n","  Compiling objects...\n","  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n","  [1/2] c++ -MMD -MF /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/layer_norm_cuda.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/layer_norm_cuda.cpp -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","  [2/2] /usr/local/cuda-11.8/bin/nvcc  -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/layer_norm_cuda_kernel.cu -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17\n","  x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/layer_norm_cuda.o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/layer_norm_cuda_kernel.o -L/usr/local/lib/python3.11/dist-packages/torch/lib -L/usr/local/cuda-11.8/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/fused_layer_norm_cuda.cpython-311-x86_64-linux-gnu.so\n","  building 'mlp_cuda' extension\n","  Emitting ninja build file /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/build.ninja...\n","  Compiling objects...\n","  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n","  [1/2] c++ -MMD -MF /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/mlp.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/mlp.cpp -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","  /root/moe-recipes/apex/csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>)’:\n","  /root/moe-recipes/apex/csrc/mlp.cpp:57:21: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n","     57 |   for (int i = 0; i < num_layers; i++) {\n","        |                   ~~^~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:64:76: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     64 |   auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());\n","        |                                                              ~~~~~~~~~~~~~~^~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/mlp.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n","    225 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:65:85: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     65 |   auto reserved_space = at::empty({static_cast<long>(reserved_size)}, inputs[0].type());\n","        |                                                                       ~~~~~~~~~~~~~~^~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/mlp.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n","    225 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:67:58: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     67 |   auto lt_workspace = at::empty({1 << 22}, inputs[0].type());\n","        |                                            ~~~~~~~~~~~~~~^~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/mlp.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n","    225 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/ATen.h:11,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/mlp.cpp:1:\n","  /root/moe-recipes/apex/csrc/mlp.cpp: In lambda function:\n","  /root/moe-recipes/apex/csrc/mlp.cpp:69:53: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","        |                                       ~~~~~~~~~~~~~~^~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:215:28: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    215 |     const auto& the_type = TYPE;                                            \\\n","        |                            ^~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/mlp.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n","    225 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/ATen.h:11,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/mlp.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:218:47: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n","    218 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n","        |                          ~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:245:3: note: in expansion of macro ‘AT_DISPATCH_SWITCH’\n","    245 |   AT_DISPATCH_SWITCH(                                        \\\n","        |   ^~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:109:23: note: declared here\n","    109 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n","        |                       ^~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp: In lambda function:\n","  /root/moe-recipes/apex/csrc/mlp.cpp:72:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n","     72 |     for (int i = 0; i < num_layers; i++) {\n","        |                     ~~^~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:240:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    240 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n","     78 |     auto result = mlp_fp<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:240:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    240 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp: In lambda function:\n","  /root/moe-recipes/apex/csrc/mlp.cpp:72:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n","     72 |     for (int i = 0; i < num_layers; i++) {\n","        |                     ~~^~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:241:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    241 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n","     78 |     auto result = mlp_fp<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:241:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    241 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp: In lambda function:\n","  /root/moe-recipes/apex/csrc/mlp.cpp:72:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n","     72 |     for (int i = 0; i < num_layers; i++) {\n","        |                     ~~^~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:242:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    242 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n","     78 |     auto result = mlp_fp<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:242:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    242 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)’:\n","  /root/moe-recipes/apex/csrc/mlp.cpp:115:21: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n","    115 |   for (int i = 0; i < num_layers; i++) {\n","        |                   ~~^~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:120:21: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n","    120 |   for (int i = 0; i < inputs.size(); i++) {\n","        |                   ~~^~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:121:66: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    121 |     outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now\n","        |                                                    ~~~~~~~~~~~~~~^~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/mlp.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n","    225 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/ATen.h:11,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/mlp.cpp:1:\n","  /root/moe-recipes/apex/csrc/mlp.cpp: In lambda function:\n","  /root/moe-recipes/apex/csrc/mlp.cpp:124:53: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |                                       ~~~~~~~~~~~~~~^~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:215:28: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    215 |     const auto& the_type = TYPE;                                            \\\n","        |                            ^~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/mlp.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n","    225 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/ATen.h:11,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/mlp.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:218:47: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n","    218 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n","        |                          ~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:245:3: note: in expansion of macro ‘AT_DISPATCH_SWITCH’\n","    245 |   AT_DISPATCH_SWITCH(                                        \\\n","        |   ^~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:109:23: note: declared here\n","    109 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n","        |                       ^~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp: In lambda function:\n","  /root/moe-recipes/apex/csrc/mlp.cpp:126:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n","    126 |     for (int i = 0; i < num_layers; i++) {\n","        |                     ~~^~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:240:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    240 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:130:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n","    130 |     for (int i = 0; i < inputs.size(); i++) {\n","        |                     ~~^~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:240:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    240 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:138:98: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    138 |     auto work_space = at::empty({static_cast<long>(work_size / sizeof(scalar_t))}, inputs[0].type());\n","        |                                                                                    ~~~~~~~~~~~~~~^~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:240:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    240 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/mlp.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n","    225 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/ATen.h:11,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/mlp.cpp:1:\n","  /root/moe-recipes/apex/csrc/mlp.cpp:140:10: warning: unused variable ‘result’ [-Wunused-variable]\n","    140 |     auto result = mlp_bp<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:240:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    240 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp: In lambda function:\n","  /root/moe-recipes/apex/csrc/mlp.cpp:126:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n","    126 |     for (int i = 0; i < num_layers; i++) {\n","        |                     ~~^~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:241:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    241 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:130:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n","    130 |     for (int i = 0; i < inputs.size(); i++) {\n","        |                     ~~^~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:241:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    241 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:138:98: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    138 |     auto work_space = at::empty({static_cast<long>(work_size / sizeof(scalar_t))}, inputs[0].type());\n","        |                                                                                    ~~~~~~~~~~~~~~^~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:241:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    241 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/mlp.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n","    225 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/ATen.h:11,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/mlp.cpp:1:\n","  /root/moe-recipes/apex/csrc/mlp.cpp:140:10: warning: unused variable ‘result’ [-Wunused-variable]\n","    140 |     auto result = mlp_bp<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:241:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    241 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp: In lambda function:\n","  /root/moe-recipes/apex/csrc/mlp.cpp:126:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n","    126 |     for (int i = 0; i < num_layers; i++) {\n","        |                     ~~^~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:242:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    242 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:130:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n","    130 |     for (int i = 0; i < inputs.size(); i++) {\n","        |                     ~~^~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:242:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    242 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:138:98: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    138 |     auto work_space = at::empty({static_cast<long>(work_size / sizeof(scalar_t))}, inputs[0].type());\n","        |                                                                                    ~~~~~~~~~~~~~~^~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:242:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    242 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/mlp.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n","    225 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/ATen.h:11,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/mlp.cpp:1:\n","  /root/moe-recipes/apex/csrc/mlp.cpp:140:10: warning: unused variable ‘result’ [-Wunused-variable]\n","    140 |     auto result = mlp_bp<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:242:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    242 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n","    246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n","        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  [2/2] /usr/local/cuda-11.8/bin/nvcc  -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/mlp_cuda.cu -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17\n","  x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/mlp.o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/mlp_cuda.o -L/usr/local/lib/python3.11/dist-packages/torch/lib -L/usr/local/cuda-11.8/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/mlp_cuda.cpython-311-x86_64-linux-gnu.so\n","  building 'fused_dense_cuda' extension\n","  Emitting ninja build file /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/build.ninja...\n","  Compiling objects...\n","  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n","  [1/2] c++ -MMD -MF /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/fused_dense.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/fused_dense.cpp -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/fused_dense.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_dense_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp: In function ‘at::Tensor linear_bias_forward(at::Tensor, at::Tensor, at::Tensor)’:\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:30:62: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     30 |   auto out = at::empty({batch_size, out_features}, input.type());\n","        |                                                    ~~~~~~~~~~^~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n","    225 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:33:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     33 |   auto lt_workspace = at::empty({1 << 22}, input.type());\n","        |                                            ~~~~~~~~~~^~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n","    225 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/ATen.h:11,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/fused_dense.cpp:1:\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp: In lambda function:\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:37:15: warning: unused variable ‘b_ptr’ [-Wunused-variable]\n","     37 |     scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n","        |               ^~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:233:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    233 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n","    267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:38:10: warning: unused variable ‘result’ [-Wunused-variable]\n","     38 |     auto result = linear_bias_forward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:233:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    233 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n","    267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp: In lambda function:\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:37:15: warning: unused variable ‘b_ptr’ [-Wunused-variable]\n","     37 |     scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n","        |               ^~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:234:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    234 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n","    267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:38:10: warning: unused variable ‘result’ [-Wunused-variable]\n","     38 |     auto result = linear_bias_forward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:234:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    234 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n","    267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp: In lambda function:\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:37:15: warning: unused variable ‘b_ptr’ [-Wunused-variable]\n","     37 |     scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n","        |               ^~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    268 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:38:10: warning: unused variable ‘result’ [-Wunused-variable]\n","     38 |     auto result = linear_bias_forward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    268 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp: In lambda function:\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:37:15: warning: unused variable ‘b_ptr’ [-Wunused-variable]\n","     37 |     scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n","        |               ^~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:269:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    269 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:38:10: warning: unused variable ‘result’ [-Wunused-variable]\n","     38 |     auto result = linear_bias_forward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:269:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    269 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp: In function ‘std::vector<at::Tensor> linear_bias_backward(at::Tensor, at::Tensor, at::Tensor)’:\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:64:68: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     64 |   auto d_weight = at::empty({out_features, in_features}, input.type());\n","        |                                                          ~~~~~~~~~~^~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n","    225 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:68:53: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     68 |   auto d_bias = at::empty({out_features}, input.type());\n","        |                                           ~~~~~~~~~~^~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n","    225 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:70:65: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     70 |   auto d_input = at::empty({batch_size, in_features}, input.type());\n","        |                                                       ~~~~~~~~~~^~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n","    225 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:73:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     73 |   auto lt_workspace = at::empty({1 << 22}, input.type());\n","        |                                            ~~~~~~~~~~^~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n","    225 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/ATen.h:11,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/fused_dense.cpp:1:\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp: In lambda function:\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:77:15: warning: unused variable ‘d_b_ptr’ [-Wunused-variable]\n","     77 |     scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n","        |               ^~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:233:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    233 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n","    267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n","     78 |     auto result = linear_bias_backward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:233:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    233 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n","    267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp: In lambda function:\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:77:15: warning: unused variable ‘d_b_ptr’ [-Wunused-variable]\n","     77 |     scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n","        |               ^~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:234:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    234 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n","    267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n","     78 |     auto result = linear_bias_backward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:234:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    234 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n","    267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp: In lambda function:\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:77:15: warning: unused variable ‘d_b_ptr’ [-Wunused-variable]\n","     77 |     scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n","        |               ^~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    268 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n","     78 |     auto result = linear_bias_backward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    268 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp: In lambda function:\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:77:15: warning: unused variable ‘d_b_ptr’ [-Wunused-variable]\n","     77 |     scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n","        |               ^~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:269:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    269 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n","     78 |     auto result = linear_bias_backward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:269:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    269 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp: In function ‘std::vector<at::Tensor> linear_gelu_linear_forward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor)’:\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:106:69: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    106 |   auto output1 = at::empty({batch_size, hidden_features}, input.type());\n","        |                                                           ~~~~~~~~~~^~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n","    225 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:107:69: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    107 |   auto gelu_in = at::empty({batch_size, hidden_features}, input.type());\n","        |                                                           ~~~~~~~~~~^~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n","    225 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:108:66: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    108 |   auto output2 = at::empty({batch_size, out_features}, input.type());\n","        |                                                        ~~~~~~~~~~^~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n","    225 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:111:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    111 |   auto lt_workspace = at::empty({1 << 22}, input.type());\n","        |                                            ~~~~~~~~~~^~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n","    225 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/ATen.h:11,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/fused_dense.cpp:1:\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp: In lambda function:\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:118:10: warning: unused variable ‘result’ [-Wunused-variable]\n","    118 |     auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:233:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    233 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n","    267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","    113 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_gelu_linear_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp: In lambda function:\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:118:10: warning: unused variable ‘result’ [-Wunused-variable]\n","    118 |     auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:234:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    234 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n","    267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","    113 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_gelu_linear_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp: In lambda function:\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:118:10: warning: unused variable ‘result’ [-Wunused-variable]\n","    118 |     auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    268 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","    113 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_gelu_linear_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp: In lambda function:\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:118:10: warning: unused variable ‘result’ [-Wunused-variable]\n","    118 |     auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:269:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    269 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","    113 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_gelu_linear_forward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp: In function ‘std::vector<at::Tensor> linear_gelu_linear_backward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor)’:\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:149:72: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    149 |   auto d_weight1 = at::empty({hidden_features, in_features}, input.type());\n","        |                                                              ~~~~~~~~~~^~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n","    225 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:150:73: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    150 |   auto d_weight2 = at::empty({out_features, hidden_features}, input.type());\n","        |                                                               ~~~~~~~~~~^~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n","    225 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:151:57: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    151 |   auto d_bias1 = at::empty({hidden_features}, input.type());\n","        |                                               ~~~~~~~~~~^~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n","    225 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:152:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    152 |   auto d_bias2 = at::empty({out_features}, input.type());\n","        |                                            ~~~~~~~~~~^~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n","    225 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:153:65: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    153 |   auto d_input = at::empty({batch_size, in_features}, input.type());\n","        |                                                       ~~~~~~~~~~^~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n","    225 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:154:71: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    154 |   auto d_output1 = at::empty({batch_size, hidden_features}, input.type());\n","        |                                                             ~~~~~~~~~~^~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n","    225 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:157:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","    157 |   auto lt_workspace = at::empty({1 << 22}, input.type());\n","        |                                            ~~~~~~~~~~^~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Tensor.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/fused_dense.cpp:1:\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n","    225 |   DeprecatedTypeProperties & type() const {\n","        |                              ^~~~\n","  In file included from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/ATen.h:11,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n","                   from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n","                   from /root/moe-recipes/apex/csrc/fused_dense.cpp:1:\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp: In lambda function:\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:163:10: warning: unused variable ‘result’ [-Wunused-variable]\n","    163 |     auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:233:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    233 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n","    267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","    159 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp: In lambda function:\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:163:10: warning: unused variable ‘result’ [-Wunused-variable]\n","    163 |     auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:234:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    234 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n","    267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","    159 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp: In lambda function:\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:163:10: warning: unused variable ‘result’ [-Wunused-variable]\n","    163 |     auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    268 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","    159 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp: In lambda function:\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:163:10: warning: unused variable ‘result’ [-Wunused-variable]\n","    163 |     auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n","        |          ^~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n","    221 |       __VA_ARGS__                                                           \\\n","        |       ^~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n","     74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:269:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n","    269 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n","        |   ^~~~~~~~~~~~~~~~\n","  /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n","    276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n","        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  /root/moe-recipes/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n","    159 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n","        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","  [2/2] /usr/local/cuda-11.8/bin/nvcc  -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/fused_dense_cuda.cu -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/fused_dense_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_dense_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17\n","  x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/fused_dense.o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/fused_dense_cuda.o -L/usr/local/lib/python3.11/dist-packages/torch/lib -L/usr/local/cuda-11.8/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/fused_dense_cuda.cpython-311-x86_64-linux-gnu.so\n","  building 'scaled_upper_triang_masked_softmax_cuda' extension\n","  creating /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron\n","  Emitting ninja build file /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/build.ninja...\n","  Compiling objects...\n","  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n","  [1/2] c++ -MMD -MF /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/scaled_upper_triang_masked_softmax.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/root/moe-recipes/apex/csrc -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/megatron/scaled_upper_triang_masked_softmax.cpp -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/scaled_upper_triang_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","  [2/2] /usr/local/cuda-11.8/bin/nvcc  -I/root/moe-recipes/apex/csrc -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.cu -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17\n","  x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/scaled_upper_triang_masked_softmax.o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.o -L/usr/local/lib/python3.11/dist-packages/torch/lib -L/usr/local/cuda-11.8/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/scaled_upper_triang_masked_softmax_cuda.cpython-311-x86_64-linux-gnu.so\n","  building 'generic_scaled_masked_softmax_cuda' extension\n","  Emitting ninja build file /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/build.ninja...\n","  Compiling objects...\n","  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n","  [1/2] c++ -MMD -MF /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/generic_scaled_masked_softmax.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/root/moe-recipes/apex/csrc -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/megatron/generic_scaled_masked_softmax.cpp -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/generic_scaled_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=generic_scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","  [2/2] /usr/local/cuda-11.8/bin/nvcc  -I/root/moe-recipes/apex/csrc -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/megatron/generic_scaled_masked_softmax_cuda.cu -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/generic_scaled_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=generic_scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17\n","  x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/generic_scaled_masked_softmax.o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/generic_scaled_masked_softmax_cuda.o -L/usr/local/lib/python3.11/dist-packages/torch/lib -L/usr/local/cuda-11.8/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/generic_scaled_masked_softmax_cuda.cpython-311-x86_64-linux-gnu.so\n","  building 'scaled_masked_softmax_cuda' extension\n","  Emitting ninja build file /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/build.ninja...\n","  Compiling objects...\n","  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n","  [1/2] c++ -MMD -MF /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/scaled_masked_softmax.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/root/moe-recipes/apex/csrc -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/megatron/scaled_masked_softmax.cpp -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/scaled_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","  [2/2] /usr/local/cuda-11.8/bin/nvcc  -I/root/moe-recipes/apex/csrc -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/megatron/scaled_masked_softmax_cuda.cu -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/scaled_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17\n","  x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/scaled_masked_softmax.o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/scaled_masked_softmax_cuda.o -L/usr/local/lib/python3.11/dist-packages/torch/lib -L/usr/local/cuda-11.8/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/scaled_masked_softmax_cuda.cpython-311-x86_64-linux-gnu.so\n","  building 'scaled_softmax_cuda' extension\n","  Emitting ninja build file /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/build.ninja...\n","  Compiling objects...\n","  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n","  [1/2] c++ -MMD -MF /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/scaled_softmax.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/root/moe-recipes/apex/csrc -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/megatron/scaled_softmax.cpp -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/scaled_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","  [2/2] /usr/local/cuda-11.8/bin/nvcc  -I/root/moe-recipes/apex/csrc -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/megatron/scaled_softmax_cuda.cu -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/scaled_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17\n","  x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/scaled_softmax.o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/scaled_softmax_cuda.o -L/usr/local/lib/python3.11/dist-packages/torch/lib -L/usr/local/cuda-11.8/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/scaled_softmax_cuda.cpython-311-x86_64-linux-gnu.so\n","  building 'fused_rotary_positional_embedding' extension\n","  Emitting ninja build file /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/build.ninja...\n","  Compiling objects...\n","  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n","  [1/2] c++ -MMD -MF /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/fused_rotary_positional_embedding.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/root/moe-recipes/apex/csrc -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/megatron/fused_rotary_positional_embedding.cpp -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/fused_rotary_positional_embedding.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_rotary_positional_embedding -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","  [2/2] /usr/local/cuda-11.8/bin/nvcc  -I/root/moe-recipes/apex/csrc -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/megatron/fused_rotary_positional_embedding_cuda.cu -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/fused_rotary_positional_embedding_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_rotary_positional_embedding -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17\n","  x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/fused_rotary_positional_embedding.o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/fused_rotary_positional_embedding_cuda.o -L/usr/local/lib/python3.11/dist-packages/torch/lib -L/usr/local/cuda-11.8/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/fused_rotary_positional_embedding.cpython-311-x86_64-linux-gnu.so\n","  building 'fused_weight_gradient_mlp_cuda' extension\n","  Emitting ninja build file /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/build.ninja...\n","  Compiling objects...\n","  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n","  [1/3] c++ -MMD -MF /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/fused_weight_gradient_dense.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/root/moe-recipes/apex/csrc -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/megatron/fused_weight_gradient_dense.cpp -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/fused_weight_gradient_dense.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_weight_gradient_mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","  [2/3] /usr/local/cuda-11.8/bin/nvcc  -I/root/moe-recipes/apex/csrc -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/megatron/fused_weight_gradient_dense_cuda.cu -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/fused_weight_gradient_dense_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_weight_gradient_mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","  [3/3] /usr/local/cuda-11.8/bin/nvcc  -I/root/moe-recipes/apex/csrc -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda-11.8/include -I/usr/include/python3.11 -c -c /root/moe-recipes/apex/csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.cu -o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_weight_gradient_mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","  x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/fused_weight_gradient_dense.o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.o /root/moe-recipes/apex/build/temp.linux-x86_64-cpython-311/csrc/megatron/fused_weight_gradient_dense_cuda.o -L/usr/local/lib/python3.11/dist-packages/torch/lib -L/usr/local/cuda-11.8/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda.cpython-311-x86_64-linux-gnu.so\n","  installing to build/bdist.linux-x86_64/wheel\n","  running install\n","  running install_lib\n","  creating build/bdist.linux-x86_64\n","  creating build/bdist.linux-x86_64/wheel\n","  copying build/lib.linux-x86_64-cpython-311/fused_rotary_positional_embedding.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n","  creating build/bdist.linux-x86_64/wheel/apex\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/bottleneck/bottleneck.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/bottleneck/halo_exchangers.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/bottleneck/test.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/bottleneck/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/fmha/fmha.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/fmha/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/conv_bias_relu\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/conv_bias_relu/conv_bias_relu.py -> build/bdist.linux-x86_64/wheel/apex/contrib/conv_bias_relu\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/conv_bias_relu/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/conv_bias_relu\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/openfold_triton\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton/_layer_norm_config_ampere.py -> build/bdist.linux-x86_64/wheel/apex/contrib/openfold_triton\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton/_mha_kernel.py -> build/bdist.linux-x86_64/wheel/apex/contrib/openfold_triton\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton/fused_adam_swa.py -> build/bdist.linux-x86_64/wheel/apex/contrib/openfold_triton\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton/_layer_norm_config_hopper.py -> build/bdist.linux-x86_64/wheel/apex/contrib/openfold_triton\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton/_layer_norm_backward_kernels.py -> build/bdist.linux-x86_64/wheel/apex/contrib/openfold_triton\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton/mha.py -> build/bdist.linux-x86_64/wheel/apex/contrib/openfold_triton\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton/layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/openfold_triton\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton/_layer_norm_forward_kernels.py -> build/bdist.linux-x86_64/wheel/apex/contrib/openfold_triton\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/openfold_triton\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/cudnn_gbn\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/cudnn_gbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/cudnn_gbn\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/cudnn_gbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/cudnn_gbn\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/gpu_direct_storage\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/gpu_direct_storage/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/gpu_direct_storage\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/layer_norm/layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/layer_norm/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels/channel_swap.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/sparse_masklib.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_lib.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/asp.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/index_mul_2d\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/index_mul_2d/index_mul_2d.py -> build/bdist.linux-x86_64/wheel/apex/contrib/index_mul_2d\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/index_mul_2d/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/index_mul_2d\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/bottleneck\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/bottleneck/test_bottleneck_module.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/bottleneck\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/bottleneck/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/bottleneck\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/fmha\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/fmha/test_fmha.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/fmha\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/fmha/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/fmha\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/conv_bias_relu\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/conv_bias_relu\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/conv_bias_relu/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/conv_bias_relu\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/cudnn_gbn\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/cudnn_gbn\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/cudnn_gbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/cudnn_gbn\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/optimizers\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/optimizers/test_distributed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/optimizers\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/optimizers/test_dist_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/optimizers\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/optimizers\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/layer_norm\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/layer_norm/test_fast_layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/layer_norm\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/layer_norm/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/layer_norm\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/index_mul_2d\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/index_mul_2d/test_index_mul_2d.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/index_mul_2d\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/index_mul_2d/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/index_mul_2d\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/transducer\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/transducer/test_transducer_joint.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/transducer\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/transducer/test_transducer_loss.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/transducer\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/transducer/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/transducer\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/xentropy\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/xentropy/test_label_smoothing.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/xentropy\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/xentropy\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/clip_grad\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/clip_grad/test_clip_grad.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/clip_grad\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/clip_grad/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/clip_grad\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/peer_memory\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/peer_memory\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/peer_memory/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/peer_memory\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/group_norm\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/group_norm/test_group_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/group_norm\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/group_norm/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/group_norm\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/focal_loss\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/focal_loss/test_focal_loss.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/focal_loss\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/focal_loss/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/focal_loss\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn/test_self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn/test_mha_fused_softmax.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/transducer/transducer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/transducer/_transducer_ref.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/transducer/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/clip_grad\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/clip_grad/clip_grad.py -> build/bdist.linux-x86_64/wheel/apex/contrib/clip_grad\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/clip_grad/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/clip_grad\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/peer_memory\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/peer_memory/peer_halo_exchanger_1d.py -> build/bdist.linux-x86_64/wheel/apex/contrib/peer_memory\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/peer_memory/peer_memory.py -> build/bdist.linux-x86_64/wheel/apex/contrib/peer_memory\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/peer_memory/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/peer_memory\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/group_norm\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/group_norm/group_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/group_norm\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/group_norm/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/group_norm\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/focal_loss\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/focal_loss/focal_loss.py -> build/bdist.linux-x86_64/wheel/apex/contrib/focal_loss\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/focal_loss/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/focal_loss\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  creating build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib.linux-x86_64-cpython-311/apex/amp/scaler.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib.linux-x86_64-cpython-311/apex/amp/handle.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib.linux-x86_64-cpython-311/apex/amp/_initialize.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib.linux-x86_64-cpython-311/apex/amp/compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib.linux-x86_64-cpython-311/apex/amp/__version__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib.linux-x86_64-cpython-311/apex/amp/opt.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib.linux-x86_64-cpython-311/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib.linux-x86_64-cpython-311/apex/amp/amp.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  creating build/bdist.linux-x86_64/wheel/apex/amp/lists\n","  copying build/lib.linux-x86_64-cpython-311/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n","  copying build/lib.linux-x86_64-cpython-311/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n","  copying build/lib.linux-x86_64-cpython-311/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n","  copying build/lib.linux-x86_64-cpython-311/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n","  copying build/lib.linux-x86_64-cpython-311/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib.linux-x86_64-cpython-311/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib.linux-x86_64-cpython-311/apex/amp/wrap.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib.linux-x86_64-cpython-311/apex/amp/frontend.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib.linux-x86_64-cpython-311/apex/amp/utils.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib.linux-x86_64-cpython-311/apex/amp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  creating build/bdist.linux-x86_64/wheel/apex/fp16_utils\n","  copying build/lib.linux-x86_64-cpython-311/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n","  copying build/lib.linux-x86_64-cpython-311/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n","  copying build/lib.linux-x86_64-cpython-311/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n","  copying build/lib.linux-x86_64-cpython-311/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n","  creating build/bdist.linux-x86_64/wheel/apex/mlp\n","  copying build/lib.linux-x86_64-cpython-311/apex/mlp/mlp.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n","  copying build/lib.linux-x86_64-cpython-311/apex/mlp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n","  creating build/bdist.linux-x86_64/wheel/apex/transformer\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/microbatches.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/log_util.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/parallel_state.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n","  creating build/bdist.linux-x86_64/wheel/apex/transformer/amp\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/amp/grad_scaler.py -> build/bdist.linux-x86_64/wheel/apex/transformer/amp\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/amp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/amp\n","  creating build/bdist.linux-x86_64/wheel/apex/transformer/layers\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/layers/layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/transformer/layers\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/layers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/layers\n","  creating build/bdist.linux-x86_64/wheel/apex/transformer/_data\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/_data/_batchsampler.py -> build/bdist.linux-x86_64/wheel/apex/transformer/_data\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/_data/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/_data\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/enums.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n","  creating build/bdist.linux-x86_64/wheel/apex/transformer/testing\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/testing/commons.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/testing/distributed_test_base.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/testing/standalone_transformer_lm.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/testing/global_vars.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/testing/standalone_gpt.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/testing/standalone_bert.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/testing/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/testing/arguments.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n","  creating build/bdist.linux-x86_64/wheel/apex/transformer/functional\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/functional/fused_softmax.py -> build/bdist.linux-x86_64/wheel/apex/transformer/functional\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/functional/fused_rope.py -> build/bdist.linux-x86_64/wheel/apex/transformer/functional\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/functional/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/functional\n","  creating build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel/layers.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel/random.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel/data.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel/mappings.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel/cross_entropy.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel/memory.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel/utils.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/_ucc_util.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/utils.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n","  creating build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/_timers.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel\n","  creating build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules/common.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/utils.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel\n","  copying build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/p2p_communication.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel\n","  creating build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n","  copying build/lib.linux-x86_64-cpython-311/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n","  copying build/lib.linux-x86_64-cpython-311/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n","  creating build/bdist.linux-x86_64/wheel/apex/fused_dense\n","  copying build/lib.linux-x86_64-cpython-311/apex/fused_dense/fused_dense.py -> build/bdist.linux-x86_64/wheel/apex/fused_dense\n","  copying build/lib.linux-x86_64-cpython-311/apex/fused_dense/__init__.py -> build/bdist.linux-x86_64/wheel/apex/fused_dense\n","  copying build/lib.linux-x86_64-cpython-311/apex/_autocast_utils.py -> build/bdist.linux-x86_64/wheel/apex\n","  creating build/bdist.linux-x86_64/wheel/apex/optimizers\n","  copying build/lib.linux-x86_64-cpython-311/apex/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n","  copying build/lib.linux-x86_64-cpython-311/apex/optimizers/fused_mixed_precision_lamb.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n","  copying build/lib.linux-x86_64-cpython-311/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n","  copying build/lib.linux-x86_64-cpython-311/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n","  copying build/lib.linux-x86_64-cpython-311/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n","  copying build/lib.linux-x86_64-cpython-311/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n","  copying build/lib.linux-x86_64-cpython-311/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n","  creating build/bdist.linux-x86_64/wheel/apex/normalization\n","  copying build/lib.linux-x86_64-cpython-311/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n","  copying build/lib.linux-x86_64-cpython-311/apex/normalization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n","  creating build/bdist.linux-x86_64/wheel/apex/RNN\n","  copying build/lib.linux-x86_64-cpython-311/apex/RNN/models.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n","  copying build/lib.linux-x86_64-cpython-311/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n","  copying build/lib.linux-x86_64-cpython-311/apex/RNN/cells.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n","  copying build/lib.linux-x86_64-cpython-311/apex/RNN/__init__.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n","  creating build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib.linux-x86_64-cpython-311/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib.linux-x86_64-cpython-311/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib.linux-x86_64-cpython-311/apex/parallel/distributed.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib.linux-x86_64-cpython-311/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib.linux-x86_64-cpython-311/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib.linux-x86_64-cpython-311/apex/parallel/LARC.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib.linux-x86_64-cpython-311/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib.linux-x86_64-cpython-311/apex/parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib.linux-x86_64-cpython-311/apex/__init__.py -> build/bdist.linux-x86_64/wheel/apex\n","  copying build/lib.linux-x86_64-cpython-311/mlp_cuda.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n","  copying build/lib.linux-x86_64-cpython-311/scaled_upper_triang_masked_softmax_cuda.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n","  copying build/lib.linux-x86_64-cpython-311/syncbn.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n","  copying build/lib.linux-x86_64-cpython-311/apex_C.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n","  copying build/lib.linux-x86_64-cpython-311/fused_layer_norm_cuda.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n","  copying build/lib.linux-x86_64-cpython-311/fused_dense_cuda.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n","  copying build/lib.linux-x86_64-cpython-311/scaled_masked_softmax_cuda.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n","  copying build/lib.linux-x86_64-cpython-311/generic_scaled_masked_softmax_cuda.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n","  copying build/lib.linux-x86_64-cpython-311/scaled_softmax_cuda.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n","  copying build/lib.linux-x86_64-cpython-311/amp_C.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n","  copying build/lib.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n","  running install_egg_info\n","  running egg_info\n","  creating apex.egg-info\n","  writing apex.egg-info/PKG-INFO\n","  writing dependency_links to apex.egg-info/dependency_links.txt\n","  writing requirements to apex.egg-info/requires.txt\n","  writing top-level names to apex.egg-info/top_level.txt\n","  writing manifest file 'apex.egg-info/SOURCES.txt'\n","  reading manifest file 'apex.egg-info/SOURCES.txt'\n","  adding license file 'LICENSE'\n","  writing manifest file 'apex.egg-info/SOURCES.txt'\n","  Copying apex.egg-info to build/bdist.linux-x86_64/wheel/apex-0.1-py3.11.egg-info\n","  running install_scripts\n","  creating build/bdist.linux-x86_64/wheel/apex-0.1.dist-info/WHEEL\n","  creating '/tmp/pip-wheel-zn7hpfjp/.tmp-prkesjmg/apex-0.1-cp311-cp311-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n","  adding 'amp_C.cpython-311-x86_64-linux-gnu.so'\n","  adding 'apex_C.cpython-311-x86_64-linux-gnu.so'\n","  adding 'fused_dense_cuda.cpython-311-x86_64-linux-gnu.so'\n","  adding 'fused_layer_norm_cuda.cpython-311-x86_64-linux-gnu.so'\n","  adding 'fused_rotary_positional_embedding.cpython-311-x86_64-linux-gnu.so'\n","  adding 'fused_weight_gradient_mlp_cuda.cpython-311-x86_64-linux-gnu.so'\n","  adding 'generic_scaled_masked_softmax_cuda.cpython-311-x86_64-linux-gnu.so'\n","  adding 'mlp_cuda.cpython-311-x86_64-linux-gnu.so'\n","  adding 'scaled_masked_softmax_cuda.cpython-311-x86_64-linux-gnu.so'\n","  adding 'scaled_softmax_cuda.cpython-311-x86_64-linux-gnu.so'\n","  adding 'scaled_upper_triang_masked_softmax_cuda.cpython-311-x86_64-linux-gnu.so'\n","  adding 'syncbn.cpython-311-x86_64-linux-gnu.so'\n","  adding 'apex/__init__.py'\n","  adding 'apex/_autocast_utils.py'\n","  adding 'apex/RNN/RNNBackend.py'\n","  adding 'apex/RNN/__init__.py'\n","  adding 'apex/RNN/cells.py'\n","  adding 'apex/RNN/models.py'\n","  adding 'apex/amp/__init__.py'\n","  adding 'apex/amp/__version__.py'\n","  adding 'apex/amp/_amp_state.py'\n","  adding 'apex/amp/_initialize.py'\n","  adding 'apex/amp/_process_optimizer.py'\n","  adding 'apex/amp/amp.py'\n","  adding 'apex/amp/compat.py'\n","  adding 'apex/amp/frontend.py'\n","  adding 'apex/amp/handle.py'\n","  adding 'apex/amp/opt.py'\n","  adding 'apex/amp/rnn_compat.py'\n","  adding 'apex/amp/scaler.py'\n","  adding 'apex/amp/utils.py'\n","  adding 'apex/amp/wrap.py'\n","  adding 'apex/amp/lists/__init__.py'\n","  adding 'apex/amp/lists/functional_overrides.py'\n","  adding 'apex/amp/lists/tensor_overrides.py'\n","  adding 'apex/amp/lists/torch_overrides.py'\n","  adding 'apex/contrib/__init__.py'\n","  adding 'apex/contrib/bottleneck/__init__.py'\n","  adding 'apex/contrib/bottleneck/bottleneck.py'\n","  adding 'apex/contrib/bottleneck/halo_exchangers.py'\n","  adding 'apex/contrib/bottleneck/test.py'\n","  adding 'apex/contrib/clip_grad/__init__.py'\n","  adding 'apex/contrib/clip_grad/clip_grad.py'\n","  adding 'apex/contrib/conv_bias_relu/__init__.py'\n","  adding 'apex/contrib/conv_bias_relu/conv_bias_relu.py'\n","  adding 'apex/contrib/cudnn_gbn/__init__.py'\n","  adding 'apex/contrib/cudnn_gbn/batch_norm.py'\n","  adding 'apex/contrib/fmha/__init__.py'\n","  adding 'apex/contrib/fmha/fmha.py'\n","  adding 'apex/contrib/focal_loss/__init__.py'\n","  adding 'apex/contrib/focal_loss/focal_loss.py'\n","  adding 'apex/contrib/gpu_direct_storage/__init__.py'\n","  adding 'apex/contrib/group_norm/__init__.py'\n","  adding 'apex/contrib/group_norm/group_norm.py'\n","  adding 'apex/contrib/groupbn/__init__.py'\n","  adding 'apex/contrib/groupbn/batch_norm.py'\n","  adding 'apex/contrib/index_mul_2d/__init__.py'\n","  adding 'apex/contrib/index_mul_2d/index_mul_2d.py'\n","  adding 'apex/contrib/layer_norm/__init__.py'\n","  adding 'apex/contrib/layer_norm/layer_norm.py'\n","  adding 'apex/contrib/multihead_attn/__init__.py'\n","  adding 'apex/contrib/multihead_attn/encdec_multihead_attn.py'\n","  adding 'apex/contrib/multihead_attn/encdec_multihead_attn_func.py'\n","  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py'\n","  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py'\n","  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_func.py'\n","  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py'\n","  adding 'apex/contrib/multihead_attn/mask_softmax_dropout_func.py'\n","  adding 'apex/contrib/multihead_attn/self_multihead_attn.py'\n","  adding 'apex/contrib/multihead_attn/self_multihead_attn_func.py'\n","  adding 'apex/contrib/openfold_triton/__init__.py'\n","  adding 'apex/contrib/openfold_triton/_layer_norm_backward_kernels.py'\n","  adding 'apex/contrib/openfold_triton/_layer_norm_config_ampere.py'\n","  adding 'apex/contrib/openfold_triton/_layer_norm_config_hopper.py'\n","  adding 'apex/contrib/openfold_triton/_layer_norm_forward_kernels.py'\n","  adding 'apex/contrib/openfold_triton/_mha_kernel.py'\n","  adding 'apex/contrib/openfold_triton/fused_adam_swa.py'\n","  adding 'apex/contrib/openfold_triton/layer_norm.py'\n","  adding 'apex/contrib/openfold_triton/mha.py'\n","  adding 'apex/contrib/optimizers/__init__.py'\n","  adding 'apex/contrib/optimizers/distributed_fused_adam.py'\n","  adding 'apex/contrib/optimizers/distributed_fused_lamb.py'\n","  adding 'apex/contrib/optimizers/fp16_optimizer.py'\n","  adding 'apex/contrib/optimizers/fused_adam.py'\n","  adding 'apex/contrib/optimizers/fused_lamb.py'\n","  adding 'apex/contrib/optimizers/fused_sgd.py'\n","  adding 'apex/contrib/peer_memory/__init__.py'\n","  adding 'apex/contrib/peer_memory/peer_halo_exchanger_1d.py'\n","  adding 'apex/contrib/peer_memory/peer_memory.py'\n","  adding 'apex/contrib/sparsity/__init__.py'\n","  adding 'apex/contrib/sparsity/asp.py'\n","  adding 'apex/contrib/sparsity/permutation_lib.py'\n","  adding 'apex/contrib/sparsity/sparse_masklib.py'\n","  adding 'apex/contrib/sparsity/permutation_search_kernels/__init__.py'\n","  adding 'apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py'\n","  adding 'apex/contrib/sparsity/permutation_search_kernels/channel_swap.py'\n","  adding 'apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py'\n","  adding 'apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py'\n","  adding 'apex/contrib/test/__init__.py'\n","  adding 'apex/contrib/test/bottleneck/__init__.py'\n","  adding 'apex/contrib/test/bottleneck/test_bottleneck_module.py'\n","  adding 'apex/contrib/test/clip_grad/__init__.py'\n","  adding 'apex/contrib/test/clip_grad/test_clip_grad.py'\n","  adding 'apex/contrib/test/conv_bias_relu/__init__.py'\n","  adding 'apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py'\n","  adding 'apex/contrib/test/cudnn_gbn/__init__.py'\n","  adding 'apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py'\n","  adding 'apex/contrib/test/fmha/__init__.py'\n","  adding 'apex/contrib/test/fmha/test_fmha.py'\n","  adding 'apex/contrib/test/focal_loss/__init__.py'\n","  adding 'apex/contrib/test/focal_loss/test_focal_loss.py'\n","  adding 'apex/contrib/test/group_norm/__init__.py'\n","  adding 'apex/contrib/test/group_norm/test_group_norm.py'\n","  adding 'apex/contrib/test/index_mul_2d/__init__.py'\n","  adding 'apex/contrib/test/index_mul_2d/test_index_mul_2d.py'\n","  adding 'apex/contrib/test/layer_norm/__init__.py'\n","  adding 'apex/contrib/test/layer_norm/test_fast_layer_norm.py'\n","  adding 'apex/contrib/test/multihead_attn/__init__.py'\n","  adding 'apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py'\n","  adding 'apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py'\n","  adding 'apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py'\n","  adding 'apex/contrib/test/multihead_attn/test_mha_fused_softmax.py'\n","  adding 'apex/contrib/test/multihead_attn/test_self_multihead_attn.py'\n","  adding 'apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py'\n","  adding 'apex/contrib/test/optimizers/__init__.py'\n","  adding 'apex/contrib/test/optimizers/test_dist_adam.py'\n","  adding 'apex/contrib/test/optimizers/test_distributed_fused_lamb.py'\n","  adding 'apex/contrib/test/peer_memory/__init__.py'\n","  adding 'apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py'\n","  adding 'apex/contrib/test/transducer/__init__.py'\n","  adding 'apex/contrib/test/transducer/test_transducer_joint.py'\n","  adding 'apex/contrib/test/transducer/test_transducer_loss.py'\n","  adding 'apex/contrib/test/xentropy/__init__.py'\n","  adding 'apex/contrib/test/xentropy/test_label_smoothing.py'\n","  adding 'apex/contrib/transducer/__init__.py'\n","  adding 'apex/contrib/transducer/_transducer_ref.py'\n","  adding 'apex/contrib/transducer/transducer.py'\n","  adding 'apex/contrib/xentropy/__init__.py'\n","  adding 'apex/contrib/xentropy/softmax_xentropy.py'\n","  adding 'apex/fp16_utils/__init__.py'\n","  adding 'apex/fp16_utils/fp16_optimizer.py'\n","  adding 'apex/fp16_utils/fp16util.py'\n","  adding 'apex/fp16_utils/loss_scaler.py'\n","  adding 'apex/fused_dense/__init__.py'\n","  adding 'apex/fused_dense/fused_dense.py'\n","  adding 'apex/mlp/__init__.py'\n","  adding 'apex/mlp/mlp.py'\n","  adding 'apex/multi_tensor_apply/__init__.py'\n","  adding 'apex/multi_tensor_apply/multi_tensor_apply.py'\n","  adding 'apex/normalization/__init__.py'\n","  adding 'apex/normalization/fused_layer_norm.py'\n","  adding 'apex/optimizers/__init__.py'\n","  adding 'apex/optimizers/fused_adagrad.py'\n","  adding 'apex/optimizers/fused_adam.py'\n","  adding 'apex/optimizers/fused_lamb.py'\n","  adding 'apex/optimizers/fused_mixed_precision_lamb.py'\n","  adding 'apex/optimizers/fused_novograd.py'\n","  adding 'apex/optimizers/fused_sgd.py'\n","  adding 'apex/parallel/LARC.py'\n","  adding 'apex/parallel/__init__.py'\n","  adding 'apex/parallel/distributed.py'\n","  adding 'apex/parallel/multiproc.py'\n","  adding 'apex/parallel/optimized_sync_batchnorm.py'\n","  adding 'apex/parallel/optimized_sync_batchnorm_kernel.py'\n","  adding 'apex/parallel/sync_batchnorm.py'\n","  adding 'apex/parallel/sync_batchnorm_kernel.py'\n","  adding 'apex/transformer/__init__.py'\n","  adding 'apex/transformer/_ucc_util.py'\n","  adding 'apex/transformer/enums.py'\n","  adding 'apex/transformer/log_util.py'\n","  adding 'apex/transformer/microbatches.py'\n","  adding 'apex/transformer/parallel_state.py'\n","  adding 'apex/transformer/utils.py'\n","  adding 'apex/transformer/_data/__init__.py'\n","  adding 'apex/transformer/_data/_batchsampler.py'\n","  adding 'apex/transformer/amp/__init__.py'\n","  adding 'apex/transformer/amp/grad_scaler.py'\n","  adding 'apex/transformer/functional/__init__.py'\n","  adding 'apex/transformer/functional/fused_rope.py'\n","  adding 'apex/transformer/functional/fused_softmax.py'\n","  adding 'apex/transformer/layers/__init__.py'\n","  adding 'apex/transformer/layers/layer_norm.py'\n","  adding 'apex/transformer/pipeline_parallel/__init__.py'\n","  adding 'apex/transformer/pipeline_parallel/_timers.py'\n","  adding 'apex/transformer/pipeline_parallel/p2p_communication.py'\n","  adding 'apex/transformer/pipeline_parallel/utils.py'\n","  adding 'apex/transformer/pipeline_parallel/schedules/__init__.py'\n","  adding 'apex/transformer/pipeline_parallel/schedules/common.py'\n","  adding 'apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py'\n","  adding 'apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py'\n","  adding 'apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py'\n","  adding 'apex/transformer/tensor_parallel/__init__.py'\n","  adding 'apex/transformer/tensor_parallel/cross_entropy.py'\n","  adding 'apex/transformer/tensor_parallel/data.py'\n","  adding 'apex/transformer/tensor_parallel/layers.py'\n","  adding 'apex/transformer/tensor_parallel/mappings.py'\n","  adding 'apex/transformer/tensor_parallel/memory.py'\n","  adding 'apex/transformer/tensor_parallel/random.py'\n","  adding 'apex/transformer/tensor_parallel/utils.py'\n","  adding 'apex/transformer/testing/__init__.py'\n","  adding 'apex/transformer/testing/arguments.py'\n","  adding 'apex/transformer/testing/commons.py'\n","  adding 'apex/transformer/testing/distributed_test_base.py'\n","  adding 'apex/transformer/testing/global_vars.py'\n","  adding 'apex/transformer/testing/standalone_bert.py'\n","  adding 'apex/transformer/testing/standalone_gpt.py'\n","  adding 'apex/transformer/testing/standalone_transformer_lm.py'\n","  adding 'apex-0.1.dist-info/LICENSE'\n","  adding 'apex-0.1.dist-info/METADATA'\n","  adding 'apex-0.1.dist-info/WHEEL'\n","  adding 'apex-0.1.dist-info/top_level.txt'\n","  adding 'apex-0.1.dist-info/RECORD'\n","  removing build/bdist.linux-x86_64/wheel\n","  Building wheel for apex (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for apex: filename=apex-0.1-cp311-cp311-linux_x86_64.whl size=35318726 sha256=3a264e1dcfc0e0946241a61c2ecf99bd33d350f98f454c657dec04d259072f94\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-y3d5t3wp/wheels/c9/9f/ec/bf87170e76dc0fc8811778b2cb4849a3e8fe08ea02cd115aa8\n","Successfully built apex\n","Installing collected packages: apex\n","Successfully installed apex-0.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"markdown","source":["W&Bにログイン\n","\n","https://wandb.ai/settings --> Danger Zone --> API keys --> APIキーをコピペ"],"metadata":{"id":"64SRSQje9yqR"}},{"cell_type":"code","source":["a03254954c2063bc42b84943579da0410bdc5da6"],"metadata":{"id":"nfpi2s4upbzp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wandb login"],"metadata":{"id":"kmVGuz5b9u2C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710825017464,"user_tz":-540,"elapsed":11270,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}},"outputId":"3b1678bb-b6a0-4da9-c591-861a6c6f6fde"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}]},{"cell_type":"code","source":["# W&Bにログインしていることを確認。\n","!cat ~/.netrc\n","# W&Bでプロジェクト"],"metadata":{"id":"40Lwiczm97BL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710825019501,"user_tz":-540,"elapsed":4,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}},"outputId":"542bb03f-58c8-491c-ee30-a08c6c931d07"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["machine api.wandb.ai\n","  login user\n","  password a03254954c2063bc42b84943579da0410bdc5da6\n"]}]},{"cell_type":"code","source":["import os\n","# 環境変数の設定\n","os.environ['OMPI_ALLOW_RUN_AS_ROOT'] = '1'\n","os.environ['OMPI_ALLOW_RUN_AS_ROOT_CONFIRM'] = '1'"],"metadata":{"id":"nz77cdeVjXoE","executionInfo":{"status":"ok","timestamp":1710825020909,"user_tz":-540,"elapsed":1,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["import sys\n","print(sys.path)\n","sys.path.append(\"/usr/local/lib/python3.11/dist-packages\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RMM2IKxAX3Tq","executionInfo":{"status":"ok","timestamp":1710825022097,"user_tz":-540,"elapsed":2,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}},"outputId":"f94e2caa-e016-415f-f755-a1568ca8d757"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["['/content', '/env/python', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.10/dist-packages/IPython/extensions', '/root/.ipython']\n"]}]},{"cell_type":"code","source":["import wandb\n","print(wandb.__path__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u41PDx-XDVkb","executionInfo":{"status":"ok","timestamp":1710825023906,"user_tz":-540,"elapsed":1207,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}},"outputId":"84c7150e-c462-42a1-c750-8b6e19ef6ae4"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["['/usr/local/lib/python3.11/dist-packages/wandb']\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"cJzhqomvvri5"}},{"cell_type":"code","source":["#cppファイル\n","%cd ~/moe-recipes/megatron_lm/megatron/core/datasets\n","!python setup.py build_ext --inplace"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Dea0EiAM5KA","executionInfo":{"status":"ok","timestamp":1710825033592,"user_tz":-540,"elapsed":7045,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}},"outputId":"323e2744-f370-46a2-f625-c272c0bacc16"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["/root/moe-recipes/megatron_lm/megatron/core/datasets\n","running build_ext\n","x86_64-linux-gnu-gcc -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/include/python3.11 -c flagcheck.cpp -o flagcheck.o -std=c++17\n","building 'helpers' extension\n","creating build\n","creating build/temp.linux-x86_64-cpython-311\n","x86_64-linux-gnu-gcc -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/pybind11/include -I/usr/include/python3.11 -c helpers.cpp -o build/temp.linux-x86_64-cpython-311/helpers.o -std=c++17 -fvisibility=hidden -g0\n","creating build/lib.linux-x86_64-cpython-311\n","x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-311/helpers.o -L/usr/lib/x86_64-linux-gnu -o build/lib.linux-x86_64-cpython-311/helpers.cpython-311-x86_64-linux-gnu.so\n","copying build/lib.linux-x86_64-cpython-311/helpers.cpython-311-x86_64-linux-gnu.so -> \n"]}]},{"cell_type":"code","source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""],"metadata":{"id":"jTbFMU83KbK_","executionInfo":{"status":"ok","timestamp":1710825825250,"user_tz":-540,"elapsed":629,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"0\""],"metadata":{"id":"2wlelnKUO42S","executionInfo":{"status":"ok","timestamp":1710826952592,"user_tz":-540,"elapsed":451,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["%cd ~/moe-recipes/scripts/abci/mixtral\n","!bash mixtral-7bx8_pretrain_colab.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710845591592,"user_tz":-540,"elapsed":3572326,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}},"outputId":"8d9392e3-e569-41bd-d80a-e3aef4a1823f","id":"w3dtcx9tTJ5m"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["/root/moe-recipes/scripts/abci/mixtral\n","\n","MASTER_ADDR=localhost\n","Unrecognized SGE_RESOURCE_TYPE: \n","Both .bin and .idx already exist.\n","\n","[2024-03-19 09:53:41,810] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","[2024-03-19 09:53:42,741] [INFO] [comm.py:637:init_distributed] cdb=None\n","[2024-03-19 09:53:42,741] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n","/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['even_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(even_batches=False)\n","  warnings.warn(\n","wandb: Currently logged in as: kumagai. Use `wandb login --relogin` to force relogin\n","wandb: Tracking run with wandb version 0.16.4\n","wandb: Run data is saved locally in /root/moe-recipes/scripts/abci/mixtral/wandb/run-20240319_095343-eh23k08k\n","wandb: Run `wandb offline` to turn off syncing.\n","wandb: Syncing run Mixtral-8x7b-NVE-okazaki-lab-cc--1node-1gpu-1024s-BS=256-LR=2e-5-MINLR=2e-6-WARMUP=1000-WD=0.1-GC=1\n","wandb: ⭐️ View project at https://wandb.ai/kumagai/Mixtral-8x7b\n","wandb: 🚀 View run at https://wandb.ai/kumagai/Mixtral-8x7b/runs/eh23k08k\n","Clearing GPU cache for all ranks\n","--> Running with torch torch_distributed debug set to detail\n"," > datasets target sizes (minimum size):\n","    train:      6400000\n","    validation: 642560\n","    test:       2560\n","> building train, validation, and test datasets for GPT ...\n","> finished creating GPT datasets ...\n","Gradient checkpointing enable\n","--> Model Mixtral_pretrain\n","\n","--> Mixtral_pretrain has 262.70208 Million params\n","\n","[2024-03-19 09:53:49,851] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n","[2024-03-19 09:53:50,034] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n","[2024-03-19 09:53:50,035] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n","[2024-03-19 09:53:50,035] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n","[2024-03-19 09:53:50,037] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW\n","[2024-03-19 09:53:50,038] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>\n","[2024-03-19 09:53:50,038] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False\n","[2024-03-19 09:53:50,038] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer\n","[2024-03-19 09:53:50,154] [INFO] [utils.py:800:see_memory_usage] Stage 3 initialize beginning\n","[2024-03-19 09:53:50,155] [INFO] [utils.py:801:see_memory_usage] MA 0.49 GB         Max_MA 0.49 GB         CA 0.61 GB         Max_CA 1 GB \n","[2024-03-19 09:53:50,155] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 4.87 GB, percent = 5.8%\n","[2024-03-19 09:53:50,156] [INFO] [stage3.py:130:__init__] Reduce bucket size 1048576\n","[2024-03-19 09:53:50,157] [INFO] [stage3.py:131:__init__] Prefetch bucket size 0\n","[2024-03-19 09:53:50,265] [INFO] [utils.py:800:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]\n","[2024-03-19 09:53:50,265] [INFO] [utils.py:801:see_memory_usage] MA 0.49 GB         Max_MA 0.49 GB         CA 0.61 GB         Max_CA 1 GB \n","[2024-03-19 09:53:50,266] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 4.87 GB, percent = 5.8%\n","Parameter Offload: Total persistent parameters: 33792 in 25 params\n","[2024-03-19 09:53:50,413] [INFO] [utils.py:800:see_memory_usage] DeepSpeedZeRoOffload initialize [end]\n","[2024-03-19 09:53:50,413] [INFO] [utils.py:801:see_memory_usage] MA 0.49 GB         Max_MA 0.55 GB         CA 0.73 GB         Max_CA 1 GB \n","[2024-03-19 09:53:50,414] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 4.87 GB, percent = 5.8%\n","[2024-03-19 09:53:50,505] [INFO] [utils.py:800:see_memory_usage] Before creating fp16 partitions\n","[2024-03-19 09:53:50,506] [INFO] [utils.py:801:see_memory_usage] MA 0.49 GB         Max_MA 0.49 GB         CA 0.73 GB         Max_CA 1 GB \n","[2024-03-19 09:53:50,506] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 4.87 GB, percent = 5.8%\n","[2024-03-19 09:53:51,317] [INFO] [utils.py:800:see_memory_usage] After creating fp16 partitions: 1\n","[2024-03-19 09:53:51,317] [INFO] [utils.py:801:see_memory_usage] MA 0.49 GB         Max_MA 0.49 GB         CA 0.5 GB         Max_CA 1 GB \n","[2024-03-19 09:53:51,318] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 4.87 GB, percent = 5.8%\n","[2024-03-19 09:53:51,422] [INFO] [utils.py:800:see_memory_usage] Before creating fp32 partitions\n","[2024-03-19 09:53:51,423] [INFO] [utils.py:801:see_memory_usage] MA 0.49 GB         Max_MA 0.49 GB         CA 0.5 GB         Max_CA 1 GB \n","[2024-03-19 09:53:51,423] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 4.87 GB, percent = 5.8%\n","[2024-03-19 09:53:51,561] [INFO] [utils.py:800:see_memory_usage] After creating fp32 partitions\n","[2024-03-19 09:53:51,562] [INFO] [utils.py:801:see_memory_usage] MA 1.47 GB         Max_MA 1.96 GB         CA 1.97 GB         Max_CA 2 GB \n","[2024-03-19 09:53:51,562] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 4.6 GB, percent = 5.5%\n","[2024-03-19 09:53:51,669] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n","[2024-03-19 09:53:51,670] [INFO] [utils.py:801:see_memory_usage] MA 1.47 GB         Max_MA 1.47 GB         CA 1.97 GB         Max_CA 2 GB \n","[2024-03-19 09:53:51,670] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 4.6 GB, percent = 5.5%\n","[2024-03-19 09:53:51,776] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n","[2024-03-19 09:53:51,777] [INFO] [utils.py:801:see_memory_usage] MA 1.47 GB         Max_MA 2.45 GB         CA 2.96 GB         Max_CA 3 GB \n","[2024-03-19 09:53:51,778] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 4.6 GB, percent = 5.5%\n","[2024-03-19 09:53:51,778] [INFO] [stage3.py:486:_setup_for_real_optimizer] optimizer state initialized\n","[2024-03-19 09:53:51,920] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n","[2024-03-19 09:53:51,921] [INFO] [utils.py:801:see_memory_usage] MA 1.96 GB         Max_MA 2.09 GB         CA 2.96 GB         Max_CA 3 GB \n","[2024-03-19 09:53:51,921] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 4.6 GB, percent = 5.5%\n","[2024-03-19 09:53:51,921] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = AdamW\n","[2024-03-19 09:53:51,921] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n","[2024-03-19 09:53:51,922] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n","[2024-03-19 09:53:51,922] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[2e-06], mom=[(0.9, 0.95)]\n","[2024-03-19 09:53:51,922] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n","[2024-03-19 09:53:51,923] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n","    \"partition_activations\": false, \n","    \"contiguous_memory_optimization\": false, \n","    \"cpu_checkpointing\": false, \n","    \"number_checkpoints\": null, \n","    \"synchronize_checkpoint_boundary\": false, \n","    \"profile\": false\n","}\n","[2024-03-19 09:53:51,923] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n","[2024-03-19 09:53:51,923] [INFO] [config.py:1000:print]   amp_enabled .................. False\n","[2024-03-19 09:53:51,923] [INFO] [config.py:1000:print]   amp_params ................... False\n","[2024-03-19 09:53:51,923] [INFO] [config.py:1000:print]   autotuning_config ............ {\n","    \"enabled\": false, \n","    \"start_step\": null, \n","    \"end_step\": null, \n","    \"metric_path\": null, \n","    \"arg_mappings\": null, \n","    \"metric\": \"throughput\", \n","    \"model_info\": null, \n","    \"results_dir\": \"autotuning_results\", \n","    \"exps_dir\": \"autotuning_exps\", \n","    \"overwrite\": true, \n","    \"fast\": true, \n","    \"start_profile_step\": 3, \n","    \"end_profile_step\": 5, \n","    \"tuner_type\": \"gridsearch\", \n","    \"tuner_early_stopping\": 5, \n","    \"tuner_num_trials\": 50, \n","    \"model_info_path\": null, \n","    \"mp_size\": 1, \n","    \"max_train_batch_size\": null, \n","    \"min_train_batch_size\": 1, \n","    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n","    \"min_train_micro_batch_size_per_gpu\": 1, \n","    \"num_tuning_micro_batch_sizes\": 3\n","}\n","[2024-03-19 09:53:51,924] [INFO] [config.py:1000:print]   bfloat16_enabled ............. true\n","[2024-03-19 09:53:51,924] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n","[2024-03-19 09:53:51,924] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n","[2024-03-19 09:53:51,924] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n","[2024-03-19 09:53:51,924] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n","[2024-03-19 09:53:51,924] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7df3fca76550>\n","[2024-03-19 09:53:51,924] [INFO] [config.py:1000:print]   communication_data_type ...... None\n","[2024-03-19 09:53:51,924] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n","[2024-03-19 09:53:51,924] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n","[2024-03-19 09:53:51,925] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n","[2024-03-19 09:53:51,925] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n","[2024-03-19 09:53:51,925] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n","[2024-03-19 09:53:51,925] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n","[2024-03-19 09:53:51,925] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n","[2024-03-19 09:53:51,925] [INFO] [config.py:1000:print]   disable_allgather ............ False\n","[2024-03-19 09:53:51,925] [INFO] [config.py:1000:print]   dump_state ................... False\n","[2024-03-19 09:53:51,925] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n","[2024-03-19 09:53:51,925] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n","[2024-03-19 09:53:51,925] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n","[2024-03-19 09:53:51,925] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n","[2024-03-19 09:53:51,926] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n","[2024-03-19 09:53:51,926] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n","[2024-03-19 09:53:51,926] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n","[2024-03-19 09:53:51,926] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n","[2024-03-19 09:53:51,926] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n","[2024-03-19 09:53:51,926] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n","[2024-03-19 09:53:51,926] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n","    \"enabled\": false, \n","    \"recompute_fwd_factor\": 0.0, \n","    \"profile_step\": 1, \n","    \"module_depth\": -1, \n","    \"top_modules\": 1, \n","    \"detailed\": true, \n","    \"output_file\": null\n","}\n","[2024-03-19 09:53:51,926] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n","[2024-03-19 09:53:51,926] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n","[2024-03-19 09:53:51,926] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n","[2024-03-19 09:53:51,927] [INFO] [config.py:1000:print]   global_rank .................. 0\n","[2024-03-19 09:53:51,927] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n","[2024-03-19 09:53:51,927] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n","[2024-03-19 09:53:51,927] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n","[2024-03-19 09:53:51,927] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n","[2024-03-19 09:53:51,927] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n","[2024-03-19 09:53:51,927] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n","[2024-03-19 09:53:51,927] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n","[2024-03-19 09:53:51,927] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n","[2024-03-19 09:53:51,927] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n","[2024-03-19 09:53:51,927] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n","[2024-03-19 09:53:51,928] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n","[2024-03-19 09:53:51,928] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n","[2024-03-19 09:53:51,928] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n","[2024-03-19 09:53:51,928] [INFO] [config.py:1000:print]   nebula_config ................ {\n","    \"enabled\": false, \n","    \"persistent_storage_path\": null, \n","    \"persistent_time_interval\": 100, \n","    \"num_of_version_in_retention\": 2, \n","    \"enable_nebula_load\": true, \n","    \"load_path\": null\n","}\n","[2024-03-19 09:53:51,928] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n","[2024-03-19 09:53:51,928] [INFO] [config.py:1000:print]   optimizer_name ............... None\n","[2024-03-19 09:53:51,928] [INFO] [config.py:1000:print]   optimizer_params ............. None\n","[2024-03-19 09:53:51,928] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n","[2024-03-19 09:53:51,928] [INFO] [config.py:1000:print]   pld_enabled .................. False\n","[2024-03-19 09:53:51,928] [INFO] [config.py:1000:print]   pld_params ................... False\n","[2024-03-19 09:53:51,929] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n","[2024-03-19 09:53:51,929] [INFO] [config.py:1000:print]   scheduler_name ............... None\n","[2024-03-19 09:53:51,929] [INFO] [config.py:1000:print]   scheduler_params ............. None\n","[2024-03-19 09:53:51,929] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n","[2024-03-19 09:53:51,929] [INFO] [config.py:1000:print]   sparse_attention ............. None\n","[2024-03-19 09:53:51,929] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n","[2024-03-19 09:53:51,929] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n","[2024-03-19 09:53:51,929] [INFO] [config.py:1000:print]   train_batch_size ............. 1\n","[2024-03-19 09:53:51,929] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  1\n","[2024-03-19 09:53:51,929] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n","[2024-03-19 09:53:51,929] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n","[2024-03-19 09:53:51,929] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n","[2024-03-19 09:53:51,930] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n","[2024-03-19 09:53:51,930] [INFO] [config.py:1000:print]   world_size ................... 1\n","[2024-03-19 09:53:51,930] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n","[2024-03-19 09:53:51,930] [INFO] [config.py:1000:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=1048576 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=0 param_persistence_threshold=10240 model_persistence_threshold=sys.maxsize max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=True stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n","[2024-03-19 09:53:51,930] [INFO] [config.py:1000:print]   zero_enabled ................. True\n","[2024-03-19 09:53:51,930] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n","[2024-03-19 09:53:51,930] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 3\n","[2024-03-19 09:53:51,930] [INFO] [config.py:986:print_user_config]   json = {\n","    \"bf16\": {\n","        \"enabled\": \"true\"\n","    }, \n","    \"zero_optimization\": {\n","        \"stage\": 3, \n","        \"overlap_comm\": true, \n","        \"contiguous_gradients\": true, \n","        \"sub_group_size\": 1.000000e+09, \n","        \"reduce_bucket_size\": 1.048576e+06, \n","        \"stage3_prefetch_bucket_size\": 0, \n","        \"stage3_param_persistence_threshold\": 1.024000e+04, \n","        \"stage3_max_live_parameters\": 1.000000e+09, \n","        \"stage3_max_reuse_distance\": 1.000000e+09, \n","        \"stage3_gather_16bit_weights_on_model_save\": true\n","    }, \n","    \"train_micro_batch_size_per_gpu\": 1, \n","    \"wall_clock_breakdown\": false, \n","    \"gradient_accumulation_steps\": 1, \n","    \"steps_per_print\": inf, \n","    \"fp16\": {\n","        \"enabled\": false\n","    }, \n","    \"zero_allow_untested_optimizer\": true\n","}\n","[2024-03-19 09:53:51,933] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /root/moe-recipes/okazaki-cc-lr_2e-5-minlr_2e-6_warmup_1000_sliding_window_1024/iter_0000750/model_optimizer/zero_pp_rank_0_mp_rank_00_model_states.pt...\n","[2024-03-19 09:53:51,937] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /root/moe-recipes/okazaki-cc-lr_2e-5-minlr_2e-6_warmup_1000_sliding_window_1024/iter_0000750/model_optimizer/zero_pp_rank_0_mp_rank_00_model_states.pt.\n","[2024-03-19 09:53:51,937] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /root/moe-recipes/okazaki-cc-lr_2e-5-minlr_2e-6_warmup_1000_sliding_window_1024/iter_0000750/model_optimizer/zero_pp_rank_0_mp_rank_00_model_states.pt...\n","[2024-03-19 09:53:51,940] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /root/moe-recipes/okazaki-cc-lr_2e-5-minlr_2e-6_warmup_1000_sliding_window_1024/iter_0000750/model_optimizer/zero_pp_rank_0_mp_rank_00_model_states.pt.\n","[2024-03-19 09:53:51,943] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /root/moe-recipes/okazaki-cc-lr_2e-5-minlr_2e-6_warmup_1000_sliding_window_1024/iter_0000750/model_optimizer/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...\n","[2024-03-19 09:53:53,814] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /root/moe-recipes/okazaki-cc-lr_2e-5-minlr_2e-6_warmup_1000_sliding_window_1024/iter_0000750/model_optimizer/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.\n","[2024-03-19 09:53:53,815] [INFO] [engine.py:3031:_get_all_zero_checkpoint_state_dicts] successfully read 1 ZeRO state_dicts for rank 0\n","[2024-03-19 09:53:54,492] [INFO] [engine.py:2963:_load_zero_checkpoint] loading 1 zero partition checkpoints for rank 0\n","Loaded model state dict from /root/moe-recipes/okazaki-cc-lr_2e-5-minlr_2e-6_warmup_1000_sliding_window_1024/iter_0000750/model_optimizer\n","model info: MixtralForCausalLM(\n","  (model): MixtralModel(\n","    (embed_tokens): Embedding(32000, 1024)\n","    (layers): ModuleList(\n","      (0-7): 8 x MixtralDecoderLayer(\n","        (self_attn): MixtralSdpaAttention(\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n","          (k_proj): Linear(in_features=1024, out_features=256, bias=False)\n","          (v_proj): Linear(in_features=1024, out_features=256, bias=False)\n","          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n","          (rotary_emb): MixtralRotaryEmbedding()\n","        )\n","        (block_sparse_moe): MixtralSparseMoeBlock(\n","          (gate): Linear(in_features=1024, out_features=2, bias=False)\n","          (experts): ModuleList(\n","            (0-1): 2 x MixtralBlockSparseTop2MLP(\n","              (w1): Linear(in_features=1024, out_features=3584, bias=False)\n","              (w2): Linear(in_features=3584, out_features=1024, bias=False)\n","              (w3): Linear(in_features=1024, out_features=3584, bias=False)\n","              (act_fn): SiLU()\n","            )\n","          )\n","        )\n","        (input_layernorm): MixtralRMSNorm()\n","        (post_attention_layernorm): MixtralRMSNorm()\n","      )\n","    )\n","    (norm): MixtralRMSNorm()\n","  )\n","  (lm_head): Linear(in_features=1024, out_features=32000, bias=False)\n",")\n","model config: MixtralConfig {\n","  \"architectures\": [\n","    \"MixtralForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attn_implementation\": \"flash_attention_2\",\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3584,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"mixtral\",\n","  \"num_attention_heads\": 8,\n","  \"num_experts_per_tok\": 2,\n","  \"num_hidden_layers\": 8,\n","  \"num_key_value_heads\": 2,\n","  \"num_local_experts\": 2,\n","  \"output_router_logits\": true,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_theta\": 1000000.0,\n","  \"router_aux_loss_coef\": 0.02,\n","  \"sliding_window\": null,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.38.2\",\n","  \"use_cache\": false,\n","  \"vocab_size\": 32000\n","}\n","\n","------------------------------------------------------------------\n","iteration: 751 , TFLOPS: 16.906765780389847, Tokens per sec: 18187.811634122358, Loss: 3.0008130073547363, load balancing loss: 1.9998779445886612\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 752 , TFLOPS: 17.49017795442358, Tokens per sec: 18815.4296460006, Loss: 3.0025269985198975, load balancing loss: 1.9998779296875\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 753 , TFLOPS: 17.620213641323183, Tokens per sec: 18955.318292342818, Loss: 2.999964952468872, load balancing loss: 2.0001220665872097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 754 , TFLOPS: 17.50793760034988, Tokens per sec: 18834.53496152883, Loss: 3.0310637950897217, load balancing loss: 2.0002441368997097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 755 , TFLOPS: 17.576574430469044, Tokens per sec: 18908.372486315424, Loss: 3.031135320663452, load balancing loss: 1.99951171875\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 756 , TFLOPS: 17.475753297474874, Tokens per sec: 18799.912015551483, Loss: 3.0225870609283447, load balancing loss: 1.999877940863371\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 757 , TFLOPS: 17.375533796658807, Tokens per sec: 18692.098763354978, Loss: 3.152545928955078, load balancing loss: 1.9996337853372097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 758 , TFLOPS: 17.532903463507996, Tokens per sec: 18861.39251798293, Loss: 3.0966203212738037, load balancing loss: 1.999755859375\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 759 , TFLOPS: 17.552552538951545, Tokens per sec: 18882.53042736158, Loss: 3.062080144882202, load balancing loss: 1.999999988824129\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 760 , TFLOPS: 17.417372529244044, Tokens per sec: 18737.107666722724, Loss: 3.079151153564453, load balancing loss: 1.9993896409869194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 761 , TFLOPS: 17.66405818903856, Tokens per sec: 19002.484993850892, Loss: 3.027775764465332, load balancing loss: 1.9995117224752903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 762 , TFLOPS: 17.640960780045006, Tokens per sec: 18977.637466566975, Loss: 2.9412944316864014, load balancing loss: 1.999999988824129\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 763 , TFLOPS: 17.45832654677411, Tokens per sec: 18781.16481911797, Loss: 3.003960371017456, load balancing loss: 1.9996337965130806\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 764 , TFLOPS: 17.625931912074535, Tokens per sec: 18961.46984330469, Loss: 2.991891622543335, load balancing loss: 1.9995117224752903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 765 , TFLOPS: 17.617420542392637, Tokens per sec: 18952.313556967398, Loss: 3.0110764503479004, load balancing loss: 2.0003662072122097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 766 , TFLOPS: 17.526314875681884, Tokens per sec: 18854.304704981158, Loss: 2.948181629180908, load balancing loss: 2.0003662146627903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 767 , TFLOPS: 17.616004335419134, Tokens per sec: 18950.790042298566, Loss: 3.082185983657837, load balancing loss: 1.999755848199129\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 768 , TFLOPS: 17.71466018835491, Tokens per sec: 19056.92116714568, Loss: 2.9052700996398926, load balancing loss: 1.9996337890625\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 769 , TFLOPS: 17.46580493754406, Tokens per sec: 18789.20985649632, Loss: 3.0149242877960205, load balancing loss: 2.000122055411339\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 770 , TFLOPS: 17.521276712055034, Tokens per sec: 18848.88479367362, Loss: 2.986053466796875, load balancing loss: 1.999755859375\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 771 , TFLOPS: 17.567592269101585, Tokens per sec: 18898.709735843764, Loss: 3.1101698875427246, load balancing loss: 2.0004882737994194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 772 , TFLOPS: 17.37687110482834, Tokens per sec: 18693.537400963145, Loss: 2.968184471130371, load balancing loss: 1.9998779334127903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 773 , TFLOPS: 17.53727399364277, Tokens per sec: 18866.0942084106, Loss: 3.0509696006774902, load balancing loss: 1.9993896447122097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 774 , TFLOPS: 17.471056657193497, Tokens per sec: 18794.85950522156, Loss: 2.939072847366333, load balancing loss: 2.0003662183880806\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 775 , TFLOPS: 17.45941885355437, Tokens per sec: 18782.33989128873, Loss: 3.0055742263793945, load balancing loss: 1.9992675743997097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 776 , TFLOPS: 17.65140687201672, Tokens per sec: 18988.875071414768, Loss: 2.993983745574951, load balancing loss: 1.9998779147863388\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 777 , TFLOPS: 17.340483172589103, Tokens per sec: 18654.39231159957, Loss: 2.9791104793548584, load balancing loss: 2.0\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 778 , TFLOPS: 17.552938072356774, Tokens per sec: 18882.945173093798, Loss: 2.977301597595215, load balancing loss: 2.000244140625\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 779 , TFLOPS: 17.556035364269682, Tokens per sec: 18886.277150517482, Loss: 2.9579124450683594, load balancing loss: 1.9989013671875\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 780 , TFLOPS: 17.284198668217964, Tokens per sec: 18593.84306304905, Loss: 3.088749408721924, load balancing loss: 1.9998779147863388\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 781 , TFLOPS: 17.52007724431942, Tokens per sec: 18847.59444083382, Loss: 3.0675125122070312, load balancing loss: 2.0\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 782 , TFLOPS: 17.657998882995347, Tokens per sec: 18995.966566945415, Loss: 2.967061996459961, load balancing loss: 1.99951171875\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 783 , TFLOPS: 17.4323571497368, Tokens per sec: 18753.227689823012, Loss: 2.9615418910980225, load balancing loss: 2.0002441368997097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 784 , TFLOPS: 17.602708582706946, Tokens per sec: 18936.48685450947, Loss: 3.0139219760894775, load balancing loss: 1.9998779334127903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 785 , TFLOPS: 17.66091394678885, Tokens per sec: 18999.102508607255, Loss: 3.0905117988586426, load balancing loss: 1.999267589300871\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 786 , TFLOPS: 17.3776229711267, Tokens per sec: 18694.346237069723, Loss: 2.9870355129241943, load balancing loss: 1.9998779334127903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 787 , TFLOPS: 17.560587258898153, Tokens per sec: 18891.173947643347, Loss: 2.895720958709717, load balancing loss: 2.0\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 788 , TFLOPS: 17.456984715737942, Tokens per sec: 18779.72131594015, Loss: 2.988586187362671, load balancing loss: 2.0007324256002903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 789 , TFLOPS: 17.37051009233514, Tokens per sec: 18686.694406949307, Loss: 3.004840135574341, load balancing loss: 1.9997558631002903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 790 , TFLOPS: 17.63971821507122, Tokens per sec: 18976.300750959745, Loss: 2.9679670333862305, load balancing loss: 2.0002441480755806\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 791 , TFLOPS: 17.60992771105559, Tokens per sec: 18944.252984842926, Loss: 2.999504327774048, load balancing loss: 2.0003662146627903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 792 , TFLOPS: 17.501275653601844, Tokens per sec: 18827.368231111923, Loss: 2.9844305515289307, load balancing loss: 2.0007324256002903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 793 , TFLOPS: 17.552351165737957, Tokens per sec: 18882.313795858874, Loss: 3.010890245437622, load balancing loss: 1.999877918511629\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 794 , TFLOPS: 17.670697014614053, Tokens per sec: 19009.626851176374, Loss: 2.911048412322998, load balancing loss: 1.9998779296875\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 795 , TFLOPS: 17.484176013076056, Tokens per sec: 18808.972930382377, Loss: 3.079108953475952, load balancing loss: 1.9989013634622097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 796 , TFLOPS: 17.591566293899312, Tokens per sec: 18924.500301159253, Loss: 3.017399787902832, load balancing loss: 2.000976547598839\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 797 , TFLOPS: 17.564918926221473, Tokens per sec: 18895.83383057788, Loss: 2.9282474517822266, load balancing loss: 1.9998779371380806\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 798 , TFLOPS: 17.451886659425686, Tokens per sec: 18774.236973806837, Loss: 3.041067361831665, load balancing loss: 2.0000000037252903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 799 , TFLOPS: 17.63591667425028, Tokens per sec: 18972.211162846394, Loss: 2.9793217182159424, load balancing loss: 2.000244140625\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 800 , TFLOPS: 17.388999155871623, Tokens per sec: 18706.584408931998, Loss: 3.0087335109710693, load balancing loss: 1.999633777886629\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 801 , TFLOPS: 17.5588957179724, Tokens per sec: 18889.354236639563, Loss: 3.0426435470581055, load balancing loss: 2.0006103441119194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 802 , TFLOPS: 17.593661317308545, Tokens per sec: 18926.754066996622, Loss: 2.903794288635254, load balancing loss: 2.0003662072122097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 803 , TFLOPS: 17.4999420179127, Tokens per sec: 18825.933544252373, Loss: 2.9892916679382324, load balancing loss: 1.999755859375\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 804 , TFLOPS: 17.70932290926026, Tokens per sec: 19051.179476033783, Loss: 2.9200363159179688, load balancing loss: 1.9990234337747097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 805 , TFLOPS: 17.516039105778837, Tokens per sec: 18843.250327708778, Loss: 2.98045015335083, load balancing loss: 2.0001220740377903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 806 , TFLOPS: 17.43807906099159, Tokens per sec: 18759.383157133616, Loss: 2.876744270324707, load balancing loss: 1.9996337816119194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 807 , TFLOPS: 17.597548056481802, Tokens per sec: 18930.93530904329, Loss: 3.0218639373779297, load balancing loss: 1.9998779147863388\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 808 , TFLOPS: 17.63349637371659, Tokens per sec: 18969.60747324801, Loss: 2.9365599155426025, load balancing loss: 1.9991455040872097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 809 , TFLOPS: 17.43384316184499, Tokens per sec: 18754.826298845037, Loss: 2.9945566654205322, load balancing loss: 2.00048828125\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 810 , TFLOPS: 17.642840248823273, Tokens per sec: 18979.65934494131, Loss: 2.8985769748687744, load balancing loss: 1.9993896521627903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 811 , TFLOPS: 17.630060679036884, Tokens per sec: 18965.911451875352, Loss: 2.967323064804077, load balancing loss: 1.9996337853372097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 812 , TFLOPS: 17.49030448383683, Tokens per sec: 18815.56576269875, Loss: 2.9896562099456787, load balancing loss: 2.0001220777630806\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 813 , TFLOPS: 17.681623323988024, Tokens per sec: 19021.38106007305, Loss: 2.9561867713928223, load balancing loss: 2.000122055411339\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 814 , TFLOPS: 17.637505367143046, Tokens per sec: 18973.92023289879, Loss: 2.917391061782837, load balancing loss: 1.9997558668255806\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 815 , TFLOPS: 17.430606463712806, Tokens per sec: 18751.34435222619, Loss: 2.9324615001678467, load balancing loss: 2.0006103478372097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 816 , TFLOPS: 17.540767132006916, Tokens per sec: 18869.852026044337, Loss: 2.967721462249756, load balancing loss: 2.0001220703125\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 817 , TFLOPS: 17.652102388454743, Tokens per sec: 18989.623287964732, Loss: 2.938570499420166, load balancing loss: 1.9990234412252903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 818 , TFLOPS: 17.494757171043098, Tokens per sec: 18820.35583533743, Loss: 2.9269371032714844, load balancing loss: 2.0002441331744194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 819 , TFLOPS: 17.399926407650273, Tokens per sec: 18718.339631640487, Loss: 2.9436051845550537, load balancing loss: 2.0004882737994194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 820 , TFLOPS: 17.538806386962417, Tokens per sec: 18867.74271300392, Loss: 2.9350059032440186, load balancing loss: 1.9998779259622097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 821 , TFLOPS: 17.344871295248016, Tokens per sec: 18659.112927557966, Loss: 2.955012083053589, load balancing loss: 2.0012206993997097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 822 , TFLOPS: 17.489704088317453, Tokens per sec: 18814.919874493145, Loss: 2.953608751296997, load balancing loss: 1.99951171875\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 823 , TFLOPS: 17.317997772053168, Tokens per sec: 18630.203165385705, Loss: 2.9754228591918945, load balancing loss: 1.9998779334127903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 824 , TFLOPS: 17.500292771584803, Tokens per sec: 18826.3108749495, Loss: 2.958951473236084, load balancing loss: 1.9996337890625\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 825 , TFLOPS: 17.53516083678562, Tokens per sec: 18863.82093513229, Loss: 2.882638931274414, load balancing loss: 2.0000000037252903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 826 , TFLOPS: 17.26531348719392, Tokens per sec: 18573.526929283245, Loss: 2.877906560897827, load balancing loss: 1.9998779259622097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 827 , TFLOPS: 17.59340115044508, Tokens per sec: 18926.474186978903, Loss: 2.9562995433807373, load balancing loss: 1.9990234375\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 828 , TFLOPS: 17.402349104435515, Tokens per sec: 18720.945899057268, Loss: 2.884451150894165, load balancing loss: 2.000122081488371\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 829 , TFLOPS: 17.3450730039533, Tokens per sec: 18659.32991997297, Loss: 2.9033775329589844, load balancing loss: 1.999999988824129\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 830 , TFLOPS: 17.577264994317034, Tokens per sec: 18909.11537501168, Loss: 2.9491961002349854, load balancing loss: 1.9995117224752903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 831 , TFLOPS: 17.609441628414643, Tokens per sec: 18943.7300711392, Loss: 2.9288582801818848, load balancing loss: 1.999755848199129\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 832 , TFLOPS: 17.426372049812464, Tokens per sec: 18746.789091722745, Loss: 2.885528087615967, load balancing loss: 2.0001220628619194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 833 , TFLOPS: 17.679034471759955, Tokens per sec: 19018.59604741692, Loss: 2.843716859817505, load balancing loss: 2.000244129449129\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 834 , TFLOPS: 17.71668905798087, Tokens per sec: 19059.103766648535, Loss: 2.9111969470977783, load balancing loss: 1.999999988824129\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 835 , TFLOPS: 17.374891696290984, Tokens per sec: 18691.408010274707, Loss: 2.8059751987457275, load balancing loss: 2.0009765625\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 836 , TFLOPS: 17.55317375827181, Tokens per sec: 18883.198717212355, Loss: 2.9137766361236572, load balancing loss: 2.0001220703125\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 837 , TFLOPS: 17.65459167657077, Tokens per sec: 18992.301192417035, Loss: 2.946798324584961, load balancing loss: 1.9992675594985485\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 838 , TFLOPS: 17.456706518232814, Tokens per sec: 18779.422039077497, Loss: 2.9443888664245605, load balancing loss: 2.0001220777630806\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 839 , TFLOPS: 17.57798543444076, Tokens per sec: 18909.890403744805, Loss: 2.9296112060546875, load balancing loss: 1.9991455078125\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 840 , TFLOPS: 17.521333531711637, Tokens per sec: 18848.94591862352, Loss: 2.910670042037964, load balancing loss: 2.0000000074505806\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 841 , TFLOPS: 17.41997356717139, Tokens per sec: 18739.905788403135, Loss: 2.9483890533447266, load balancing loss: 2.0003662109375\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 842 , TFLOPS: 17.573410332784928, Tokens per sec: 18904.968641167376, Loss: 2.9272232055664062, load balancing loss: 2.0\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 843 , TFLOPS: 17.467607241021074, Tokens per sec: 18791.14872266228, Loss: 2.874098777770996, load balancing loss: 2.0004882849752903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 844 , TFLOPS: 17.389385670506414, Tokens per sec: 18707.000210242713, Loss: 2.941927194595337, load balancing loss: 1.9997558631002903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 845 , TFLOPS: 17.626162601430803, Tokens per sec: 18961.71801226925, Loss: 2.8356385231018066, load balancing loss: 1.9995117112994194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 846 , TFLOPS: 17.40712089261015, Tokens per sec: 18726.079251326148, Loss: 2.9122731685638428, load balancing loss: 2.0001220703125\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 847 , TFLOPS: 17.570007169383064, Tokens per sec: 18901.307616006372, Loss: 2.84979510307312, load balancing loss: 1.999267578125\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 848 , TFLOPS: 17.594290336004942, Tokens per sec: 18927.43074719158, Loss: 2.795710325241089, load balancing loss: 1.9996337890625\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 849 , TFLOPS: 17.51393664012804, Tokens per sec: 18840.988555722306, Loss: 2.9210712909698486, load balancing loss: 1.9995117001235485\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 850 , TFLOPS: 17.574846009255424, Tokens per sec: 18906.513100560267, Loss: 2.9845569133758545, load balancing loss: 2.0006103515625\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 851 , TFLOPS: 17.64766050929353, Tokens per sec: 18984.844842309594, Loss: 2.9818575382232666, load balancing loss: 1.9995117224752903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 852 , TFLOPS: 17.442553640240405, Tokens per sec: 18764.196780601083, Loss: 2.848245859146118, load balancing loss: 1.9999999925494194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 853 , TFLOPS: 17.7608391018904, Tokens per sec: 19106.599112162592, Loss: 3.0128633975982666, load balancing loss: 1.9996337816119194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 854 , TFLOPS: 17.698481319997242, Tokens per sec: 19039.516406592138, Loss: 2.911679983139038, load balancing loss: 2.0001220703125\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 855 , TFLOPS: 17.507716651715455, Tokens per sec: 18834.29727135225, Loss: 2.8496837615966797, load balancing loss: 1.9992675930261612\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 856 , TFLOPS: 17.706104040771546, Tokens per sec: 19047.716710031804, Loss: 2.887685775756836, load balancing loss: 1.9999999962747097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 857 , TFLOPS: 17.65781333319368, Tokens per sec: 18995.76695781347, Loss: 2.8848977088928223, load balancing loss: 1.999877918511629\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 858 , TFLOPS: 17.36262638659529, Tokens per sec: 18678.213343401272, Loss: 2.869227886199951, load balancing loss: 2.0003662109375\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 859 , TFLOPS: 17.637587324256327, Tokens per sec: 18974.008400000515, Loss: 2.857480525970459, load balancing loss: 1.9998779334127903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 860 , TFLOPS: 17.704407481776634, Tokens per sec: 19045.89160073376, Loss: 2.9119906425476074, load balancing loss: 1.9991455227136612\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 861 , TFLOPS: 17.538812238559952, Tokens per sec: 18867.749007983995, Loss: 2.904120922088623, load balancing loss: 2.0001220628619194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 862 , TFLOPS: 17.716415444813954, Tokens per sec: 19058.809421484886, Loss: 2.872816324234009, load balancing loss: 1.9995117150247097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 863 , TFLOPS: 17.693207224308846, Tokens per sec: 19033.84268636872, Loss: 2.862534523010254, load balancing loss: 1.9995117150247097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 864 , TFLOPS: 17.3760105186485, Tokens per sec: 18692.611607139705, Loss: 2.9013500213623047, load balancing loss: 2.0002441331744194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 865 , TFLOPS: 17.65980183353134, Tokens per sec: 18997.90612919879, Loss: 2.8309879302978516, load balancing loss: 1.999511729925871\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 866 , TFLOPS: 17.758584844341183, Tokens per sec: 19104.174046824104, Loss: 2.8822314739227295, load balancing loss: 1.99951171875\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 867 , TFLOPS: 17.396339233068858, Tokens per sec: 18714.480652552887, Loss: 2.8780272006988525, load balancing loss: 1.9992675855755806\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 868 , TFLOPS: 17.679262543740425, Tokens per sec: 19018.841400683985, Loss: 2.88731050491333, load balancing loss: 1.9992675855755806\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 869 , TFLOPS: 17.47637153414557, Tokens per sec: 18800.577096753765, Loss: 2.8585548400878906, load balancing loss: 2.0001220665872097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 870 , TFLOPS: 17.691266624536187, Tokens per sec: 19031.755045031467, Loss: 2.9690144062042236, load balancing loss: 2.0003662034869194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 871 , TFLOPS: 17.65671695051211, Tokens per sec: 18994.587500905487, Loss: 2.8215229511260986, load balancing loss: 1.999755859375\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 872 , TFLOPS: 17.425737695841192, Tokens per sec: 18746.10667199276, Loss: 2.9567432403564453, load balancing loss: 1.9997558668255806\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 873 , TFLOPS: 17.486046275062186, Tokens per sec: 18810.984904354933, Loss: 2.8589582443237305, load balancing loss: 1.9993896484375\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 874 , TFLOPS: 17.582719809104947, Tokens per sec: 18914.983507636825, Loss: 2.835420846939087, load balancing loss: 2.0001220740377903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 875 , TFLOPS: 17.53110509834096, Tokens per sec: 18859.4578885374, Loss: 2.8915436267852783, load balancing loss: 1.9998779334127903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 876 , TFLOPS: 17.526455674217544, Tokens per sec: 18854.456171990176, Loss: 2.862154960632324, load balancing loss: 1.9990234225988388\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 877 , TFLOPS: 17.570807224580633, Tokens per sec: 18902.16829234266, Loss: 2.852369785308838, load balancing loss: 1.9999999850988388\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 878 , TFLOPS: 17.446553889028745, Tokens per sec: 18768.500133022062, Loss: 2.853158712387085, load balancing loss: 1.9997558519244194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 879 , TFLOPS: 17.600275210138907, Tokens per sec: 18933.86910239307, Loss: 2.752811908721924, load balancing loss: 1.9989013709127903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 880 , TFLOPS: 17.560820966844812, Tokens per sec: 18891.4253639205, Loss: 2.892529249191284, load balancing loss: 1.999511707574129\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 881 , TFLOPS: 17.419682900837355, Tokens per sec: 18739.593097933506, Loss: 2.864609479904175, load balancing loss: 2.0007324181497097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 882 , TFLOPS: 17.512329006016593, Tokens per sec: 18839.25910925245, Loss: 2.86531925201416, load balancing loss: 2.0002441480755806\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 883 , TFLOPS: 17.649010344913634, Tokens per sec: 18986.296956588245, Loss: 2.836646795272827, load balancing loss: 1.9998779296875\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 884 , TFLOPS: 17.401915207020483, Tokens per sec: 18720.479124716414, Loss: 2.7936792373657227, load balancing loss: 2.000244140625\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 885 , TFLOPS: 17.494867193198377, Tokens per sec: 18820.474194002934, Loss: 2.809020519256592, load balancing loss: 1.999755859375\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 886 , TFLOPS: 17.688713123034518, Tokens per sec: 19029.00806166853, Loss: 2.8061585426330566, load balancing loss: 2.000244129449129\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 887 , TFLOPS: 17.55505273922305, Tokens per sec: 18885.220070796426, Loss: 2.8150036334991455, load balancing loss: 1.9991455040872097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 888 , TFLOPS: 17.76194481294252, Tokens per sec: 19107.78860426291, Loss: 2.8069121837615967, load balancing loss: 2.0002441368997097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 889 , TFLOPS: 17.533131390167803, Tokens per sec: 18861.63771491822, Loss: 2.8828234672546387, load balancing loss: 1.999755848199129\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 890 , TFLOPS: 17.373708542145884, Tokens per sec: 18690.135207125677, Loss: 2.836036443710327, load balancing loss: 2.0000000037252903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 891 , TFLOPS: 17.61615954436606, Tokens per sec: 18950.957011612936, Loss: 2.7571067810058594, load balancing loss: 2.000732410699129\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 892 , TFLOPS: 17.595364492054568, Tokens per sec: 18928.586293329146, Loss: 2.946847915649414, load balancing loss: 2.0000000037252903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 893 , TFLOPS: 17.63720152335648, Tokens per sec: 18973.593366505298, Loss: 2.7850050926208496, load balancing loss: 1.9993896447122097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 894 , TFLOPS: 17.615792458212685, Tokens per sec: 18950.5621109029, Loss: 2.862910032272339, load balancing loss: 2.00048828125\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 895 , TFLOPS: 17.457583424164618, Tokens per sec: 18780.365389220016, Loss: 2.8808069229125977, load balancing loss: 2.000244140625\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 896 , TFLOPS: 17.74590303412351, Tokens per sec: 19090.53132068625, Loss: 2.877725839614868, load balancing loss: 1.9996337853372097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 897 , TFLOPS: 17.644654124838482, Tokens per sec: 18981.61066051052, Loss: 2.7982022762298584, load balancing loss: 1.999511707574129\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 898 , TFLOPS: 17.458893111135023, Tokens per sec: 18781.774312737787, Loss: 2.8635685443878174, load balancing loss: 1.9999999962747097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 899 , TFLOPS: 17.646496811285783, Tokens per sec: 18983.5929695127, Loss: 2.818207263946533, load balancing loss: 2.0006103478372097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 900 , TFLOPS: 17.720051697977432, Tokens per sec: 19062.721197897383, Loss: 2.840533971786499, load balancing loss: 1.9992675818502903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 901 , TFLOPS: 17.57964136078709, Tokens per sec: 18911.67180160991, Loss: 2.8330447673797607, load balancing loss: 2.0003662072122097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 902 , TFLOPS: 17.720657834657892, Tokens per sec: 19063.373262278703, Loss: 2.8142752647399902, load balancing loss: 1.999755859375\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 903 , TFLOPS: 17.596846737444594, Tokens per sec: 18930.180850224267, Loss: 2.825460195541382, load balancing loss: 2.0000000074505806\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 904 , TFLOPS: 17.42143906923589, Tokens per sec: 18741.48233331094, Loss: 2.8547706604003906, load balancing loss: 1.9997558631002903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 905 , TFLOPS: 17.68625137473018, Tokens per sec: 19026.35978375237, Loss: 2.788925886154175, load balancing loss: 2.000244140625\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 906 , TFLOPS: 17.65066479423057, Tokens per sec: 18988.076765507674, Loss: 2.8193564414978027, load balancing loss: 2.0001220703125\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 907 , TFLOPS: 17.43496443629621, Tokens per sec: 18756.03253360181, Loss: 2.8139655590057373, load balancing loss: 2.0002441108226776\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 908 , TFLOPS: 17.694711737495847, Tokens per sec: 19035.46119831841, Loss: 2.830885171890259, load balancing loss: 2.0006103441119194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 909 , TFLOPS: 17.651779891959976, Tokens per sec: 18989.27635552504, Loss: 2.800055980682373, load balancing loss: 2.0004882849752903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 910 , TFLOPS: 17.541410687202983, Tokens per sec: 18870.544344186925, Loss: 2.9660730361938477, load balancing loss: 2.0006103441119194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 911 , TFLOPS: 17.47984104319673, Tokens per sec: 18804.309494653222, Loss: 2.850597620010376, load balancing loss: 1.999267578125\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 912 , TFLOPS: 17.583520270835994, Tokens per sec: 18915.844621310116, Loss: 2.8216257095336914, load balancing loss: 2.0001220777630806\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 913 , TFLOPS: 17.560870447390638, Tokens per sec: 18891.47859366643, Loss: 2.7664482593536377, load balancing loss: 2.0002441331744194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 914 , TFLOPS: 17.62470598502592, Tokens per sec: 18960.151026298114, Loss: 2.789872169494629, load balancing loss: 2.000244140625\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 915 , TFLOPS: 17.426549323711335, Tokens per sec: 18746.97979787685, Loss: 2.8078699111938477, load balancing loss: 2.0001220665872097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 916 , TFLOPS: 17.609901803164092, Tokens per sec: 18944.225113879515, Loss: 2.7913451194763184, load balancing loss: 1.9996337853372097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 917 , TFLOPS: 17.665990066679697, Tokens per sec: 19004.56325217029, Loss: 2.824392795562744, load balancing loss: 2.0000000037252903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 918 , TFLOPS: 17.45928294039629, Tokens per sec: 18782.193679828186, Loss: 2.753659248352051, load balancing loss: 2.0002441331744194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 919 , TFLOPS: 17.526200693569656, Tokens per sec: 18854.18187115379, Loss: 2.893598794937134, load balancing loss: 2.0002441480755806\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 920 , TFLOPS: 17.664650630110454, Tokens per sec: 19003.122324891014, Loss: 2.819026470184326, load balancing loss: 2.0006103552877903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 921 , TFLOPS: 17.465981622646858, Tokens per sec: 18789.399929240568, Loss: 2.8910024166107178, load balancing loss: 1.9997558631002903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 922 , TFLOPS: 17.61919620390096, Tokens per sec: 18954.223762470854, Loss: 2.8065271377563477, load balancing loss: 1.9997558556497097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 923 , TFLOPS: 17.67216177585658, Tokens per sec: 19011.20259912924, Loss: 2.745384693145752, load balancing loss: 2.0004882775247097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 924 , TFLOPS: 17.463400618861307, Tokens per sec: 18786.62335971282, Loss: 2.8356289863586426, load balancing loss: 1.999267566949129\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 925 , TFLOPS: 17.721337355250167, Tokens per sec: 19064.104270958564, Loss: 2.783454656600952, load balancing loss: 2.0002441331744194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 926 , TFLOPS: 17.67940060274526, Tokens per sec: 19018.989920584656, Loss: 2.836040735244751, load balancing loss: 2.0002441443502903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 927 , TFLOPS: 17.43908426712489, Tokens per sec: 18760.464528937275, Loss: 2.7678513526916504, load balancing loss: 2.0000000037252903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 928 , TFLOPS: 17.695646597334612, Tokens per sec: 19036.466893604702, Loss: 2.7735328674316406, load balancing loss: 1.9999999962747097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 929 , TFLOPS: 17.62697176865689, Tokens per sec: 18962.588491063347, Loss: 2.6938834190368652, load balancing loss: 1.9995117112994194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 930 , TFLOPS: 17.52795299304975, Tokens per sec: 18856.066944460214, Loss: 2.8078067302703857, load balancing loss: 2.0003662072122097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 931 , TFLOPS: 17.5685953529391, Tokens per sec: 18899.788824542746, Loss: 2.8432796001434326, load balancing loss: 1.9999999962747097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 932 , TFLOPS: 17.549290539651555, Tokens per sec: 18879.0212624752, Loss: 2.7299015522003174, load balancing loss: 1.9995117224752903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 933 , TFLOPS: 17.371366533627594, Tokens per sec: 18687.61574182229, Loss: 2.8121607303619385, load balancing loss: 1.9995117224752903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 934 , TFLOPS: 17.7337081433707, Tokens per sec: 19077.412408483175, Loss: 2.7759783267974854, load balancing loss: 2.0001220777630806\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 935 , TFLOPS: 17.656074591988595, Tokens per sec: 18993.89647010876, Loss: 2.8126795291900635, load balancing loss: 1.9999999962747097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 936 , TFLOPS: 17.411581235682906, Tokens per sec: 18730.877559925473, Loss: 2.836667060852051, load balancing loss: 1.9996337853372097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 937 , TFLOPS: 17.569202536349117, Tokens per sec: 18900.442014965574, Loss: 2.81264591217041, load balancing loss: 2.0006103478372097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 938 , TFLOPS: 17.449059683537474, Tokens per sec: 18771.195794576175, Loss: 2.790407180786133, load balancing loss: 2.0001220703125\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 939 , TFLOPS: 17.66321550905968, Tokens per sec: 19001.57846300266, Loss: 2.759425640106201, load balancing loss: 1.9997558631002903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 940 , TFLOPS: 17.662186215188964, Tokens per sec: 19000.47117830493, Loss: 2.7007200717926025, load balancing loss: 2.0007324256002903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 941 , TFLOPS: 17.467280711944127, Tokens per sec: 18790.797452086834, Loss: 2.778517961502075, load balancing loss: 1.999755859375\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 942 , TFLOPS: 17.592113530564927, Tokens per sec: 18925.089002601195, Loss: 2.7618157863616943, load balancing loss: 2.0003662109375\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 943 , TFLOPS: 17.741232743883298, Tokens per sec: 19085.50715697161, Loss: 2.8150455951690674, load balancing loss: 1.9996337816119194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 944 , TFLOPS: 17.456191109418953, Tokens per sec: 18778.867577121684, Loss: 2.7528228759765625, load balancing loss: 1.999511707574129\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 945 , TFLOPS: 17.608416540344916, Tokens per sec: 18942.627310921027, Loss: 2.7566773891448975, load balancing loss: 2.000488292425871\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 946 , TFLOPS: 17.55437879686848, Tokens per sec: 18884.495063024016, Loss: 2.830181360244751, load balancing loss: 2.0006103515625\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 947 , TFLOPS: 17.46914563564418, Tokens per sec: 18792.803683284994, Loss: 2.680257797241211, load balancing loss: 1.9992675706744194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 948 , TFLOPS: 17.713640267683356, Tokens per sec: 19055.823965865624, Loss: 2.793083429336548, load balancing loss: 1.9998779259622097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 949 , TFLOPS: 17.622548957259585, Tokens per sec: 18957.830557959387, Loss: 2.852573871612549, load balancing loss: 1.9996337927877903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 950 , TFLOPS: 17.467682743222873, Tokens per sec: 18791.229945756168, Loss: 2.8581507205963135, load balancing loss: 2.0\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 951 , TFLOPS: 17.6201358652246, Tokens per sec: 18955.23462305627, Loss: 2.764101982116699, load balancing loss: 1.9993896447122097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 952 , TFLOPS: 17.639815697442724, Tokens per sec: 18976.405619687073, Loss: 2.7584924697875977, load balancing loss: 1.9999999925494194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 953 , TFLOPS: 17.47321878097181, Tokens per sec: 18797.185455703184, Loss: 2.751692056655884, load balancing loss: 1.9997558556497097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 954 , TFLOPS: 17.617509354758248, Tokens per sec: 18952.409098752123, Loss: 2.736556053161621, load balancing loss: 1.9996337853372097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 955 , TFLOPS: 17.62003324673165, Tokens per sec: 18955.12422903744, Loss: 2.7891361713409424, load balancing loss: 1.9995117262005806\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 956 , TFLOPS: 17.373996333505925, Tokens per sec: 18690.4448047811, Loss: 2.809258460998535, load balancing loss: 2.0000000037252903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 957 , TFLOPS: 17.626393726074316, Tokens per sec: 18961.96664950329, Loss: 2.7975330352783203, load balancing loss: 1.9998779296875\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 958 , TFLOPS: 17.61598497440948, Tokens per sec: 18950.769214282063, Loss: 2.6845858097076416, load balancing loss: 2.0002441443502903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 959 , TFLOPS: 17.502458116690445, Tokens per sec: 18828.640290842275, Loss: 2.8192548751831055, load balancing loss: 1.9997558631002903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 960 , TFLOPS: 17.658285666890393, Tokens per sec: 18996.275080799016, Loss: 2.7365362644195557, load balancing loss: 1.9995117224752903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 961 , TFLOPS: 17.480978362690088, Tokens per sec: 18805.532990204156, Loss: 2.731560468673706, load balancing loss: 2.0001220628619194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 962 , TFLOPS: 17.635489894457407, Tokens per sec: 18971.75204543844, Loss: 2.7455873489379883, load balancing loss: 1.999999988824129\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 963 , TFLOPS: 17.518117000124125, Tokens per sec: 18845.485666592547, Loss: 2.772048234939575, load balancing loss: 1.999389659613371\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 964 , TFLOPS: 17.411039035819833, Tokens per sec: 18730.294276930625, Loss: 2.6394290924072266, load balancing loss: 2.0\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 965 , TFLOPS: 17.6244826473339, Tokens per sec: 18959.910766042187, Loss: 2.755434513092041, load balancing loss: 2.0007324256002903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 966 , TFLOPS: 17.74011313365673, Tokens per sec: 19084.302712539782, Loss: 2.805006980895996, load balancing loss: 2.0001220740377903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 967 , TFLOPS: 17.432732001389315, Tokens per sec: 18753.630944433342, Loss: 2.8042144775390625, load balancing loss: 2.0007324256002903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 968 , TFLOPS: 17.594863726326516, Tokens per sec: 18928.047583983258, Loss: 2.7190709114074707, load balancing loss: 1.9993896558880806\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 969 , TFLOPS: 17.622837440305947, Tokens per sec: 18958.140899711027, Loss: 2.7651336193084717, load balancing loss: 1.9987793043255806\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 970 , TFLOPS: 17.41133006128794, Tokens per sec: 18730.60735374635, Loss: 2.8429462909698486, load balancing loss: 1.9990234375\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 971 , TFLOPS: 17.539557298334035, Tokens per sec: 18868.550521827812, Loss: 2.738881826400757, load balancing loss: 2.0002441480755806\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 972 , TFLOPS: 17.68290803092605, Tokens per sec: 19022.76311079153, Loss: 2.7513647079467773, load balancing loss: 1.9993896484375\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 973 , TFLOPS: 17.436391818027886, Tokens per sec: 18757.568069753605, Loss: 2.855100393295288, load balancing loss: 2.0003662146627903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 974 , TFLOPS: 17.72484904738956, Tokens per sec: 19067.882048209274, Loss: 2.7774107456207275, load balancing loss: 2.0012207105755806\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 975 , TFLOPS: 17.55333178302802, Tokens per sec: 18883.368715693246, Loss: 2.7922894954681396, load balancing loss: 2.0003662072122097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 976 , TFLOPS: 17.369053395583016, Tokens per sec: 18685.12733454292, Loss: 2.8070688247680664, load balancing loss: 1.9991455227136612\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 977 , TFLOPS: 17.65979970597457, Tokens per sec: 18997.9038404345, Loss: 2.780805826187134, load balancing loss: 2.000366222113371\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 978 , TFLOPS: 17.608877698830135, Tokens per sec: 18943.12341193595, Loss: 2.8465871810913086, load balancing loss: 2.0006103441119194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 979 , TFLOPS: 17.3221351775077, Tokens per sec: 18634.654066997435, Loss: 2.725024700164795, load balancing loss: 2.000244129449129\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 980 , TFLOPS: 17.500059013336553, Tokens per sec: 18826.059404559346, Loss: 2.7014620304107666, load balancing loss: 1.9999999962747097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 981 , TFLOPS: 17.569052403186074, Tokens per sec: 18900.280506033298, Loss: 2.750025749206543, load balancing loss: 2.0006103441119194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 982 , TFLOPS: 17.4736748602715, Tokens per sec: 18797.67609267662, Loss: 2.800041913986206, load balancing loss: 1.9995117112994194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 983 , TFLOPS: 17.64239533536895, Tokens per sec: 18979.180719862696, Loss: 2.7612569332122803, load balancing loss: 2.0003662072122097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 984 , TFLOPS: 17.453836331349557, Tokens per sec: 18776.33437470304, Loss: 2.71752667427063, load balancing loss: 2.0007324144244194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 985 , TFLOPS: 17.628330620813106, Tokens per sec: 18964.05030507183, Loss: 2.7929513454437256, load balancing loss: 1.9993896484375\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 986 , TFLOPS: 17.676539011566017, Tokens per sec: 19015.91150322098, Loss: 2.8122646808624268, load balancing loss: 2.0001220777630806\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 987 , TFLOPS: 17.33949028949163, Tokens per sec: 18653.324196562895, Loss: 2.797804355621338, load balancing loss: 1.9998779259622097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 988 , TFLOPS: 17.65816828098811, Tokens per sec: 18996.148800426592, Loss: 2.804741382598877, load balancing loss: 1.9989013709127903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 989 , TFLOPS: 17.5631009785799, Tokens per sec: 18893.87813487031, Loss: 2.794964075088501, load balancing loss: 2.00048828125\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 990 , TFLOPS: 17.427866358358735, Tokens per sec: 18748.396625813883, Loss: 2.6514499187469482, load balancing loss: 1.999877940863371\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 991 , TFLOPS: 17.62271855938511, Tokens per sec: 18958.013011040708, Loss: 2.7527639865875244, load balancing loss: 2.000244129449129\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 992 , TFLOPS: 17.708853543344674, Tokens per sec: 19050.674545701688, Loss: 2.634579658508301, load balancing loss: 1.999511707574129\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 993 , TFLOPS: 17.45372971964179, Tokens per sec: 18776.21968489873, Loss: 2.7333590984344482, load balancing loss: 1.999633777886629\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 994 , TFLOPS: 17.602070507273613, Tokens per sec: 18935.80043133779, Loss: 2.6995131969451904, load balancing loss: 2.000244125723839\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 995 , TFLOPS: 17.728353385050344, Tokens per sec: 19071.651913723745, Loss: 2.762399435043335, load balancing loss: 2.0000000037252903\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 996 , TFLOPS: 17.46956415575359, Tokens per sec: 18793.2539151634, Loss: 2.7390835285186768, load balancing loss: 2.0002441331744194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 997 , TFLOPS: 17.534653590547773, Tokens per sec: 18863.275254240634, Loss: 2.834562063217163, load balancing loss: 1.9995117112994194\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 998 , TFLOPS: 17.434019443874, Tokens per sec: 18755.015937974116, Loss: 2.6891820430755615, load balancing loss: 1.9997558668255806\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 999 , TFLOPS: 17.454510124782747, Tokens per sec: 18777.059222270123, Loss: 2.687814235687256, load balancing loss: 1.9996337890625\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 1000 , TFLOPS: 17.55912907626479, Tokens per sec: 18889.60527676872, Loss: 2.8146936893463135, load balancing loss: 2.0001220665872097\n","------------------------------------------------------------------\n","Saving checkpoint to /root/moe-recipes/okazaki-cc-lr_2e-5-minlr_2e-6_warmup_1000_sliding_window_1024/iter_0001000\n","[2024-03-19 10:51:50,065] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint model_optimizer is about to be saved!\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n","  warnings.warn(\n","[2024-03-19 10:51:50,073] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /root/moe-recipes/okazaki-cc-lr_2e-5-minlr_2e-6_warmup_1000_sliding_window_1024/iter_0001000/model_optimizer/zero_pp_rank_0_mp_rank_00_model_states.pt\n","[2024-03-19 10:51:50,074] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /root/moe-recipes/okazaki-cc-lr_2e-5-minlr_2e-6_warmup_1000_sliding_window_1024/iter_0001000/model_optimizer/zero_pp_rank_0_mp_rank_00_model_states.pt...\n","[2024-03-19 10:51:50,080] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /root/moe-recipes/okazaki-cc-lr_2e-5-minlr_2e-6_warmup_1000_sliding_window_1024/iter_0001000/model_optimizer/zero_pp_rank_0_mp_rank_00_model_states.pt.\n","[2024-03-19 10:51:50,080] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /root/moe-recipes/okazaki-cc-lr_2e-5-minlr_2e-6_warmup_1000_sliding_window_1024/iter_0001000/model_optimizer/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...\n","[2024-03-19 10:51:57,745] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /root/moe-recipes/okazaki-cc-lr_2e-5-minlr_2e-6_warmup_1000_sliding_window_1024/iter_0001000/model_optimizer/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.\n","[2024-03-19 10:51:57,746] [INFO] [engine.py:3488:_save_zero_checkpoint] zero checkpoint saved /root/moe-recipes/okazaki-cc-lr_2e-5-minlr_2e-6_warmup_1000_sliding_window_1024/iter_0001000/model_optimizer/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt\n","[2024-03-19 10:51:57,747] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint model_optimizer is ready now!\n","Saving scheduler state dict to /root/moe-recipes/okazaki-cc-lr_2e-5-minlr_2e-6_warmup_1000_sliding_window_1024/iter_0001000/scheduler.pt\n","Saved scheduler state dict to /root/moe-recipes/okazaki-cc-lr_2e-5-minlr_2e-6_warmup_1000_sliding_window_1024/iter_0001000/scheduler.pt\n","Saving RNG states to /root/moe-recipes/okazaki-cc-lr_2e-5-minlr_2e-6_warmup_1000_sliding_window_1024/iter_0001000/rng.pt\n","Saved RNG states to /root/moe-recipes/okazaki-cc-lr_2e-5-minlr_2e-6_warmup_1000_sliding_window_1024/iter_0001000/rng.pt\n","Saved checkpoint to /root/moe-recipes/okazaki-cc-lr_2e-5-minlr_2e-6_warmup_1000_sliding_window_1024/iter_0001000, took 10.79s\n","------------------------------------------------------------------\n","iteration: 1001 , TFLOPS: 17.521315804245745, Tokens per sec: 18848.926847926352, Loss: 2.7034597396850586, load balancing loss: 2.0002441368997097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 1002 , TFLOPS: 17.454823392319152, Tokens per sec: 18777.396226462246, Loss: 2.745422124862671, load balancing loss: 2.000244129449129\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 1003 , TFLOPS: 17.615117817085494, Tokens per sec: 18949.836351411028, Loss: 2.6848087310791016, load balancing loss: 1.9998779259622097\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 1004 , TFLOPS: 17.59630420771815, Tokens per sec: 18929.597212371904, Loss: 2.7565133571624756, load balancing loss: 1.99951171875\n","------------------------------------------------------------------\n","------------------------------------------------------------------\n","iteration: 1005 , TFLOPS: 17.375349350574876, Tokens per sec: 18691.900341570778, Loss: 2.730187177658081, load balancing loss: 1.9997558631002903\n","------------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["%cd ~/moe-recipes/tools/checkpoint-convert/scripts/abci\n","!bash convert_deepspeed_colab.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3xQOALD5BrIY","executionInfo":{"status":"ok","timestamp":1710845880624,"user_tz":-540,"elapsed":8733,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}},"outputId":"759da0d2-c6c7-49ed-8fc2-ee0cb968a517"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["/root/moe-recipes/tools/checkpoint-convert/scripts/abci\n","[2024-03-19 10:57:54,818] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","Processing zero checkpoint '/root/moe-recipes/okazaki-cc-lr_2e-5-minlr_2e-6_warmup_1000_sliding_window_1024/iter_0001000/model_optimizer'\n","load /root/moe-recipes/okazaki-cc-lr_2e-5-minlr_2e-6_warmup_1000_sliding_window_1024/iter_0001000/model_optimizer/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt\n","DEBUG: state_dict={'optimizer_state_dict': {'zero_stage': <ZeroStageEnum.weights: 3>, 'loss_scaler': <deepspeed.runtime.fp16.loss_scaler.LossScaler object at 0x780eddec4750>, 'dynamic_loss_scale': False, 'overflow': False, 'partition_count': 1, 'optimizer_state_dict': {'state': {0: {'step': tensor(32000.), 'exp_avg': tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -4.3633e-09,\n","        -2.0922e-09, -2.1383e-08]), 'exp_avg_sq': tensor([0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.0762e-17, 5.6729e-17,\n","        4.8438e-16])}}, 'param_groups': [{'lr': 2e-05, 'betas': (0.9, 0.95), 'eps': 1e-06, 'weight_decay': 0.1, 'amsgrad': False, 'foreach': None, 'maximize': False, 'capturable': False, 'differentiable': False, 'fused': None, 'initial_lr': 2e-05, 'params': [0]}]}, 'fp32_flat_groups': [tensor([-0.0006,  0.0114,  0.0083,  ...,  0.0119, -0.0116, -0.0031],\n","       requires_grad=True)]}, 'ds_config': {'bf16': {'enabled': 'true'}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 1048576, 'stage3_prefetch_bucket_size': 0, 'stage3_param_persistence_threshold': 10240, 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'train_micro_batch_size_per_gpu': 1, 'wall_clock_breakdown': False, 'gradient_accumulation_steps': 1, 'steps_per_print': inf, 'fp16': {'enabled': False}, 'zero_allow_untested_optimizer': True}, 'ds_version': '0.14.0'}\n","Detected checkpoint of type zero stage ZeroStageEnum.weights, world_size: 1\n","Found buffers: []\n","Found frozen_param_shapes: OrderedDict()\n","Parsing checkpoint created by deepspeed==0.14.0\n","added 0 buffers\n","fp32_flat_groups[0].shape=torch.Size([262702080])\n","Trainable params: Have 262702080 numels to process.\n","Trainable params: Need 262702080 numels in 107 params.\n","Trainable params: 1 model.embed_tokens.weight full shape: torch.Size([32000, 1024]) partition0 numel=32768000 partitioned_padding_numel=0\n","Trainable params: 2 model.layers.0.self_attn.q_proj.weight full shape: torch.Size([1024, 1024]) partition0 numel=1048576 partitioned_padding_numel=0\n","Trainable params: 3 model.layers.0.self_attn.k_proj.weight full shape: torch.Size([256, 1024]) partition0 numel=262144 partitioned_padding_numel=0\n","Trainable params: 4 model.layers.0.self_attn.v_proj.weight full shape: torch.Size([256, 1024]) partition0 numel=262144 partitioned_padding_numel=0\n","Trainable params: 5 model.layers.0.self_attn.o_proj.weight full shape: torch.Size([1024, 1024]) partition0 numel=1048576 partitioned_padding_numel=0\n","Trainable params: 6 model.layers.0.block_sparse_moe.gate.weight full shape: torch.Size([2, 1024]) partition0 numel=2048 partitioned_padding_numel=0\n","Trainable params: 7 model.layers.0.block_sparse_moe.experts.0.w1.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 8 model.layers.0.block_sparse_moe.experts.0.w2.weight full shape: torch.Size([1024, 3584]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 9 model.layers.0.block_sparse_moe.experts.0.w3.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 10 model.layers.0.block_sparse_moe.experts.1.w1.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 11 model.layers.0.block_sparse_moe.experts.1.w2.weight full shape: torch.Size([1024, 3584]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 12 model.layers.0.block_sparse_moe.experts.1.w3.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 13 model.layers.0.input_layernorm.weight full shape: torch.Size([1024]) partition0 numel=1024 partitioned_padding_numel=0\n","Trainable params: 14 model.layers.0.post_attention_layernorm.weight full shape: torch.Size([1024]) partition0 numel=1024 partitioned_padding_numel=0\n","Trainable params: 15 model.layers.1.self_attn.q_proj.weight full shape: torch.Size([1024, 1024]) partition0 numel=1048576 partitioned_padding_numel=0\n","Trainable params: 16 model.layers.1.self_attn.k_proj.weight full shape: torch.Size([256, 1024]) partition0 numel=262144 partitioned_padding_numel=0\n","Trainable params: 17 model.layers.1.self_attn.v_proj.weight full shape: torch.Size([256, 1024]) partition0 numel=262144 partitioned_padding_numel=0\n","Trainable params: 18 model.layers.1.self_attn.o_proj.weight full shape: torch.Size([1024, 1024]) partition0 numel=1048576 partitioned_padding_numel=0\n","Trainable params: 19 model.layers.1.block_sparse_moe.gate.weight full shape: torch.Size([2, 1024]) partition0 numel=2048 partitioned_padding_numel=0\n","Trainable params: 20 model.layers.1.block_sparse_moe.experts.0.w1.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 21 model.layers.1.block_sparse_moe.experts.0.w2.weight full shape: torch.Size([1024, 3584]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 22 model.layers.1.block_sparse_moe.experts.0.w3.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 23 model.layers.1.block_sparse_moe.experts.1.w1.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 24 model.layers.1.block_sparse_moe.experts.1.w2.weight full shape: torch.Size([1024, 3584]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 25 model.layers.1.block_sparse_moe.experts.1.w3.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 26 model.layers.1.input_layernorm.weight full shape: torch.Size([1024]) partition0 numel=1024 partitioned_padding_numel=0\n","Trainable params: 27 model.layers.1.post_attention_layernorm.weight full shape: torch.Size([1024]) partition0 numel=1024 partitioned_padding_numel=0\n","Trainable params: 28 model.layers.2.self_attn.q_proj.weight full shape: torch.Size([1024, 1024]) partition0 numel=1048576 partitioned_padding_numel=0\n","Trainable params: 29 model.layers.2.self_attn.k_proj.weight full shape: torch.Size([256, 1024]) partition0 numel=262144 partitioned_padding_numel=0\n","Trainable params: 30 model.layers.2.self_attn.v_proj.weight full shape: torch.Size([256, 1024]) partition0 numel=262144 partitioned_padding_numel=0\n","Trainable params: 31 model.layers.2.self_attn.o_proj.weight full shape: torch.Size([1024, 1024]) partition0 numel=1048576 partitioned_padding_numel=0\n","Trainable params: 32 model.layers.2.block_sparse_moe.gate.weight full shape: torch.Size([2, 1024]) partition0 numel=2048 partitioned_padding_numel=0\n","Trainable params: 33 model.layers.2.block_sparse_moe.experts.0.w1.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 34 model.layers.2.block_sparse_moe.experts.0.w2.weight full shape: torch.Size([1024, 3584]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 35 model.layers.2.block_sparse_moe.experts.0.w3.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 36 model.layers.2.block_sparse_moe.experts.1.w1.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 37 model.layers.2.block_sparse_moe.experts.1.w2.weight full shape: torch.Size([1024, 3584]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 38 model.layers.2.block_sparse_moe.experts.1.w3.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 39 model.layers.2.input_layernorm.weight full shape: torch.Size([1024]) partition0 numel=1024 partitioned_padding_numel=0\n","Trainable params: 40 model.layers.2.post_attention_layernorm.weight full shape: torch.Size([1024]) partition0 numel=1024 partitioned_padding_numel=0\n","Trainable params: 41 model.layers.3.self_attn.q_proj.weight full shape: torch.Size([1024, 1024]) partition0 numel=1048576 partitioned_padding_numel=0\n","Trainable params: 42 model.layers.3.self_attn.k_proj.weight full shape: torch.Size([256, 1024]) partition0 numel=262144 partitioned_padding_numel=0\n","Trainable params: 43 model.layers.3.self_attn.v_proj.weight full shape: torch.Size([256, 1024]) partition0 numel=262144 partitioned_padding_numel=0\n","Trainable params: 44 model.layers.3.self_attn.o_proj.weight full shape: torch.Size([1024, 1024]) partition0 numel=1048576 partitioned_padding_numel=0\n","Trainable params: 45 model.layers.3.block_sparse_moe.gate.weight full shape: torch.Size([2, 1024]) partition0 numel=2048 partitioned_padding_numel=0\n","Trainable params: 46 model.layers.3.block_sparse_moe.experts.0.w1.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 47 model.layers.3.block_sparse_moe.experts.0.w2.weight full shape: torch.Size([1024, 3584]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 48 model.layers.3.block_sparse_moe.experts.0.w3.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 49 model.layers.3.block_sparse_moe.experts.1.w1.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 50 model.layers.3.block_sparse_moe.experts.1.w2.weight full shape: torch.Size([1024, 3584]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 51 model.layers.3.block_sparse_moe.experts.1.w3.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 52 model.layers.3.input_layernorm.weight full shape: torch.Size([1024]) partition0 numel=1024 partitioned_padding_numel=0\n","Trainable params: 53 model.layers.3.post_attention_layernorm.weight full shape: torch.Size([1024]) partition0 numel=1024 partitioned_padding_numel=0\n","Trainable params: 54 model.layers.4.self_attn.q_proj.weight full shape: torch.Size([1024, 1024]) partition0 numel=1048576 partitioned_padding_numel=0\n","Trainable params: 55 model.layers.4.self_attn.k_proj.weight full shape: torch.Size([256, 1024]) partition0 numel=262144 partitioned_padding_numel=0\n","Trainable params: 56 model.layers.4.self_attn.v_proj.weight full shape: torch.Size([256, 1024]) partition0 numel=262144 partitioned_padding_numel=0\n","Trainable params: 57 model.layers.4.self_attn.o_proj.weight full shape: torch.Size([1024, 1024]) partition0 numel=1048576 partitioned_padding_numel=0\n","Trainable params: 58 model.layers.4.block_sparse_moe.gate.weight full shape: torch.Size([2, 1024]) partition0 numel=2048 partitioned_padding_numel=0\n","Trainable params: 59 model.layers.4.block_sparse_moe.experts.0.w1.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 60 model.layers.4.block_sparse_moe.experts.0.w2.weight full shape: torch.Size([1024, 3584]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 61 model.layers.4.block_sparse_moe.experts.0.w3.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 62 model.layers.4.block_sparse_moe.experts.1.w1.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 63 model.layers.4.block_sparse_moe.experts.1.w2.weight full shape: torch.Size([1024, 3584]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 64 model.layers.4.block_sparse_moe.experts.1.w3.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 65 model.layers.4.input_layernorm.weight full shape: torch.Size([1024]) partition0 numel=1024 partitioned_padding_numel=0\n","Trainable params: 66 model.layers.4.post_attention_layernorm.weight full shape: torch.Size([1024]) partition0 numel=1024 partitioned_padding_numel=0\n","Trainable params: 67 model.layers.5.self_attn.q_proj.weight full shape: torch.Size([1024, 1024]) partition0 numel=1048576 partitioned_padding_numel=0\n","Trainable params: 68 model.layers.5.self_attn.k_proj.weight full shape: torch.Size([256, 1024]) partition0 numel=262144 partitioned_padding_numel=0\n","Trainable params: 69 model.layers.5.self_attn.v_proj.weight full shape: torch.Size([256, 1024]) partition0 numel=262144 partitioned_padding_numel=0\n","Trainable params: 70 model.layers.5.self_attn.o_proj.weight full shape: torch.Size([1024, 1024]) partition0 numel=1048576 partitioned_padding_numel=0\n","Trainable params: 71 model.layers.5.block_sparse_moe.gate.weight full shape: torch.Size([2, 1024]) partition0 numel=2048 partitioned_padding_numel=0\n","Trainable params: 72 model.layers.5.block_sparse_moe.experts.0.w1.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 73 model.layers.5.block_sparse_moe.experts.0.w2.weight full shape: torch.Size([1024, 3584]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 74 model.layers.5.block_sparse_moe.experts.0.w3.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 75 model.layers.5.block_sparse_moe.experts.1.w1.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 76 model.layers.5.block_sparse_moe.experts.1.w2.weight full shape: torch.Size([1024, 3584]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 77 model.layers.5.block_sparse_moe.experts.1.w3.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 78 model.layers.5.input_layernorm.weight full shape: torch.Size([1024]) partition0 numel=1024 partitioned_padding_numel=0\n","Trainable params: 79 model.layers.5.post_attention_layernorm.weight full shape: torch.Size([1024]) partition0 numel=1024 partitioned_padding_numel=0\n","Trainable params: 80 model.layers.6.self_attn.q_proj.weight full shape: torch.Size([1024, 1024]) partition0 numel=1048576 partitioned_padding_numel=0\n","Trainable params: 81 model.layers.6.self_attn.k_proj.weight full shape: torch.Size([256, 1024]) partition0 numel=262144 partitioned_padding_numel=0\n","Trainable params: 82 model.layers.6.self_attn.v_proj.weight full shape: torch.Size([256, 1024]) partition0 numel=262144 partitioned_padding_numel=0\n","Trainable params: 83 model.layers.6.self_attn.o_proj.weight full shape: torch.Size([1024, 1024]) partition0 numel=1048576 partitioned_padding_numel=0\n","Trainable params: 84 model.layers.6.block_sparse_moe.gate.weight full shape: torch.Size([2, 1024]) partition0 numel=2048 partitioned_padding_numel=0\n","Trainable params: 85 model.layers.6.block_sparse_moe.experts.0.w1.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 86 model.layers.6.block_sparse_moe.experts.0.w2.weight full shape: torch.Size([1024, 3584]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 87 model.layers.6.block_sparse_moe.experts.0.w3.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 88 model.layers.6.block_sparse_moe.experts.1.w1.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 89 model.layers.6.block_sparse_moe.experts.1.w2.weight full shape: torch.Size([1024, 3584]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 90 model.layers.6.block_sparse_moe.experts.1.w3.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 91 model.layers.6.input_layernorm.weight full shape: torch.Size([1024]) partition0 numel=1024 partitioned_padding_numel=0\n","Trainable params: 92 model.layers.6.post_attention_layernorm.weight full shape: torch.Size([1024]) partition0 numel=1024 partitioned_padding_numel=0\n","Trainable params: 93 model.layers.7.self_attn.q_proj.weight full shape: torch.Size([1024, 1024]) partition0 numel=1048576 partitioned_padding_numel=0\n","Trainable params: 94 model.layers.7.self_attn.k_proj.weight full shape: torch.Size([256, 1024]) partition0 numel=262144 partitioned_padding_numel=0\n","Trainable params: 95 model.layers.7.self_attn.v_proj.weight full shape: torch.Size([256, 1024]) partition0 numel=262144 partitioned_padding_numel=0\n","Trainable params: 96 model.layers.7.self_attn.o_proj.weight full shape: torch.Size([1024, 1024]) partition0 numel=1048576 partitioned_padding_numel=0\n","Trainable params: 97 model.layers.7.block_sparse_moe.gate.weight full shape: torch.Size([2, 1024]) partition0 numel=2048 partitioned_padding_numel=0\n","Trainable params: 98 model.layers.7.block_sparse_moe.experts.0.w1.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 99 model.layers.7.block_sparse_moe.experts.0.w2.weight full shape: torch.Size([1024, 3584]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 100 model.layers.7.block_sparse_moe.experts.0.w3.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 101 model.layers.7.block_sparse_moe.experts.1.w1.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 102 model.layers.7.block_sparse_moe.experts.1.w2.weight full shape: torch.Size([1024, 3584]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 103 model.layers.7.block_sparse_moe.experts.1.w3.weight full shape: torch.Size([3584, 1024]) partition0 numel=3670016 partitioned_padding_numel=0\n","Trainable params: 104 model.layers.7.input_layernorm.weight full shape: torch.Size([1024]) partition0 numel=1024 partitioned_padding_numel=0\n","Trainable params: 105 model.layers.7.post_attention_layernorm.weight full shape: torch.Size([1024]) partition0 numel=1024 partitioned_padding_numel=0\n","Trainable params: 106 model.norm.weight full shape: torch.Size([1024]) partition0 numel=1024 partitioned_padding_numel=0\n","Trainable params: 107 lm_head.weight full shape: torch.Size([32000, 1024]) partition0 numel=32768000 partitioned_padding_numel=0\n","Reconstructed Trainable fp32 state dict with 107 params 262702080 elements\n","Saving fp32 state dict to /root/moe-recipes/okazaki-cc-lr_2e-5-minlr_2e-6_warmup_1000_sliding_window_1024/iter_0001000/fp32_model.bin\n","Done\n"]}]},{"cell_type":"code","source":["%cd ~/moe-recipes/tools/checkpoint-convert/scripts/abci\n","!bash convert_ckpt_colab.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d6B69kSTa81A","executionInfo":{"status":"ok","timestamp":1710852014888,"user_tz":-540,"elapsed":10184,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}},"outputId":"6927a13a-505a-4406-b57b-642e89540d30"},"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["/root/moe-recipes/tools/checkpoint-convert/scripts/abci\n","MASTER_ADDR=localhost\n","convert /root/moe-recipes/okazaki-cc-lr_2e-5-minlr_2e-6_warmup_1000_sliding_window_1024/iter_0000250/fp32_model.bin to /root/moe-recipes/huggingface/iter_0000250\n","Loading CKPT: /root/moe-recipes/okazaki-cc-lr_2e-5-minlr_2e-6_warmup_1000_sliding_window_1024/iter_0000250/fp32_model.bin\n","Loading state dict into HF model\n","Saving HF model\n"]}]},{"cell_type":"code","source":["#Write権限のあるアクセストークンが必要\n","from huggingface_hub import notebook_login\n","notebook_login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["39e822e5751e490790785ab4b64e53e9","d34a4f2e94b84d0886cff9b8c06c10e7","fa1ad8aa66874eddaa23a92487351702","5919c7179dd94bcf9db59431312549f6","81a91bc9f44c45dfa5e056b08d6528e0","af74f7ac1b014ad2863de54a5c4e65eb","8e1440abf3a046ccadab00beae259ab8","3c7cb6e1dcb349a4919cd11726babac0","48703581b7c94769809109f260d61bd9","b701d2891b4440548d32fa3c25128097","4661c496caa74ea2a9af0413295d6d8b","73045d42a22b49768cca62c1ef9f4d04","7466329ec4574396b1ea2fe19d9397a7","2212b57f4a0946a4a40aa01133a9fc02","22920191668f467d8af55bd2065683c9","5d29c3ce23e7414297ae8f01e534c8bc","614f5910f73141888545587cc864c0a5","1a3610edc93244349e84910718022d33","a2012f3cf7ef40ae8a3dc723356602eb","36e7b8ca147249f5a0c77102843453e6","95d648c846c748f9bffce2a9bd4abe1d","8fd983ee67754d2ba9fcb8c11015766e","3e9289edc96b43daa07081c30bb56950","8835f0e19c9244db8ccf9aa6bef91d27","351dfb47e8aa46ec9ac0c2aff7712eaf","f8f32e1762504d04b4def420c5c85000","ef67986ae33d40dd9080c65a4beca3a7","eee537f4756e49fe9fabed34a1a97277","93725d6daf3a47088c7602d23b9477aa","f32ba8185ec74c3997ef680ebe4053df","58a6c517f7de479aae91fa2ae95e8fdc","bcce7766bd174302b36246fd44ab2dc6"]},"id":"NysICPYsjNIx","executionInfo":{"status":"ok","timestamp":1710850294176,"user_tz":-540,"elapsed":6,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}},"outputId":"d69f9b6d-e242-422f-e70b-51fe3bbb9ebe"},"execution_count":84,"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39e822e5751e490790785ab4b64e53e9"}},"metadata":{}}]},{"cell_type":"code","source":["%cd ~/moe-recipes/tools/model-upload\n","!bash upload.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JAI5TU8Qg1Fg","executionInfo":{"status":"ok","timestamp":1710852731151,"user_tz":-540,"elapsed":99321,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}},"outputId":"f89acac9-863d-41d3-d9fd-37eaea3e6c15"},"execution_count":97,"outputs":[{"output_type":"stream","name":"stdout","text":["/root/moe-recipes/tools/model-upload\n","to upload: ['tokenizer_config.json', 'config.json', 'generation_config.json', 'model.safetensors', 'tokenizer.json', 'tokenizer.model']\n","Uploading tokenizer_config.json to branch main...\n","Successfully uploaded tokenizer_config.json !\n","Uploading config.json to branch main...\n","Successfully uploaded config.json !\n","Uploading generation_config.json to branch main...\n","Successfully uploaded generation_config.json !\n","Uploading model.safetensors to branch main...\n","model.safetensors: 100% 1.05G/1.05G [01:26<00:00, 12.1MB/s]\n","Successfully uploaded model.safetensors !\n","Uploading tokenizer.json to branch main...\n","Successfully uploaded tokenizer.json !\n","Uploading tokenizer.model to branch main...\n","tokenizer.model: 100% 493k/493k [00:00<00:00, 1.42MB/s]\n","Successfully uploaded tokenizer.model !\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oPu_S_TS8IOp","executionInfo":{"status":"ok","timestamp":1710839224658,"user_tz":-540,"elapsed":60827,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}},"outputId":"27fe507e-5920-4eee-c58c-0fb2e9f081be"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!cp -r /root/moe-recipes/okazaki-cc-lr_2e-5-minlr_2e-6_warmup_1000_sliding_window_1024 /content/drive/My\\ Drive/"],"metadata":{"id":"XUEWdapJ-O7q","executionInfo":{"status":"ok","timestamp":1710853289362,"user_tz":-540,"elapsed":83377,"user":{"displayName":"5 Kuuma (‪kuuma5‬)","userId":"00128829864959543579"}}},"execution_count":98,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[{"file_id":"1dnzwsEsT93RDPldF89zQbi785uyOANx_","timestamp":1710266197968},{"file_id":"1oMDXdVhUhBbsGXVdeuPUr2oKVVkgKFwX","timestamp":1710255842121},{"file_id":"1RR4qwxzQoY18H-xoL6_hDFJWJYfJgw8H","timestamp":1709630543531}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c6fe94b70c50470495befb609de8d2e8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6199cc7dd9624dc8b18d11096ac67a13","IPY_MODEL_df48b892eb674ec881867664c73bde78","IPY_MODEL_f346caf6dfd345e88d9fae0e30dd3ccd"],"layout":"IPY_MODEL_57d08b7e9b1a4a1999f6c7c1b9220814"}},"6199cc7dd9624dc8b18d11096ac67a13":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f67e1d4ebf4448bca2b34d74c3f80249","placeholder":"​","style":"IPY_MODEL_517127fce3ec442f9c42a17752aeed0f","value":"tokenizer_config.json: 100%"}},"df48b892eb674ec881867664c73bde78":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0e1dde5d3034a67b1a03ca10c0d34b9","max":967,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4ce24eca8dbb480799bd5cb162bffe97","value":967}},"f346caf6dfd345e88d9fae0e30dd3ccd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3d704b60bd34593adf44d28981c3902","placeholder":"​","style":"IPY_MODEL_7dcbeabcd20541a483b000af3a701feb","value":" 967/967 [00:00&lt;00:00, 82.4kB/s]"}},"57d08b7e9b1a4a1999f6c7c1b9220814":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f67e1d4ebf4448bca2b34d74c3f80249":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"517127fce3ec442f9c42a17752aeed0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d0e1dde5d3034a67b1a03ca10c0d34b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ce24eca8dbb480799bd5cb162bffe97":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e3d704b60bd34593adf44d28981c3902":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7dcbeabcd20541a483b000af3a701feb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c7310901b30c414fa7e29bb084986e1a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3719d76264814566804dac0094c3d105","IPY_MODEL_58ab0807c52740de936d79f6a0e7f13d","IPY_MODEL_5a9e40ca33ba4b70abfc5075b11ef320"],"layout":"IPY_MODEL_cc484497cbe84ea1a9c5d7127521bbb5"}},"3719d76264814566804dac0094c3d105":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1af221c394c541a298118903e567fec2","placeholder":"​","style":"IPY_MODEL_2d20507f7926459caaf46bb776aeca8b","value":"tokenizer.model: 100%"}},"58ab0807c52740de936d79f6a0e7f13d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0cee4ee704a046b1a3669476ecdc27c7","max":493443,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9d70008067b941e78db3a011b0f705f2","value":493443}},"5a9e40ca33ba4b70abfc5075b11ef320":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d6e34b71f5f413eaf3011e0b286615a","placeholder":"​","style":"IPY_MODEL_0d7c1f47efe44eb1a3250ae866540dd9","value":" 493k/493k [00:00&lt;00:00, 19.6MB/s]"}},"cc484497cbe84ea1a9c5d7127521bbb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1af221c394c541a298118903e567fec2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d20507f7926459caaf46bb776aeca8b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0cee4ee704a046b1a3669476ecdc27c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d70008067b941e78db3a011b0f705f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8d6e34b71f5f413eaf3011e0b286615a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d7c1f47efe44eb1a3250ae866540dd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"354880a1d1d0419ab74668a13a2b1627":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9d99df716c2443f690fade01e204ad8a","IPY_MODEL_629ccc3f025049b39a3134cfdbac3f14","IPY_MODEL_ad7035ac8de942f196749394ed48a714"],"layout":"IPY_MODEL_d2bbb85605cb46688ba77854200265c7"}},"9d99df716c2443f690fade01e204ad8a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8824d2d9d9cf427e9b5c3d4bb863b1cf","placeholder":"​","style":"IPY_MODEL_5f3d2dcfe7c247f7ba8e4a301f6e1d2b","value":"tokenizer.json: 100%"}},"629ccc3f025049b39a3134cfdbac3f14":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ca79947b0664e759f0a6d9df3f9cc7e","max":1795303,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d9b73342b27343308a8c54c2eaa24cc3","value":1795303}},"ad7035ac8de942f196749394ed48a714":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1bd52af930f64ccc8d91450e1cb4663e","placeholder":"​","style":"IPY_MODEL_30d7729408b14e6db45179d81fa043b9","value":" 1.80M/1.80M [00:00&lt;00:00, 7.06MB/s]"}},"d2bbb85605cb46688ba77854200265c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8824d2d9d9cf427e9b5c3d4bb863b1cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f3d2dcfe7c247f7ba8e4a301f6e1d2b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ca79947b0664e759f0a6d9df3f9cc7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9b73342b27343308a8c54c2eaa24cc3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1bd52af930f64ccc8d91450e1cb4663e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30d7729408b14e6db45179d81fa043b9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fca413e0d8e643758caf7d0d131fecfa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_04f1a5cd3ebc408cae13a4ac3a53d465","IPY_MODEL_6a964d68ee794218b18bcf602a4124ed","IPY_MODEL_fd7da8d0d37c406883e1e3081a6daf52"],"layout":"IPY_MODEL_d3db72b97e8948c899cc303ff9b16694"}},"04f1a5cd3ebc408cae13a4ac3a53d465":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c175173be8a4b14914125b48ee766b7","placeholder":"​","style":"IPY_MODEL_e6cff957b7b04580845cc969c71c28e9","value":"special_tokens_map.json: 100%"}},"6a964d68ee794218b18bcf602a4124ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b38fb27ff76e4c7680a8c3e7f5c63250","max":72,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2abbd77b65434840af9a9078f8188cc9","value":72}},"fd7da8d0d37c406883e1e3081a6daf52":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad59fbb0749e4c4ea2a3b6b6d6dddf7c","placeholder":"​","style":"IPY_MODEL_d5f7cbdb20b34ecd96ba965ec3a1de67","value":" 72.0/72.0 [00:00&lt;00:00, 4.42kB/s]"}},"d3db72b97e8948c899cc303ff9b16694":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c175173be8a4b14914125b48ee766b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6cff957b7b04580845cc969c71c28e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b38fb27ff76e4c7680a8c3e7f5c63250":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2abbd77b65434840af9a9078f8188cc9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ad59fbb0749e4c4ea2a3b6b6d6dddf7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5f7cbdb20b34ecd96ba965ec3a1de67":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39e822e5751e490790785ab4b64e53e9":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_95d648c846c748f9bffce2a9bd4abe1d","IPY_MODEL_8fd983ee67754d2ba9fcb8c11015766e","IPY_MODEL_3e9289edc96b43daa07081c30bb56950","IPY_MODEL_8835f0e19c9244db8ccf9aa6bef91d27"],"layout":"IPY_MODEL_8e1440abf3a046ccadab00beae259ab8"}},"d34a4f2e94b84d0886cff9b8c06c10e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c7cb6e1dcb349a4919cd11726babac0","placeholder":"​","style":"IPY_MODEL_48703581b7c94769809109f260d61bd9","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"fa1ad8aa66874eddaa23a92487351702":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_b701d2891b4440548d32fa3c25128097","placeholder":"​","style":"IPY_MODEL_4661c496caa74ea2a9af0413295d6d8b","value":""}},"5919c7179dd94bcf9db59431312549f6":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_73045d42a22b49768cca62c1ef9f4d04","style":"IPY_MODEL_7466329ec4574396b1ea2fe19d9397a7","value":true}},"81a91bc9f44c45dfa5e056b08d6528e0":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_2212b57f4a0946a4a40aa01133a9fc02","style":"IPY_MODEL_22920191668f467d8af55bd2065683c9","tooltip":""}},"af74f7ac1b014ad2863de54a5c4e65eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d29c3ce23e7414297ae8f01e534c8bc","placeholder":"​","style":"IPY_MODEL_614f5910f73141888545587cc864c0a5","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"8e1440abf3a046ccadab00beae259ab8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"3c7cb6e1dcb349a4919cd11726babac0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48703581b7c94769809109f260d61bd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b701d2891b4440548d32fa3c25128097":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4661c496caa74ea2a9af0413295d6d8b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73045d42a22b49768cca62c1ef9f4d04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7466329ec4574396b1ea2fe19d9397a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2212b57f4a0946a4a40aa01133a9fc02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22920191668f467d8af55bd2065683c9":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"5d29c3ce23e7414297ae8f01e534c8bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"614f5910f73141888545587cc864c0a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a3610edc93244349e84910718022d33":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2012f3cf7ef40ae8a3dc723356602eb","placeholder":"​","style":"IPY_MODEL_36e7b8ca147249f5a0c77102843453e6","value":"Connecting..."}},"a2012f3cf7ef40ae8a3dc723356602eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36e7b8ca147249f5a0c77102843453e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95d648c846c748f9bffce2a9bd4abe1d":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_351dfb47e8aa46ec9ac0c2aff7712eaf","placeholder":"​","style":"IPY_MODEL_f8f32e1762504d04b4def420c5c85000","value":"Token is valid (permission: write)."}},"8fd983ee67754d2ba9fcb8c11015766e":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef67986ae33d40dd9080c65a4beca3a7","placeholder":"​","style":"IPY_MODEL_eee537f4756e49fe9fabed34a1a97277","value":"Your token has been saved in your configured git credential helpers (store)."}},"3e9289edc96b43daa07081c30bb56950":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93725d6daf3a47088c7602d23b9477aa","placeholder":"​","style":"IPY_MODEL_f32ba8185ec74c3997ef680ebe4053df","value":"Your token has been saved to /root/.cache/huggingface/token"}},"8835f0e19c9244db8ccf9aa6bef91d27":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58a6c517f7de479aae91fa2ae95e8fdc","placeholder":"​","style":"IPY_MODEL_bcce7766bd174302b36246fd44ab2dc6","value":"Login successful"}},"351dfb47e8aa46ec9ac0c2aff7712eaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8f32e1762504d04b4def420c5c85000":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef67986ae33d40dd9080c65a4beca3a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eee537f4756e49fe9fabed34a1a97277":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"93725d6daf3a47088c7602d23b9477aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f32ba8185ec74c3997ef680ebe4053df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58a6c517f7de479aae91fa2ae95e8fdc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcce7766bd174302b36246fd44ab2dc6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}